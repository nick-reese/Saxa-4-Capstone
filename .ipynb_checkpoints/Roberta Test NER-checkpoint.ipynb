{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39244000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nicholasreese/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "from docx import Document\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import pdfplumber\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from textblob import TextBlob\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import os\n",
    "import json\n",
    "from docx import Document\n",
    "import pdfplumber\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "from plotly.offline import plot\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e044a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a22515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasreese/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning:\n",
      "\n",
      "`torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6b32b0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54816c",
   "metadata": {},
   "source": [
    "## Loading the Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3099f737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4731618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = \"\"\"\n",
    "\n",
    "Nicholas E. Reese\n",
    "Van Ness, Washington D.C.\n",
    "412-216-2398\n",
    "Nicholas.E.Reese15@gmail.com \n",
    "Education \n",
    "•Georgetown University - August 2023 – December 2024\n",
    "Master of Science Business Analytics – MSBA candidate\n",
    "Peer-Elected Class Representative \n",
    "•Dickinson College - August 2014 – September 2018\n",
    "Economics & Political Science Double Major\n",
    "Varsity Tennis Captain \n",
    "•University of Bologna - August 2016\n",
    "\n",
    "Skills\n",
    "- R studio\n",
    "- Python\n",
    "- Power BI\n",
    "- SQL\n",
    "- Neural Networks\n",
    "- Machine Learning\n",
    "- Macro Modeling\n",
    "- AWS Cloud Services\n",
    "- Pandas\n",
    "- A/B Testing\n",
    "- Scikit-Learn\n",
    "- Econometrics\n",
    "\n",
    "Professional Experience\n",
    "FINRA, Washington, D.C.\tJune 2020 – Present \n",
    "Senior Analyst, Market Regulation\tSeptember 2022 – Present \n",
    "•Earned top 10% of performance of analysts for past two years.\n",
    "•Led team in research implementing PostgreSQL and NoSQL queries for large data pulls.\n",
    "•Spearheaded new analytical approaches to financial workflow with tools such as R & Python for model development.\n",
    "•Developed working predictive modeling schemas for senior staff using statistical analysis.\n",
    "•Leveraged skills in platforms like Python, R, Power BI, Tableau and SQL accompanied with strong statistical background in financial markets.\n",
    "•Built the Security-Based Swap training manual deck & produced the recorded info session for all of FINRA. \n",
    "•Selected for the FINRA’s first Georgetown Advanced Analytics Program as one of the most junior staff awarded opportunity.\n",
    "•Incorporated statistical analytics to assist in creating a NPL tool to analyze financial documents language to minimize time on manual analysis.\n",
    "•Produced unsupervised and supervised models to perform analysis for Security-Based Swaps trade patterns.\n",
    "•Improved FINRA platforms with Data Scientists for higher accuracy and efficiency. \n",
    "•Managed process of re-engineering supervisory reviews through advanced analytic tools for senior staff.\n",
    "•Implements advanced analytics to assist senior staff with maximizing efficiencies in daily workloads and trade pattern creations.\n",
    "•Presented visualization case work using Power BI & Tableau to senior leadership.\n",
    "•Persuaded senior staff to allow for statistical analytics tools like R.\n",
    "•Mentored over 20 junior & senior staff members on improving processes with analytical tools for financial reviews.\n",
    "•Managed junior staff with day-to-day workload while teaching the staff how to use advanced analytics.\n",
    "Analyst, Market Regulation\tJune 2021-September 2022\n",
    "·Created macroeconomic models for newly implemented FINRA Rule 2232 and MSRB Rule G-15.\n",
    "·Mentored junior staff with creating macro models, synthesizing responses from FINRA member firms.\n",
    "·Won the Regulator Scholarship for continued financial learning based on individual performance.\n",
    "·Received six internal awards for expertise in Municipal and Corporate Bond analysis as an analyst.\n",
    "Associate Analyst, Market Regulation\tJune 2020 – June 2021\n",
    "·Created macroeconomic models to quantify business models of selected firms for FINRA Rule 2232.\n",
    "             BNY Mellon, Pittsburgh, PA\t\t\t\t\t\t                 September 2019 – June 2020\n",
    "Corporate Trust Associate\n",
    "·Leader & instructor of the Bloomberg software for the Corporate Trust Team.\n",
    "LendingHome, Internship, Pittsburgh, PA\n",
    "Funding Specialist & Post Closing Member\tMarch 2019 – August 2019\n",
    "·Reviewed closing documents to ensure precise execution for funding staff.\n",
    "              Veraction/Trax, Junior Business Analyst, Memphis, TN\t  June 2016 - August 2016                                                    June 2016 - August 2016\n",
    "·Led the creation, development, and implementation of Request For Proposal (RFP) database.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16774b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resume_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf437695",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93d14c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ffe6ca6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "ner_pipeline = pipeline('ner', model = \"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "                       aggregation_strategy = 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0187db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = ner_pipeline(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90ee7beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Nicholas E, Label: PER, Score: 0.8347\n",
      "Entity: Reese, Label: PER, Score: 0.8619\n",
      "Entity: Van Ness, Label: LOC, Score: 0.6532\n",
      "Entity: Washington D, Label: LOC, Score: 0.9981\n",
      "Entity: C, Label: LOC, Score: 0.9990\n",
      "Entity: Nicholas, Label: PER, Score: 0.9735\n",
      "Entity: E, Label: PER, Score: 0.6905\n",
      "Entity: Reese, Label: PER, Score: 0.9786\n",
      "Entity: Georgetown University, Label: ORG, Score: 0.9974\n",
      "Entity: Science, Label: MISC, Score: 0.7188\n",
      "Entity: Business, Label: ORG, Score: 0.3938\n",
      "Entity: ##tics, Label: MISC, Score: 0.6904\n",
      "Entity: MS, Label: MISC, Score: 0.6772\n",
      "Entity: ##BA, Label: ORG, Score: 0.6136\n",
      "Entity: Dickinson College, Label: ORG, Score: 0.9974\n",
      "Entity: & Political, Label: ORG, Score: 0.6406\n",
      "Entity: Science, Label: MISC, Score: 0.6226\n",
      "Entity: University of Bologna, Label: ORG, Score: 0.9910\n",
      "Entity: Python, Label: MISC, Score: 0.7331\n",
      "Entity: B, Label: MISC, Score: 0.3749\n",
      "Entity: S, Label: MISC, Score: 0.4090\n",
      "Entity: N, Label: MISC, Score: 0.3621\n",
      "Entity: Networks, Label: MISC, Score: 0.5680\n",
      "Entity: AWS, Label: ORG, Score: 0.8358\n",
      "Entity: E, Label: MISC, Score: 0.4678\n",
      "Entity: FINRA, Label: ORG, Score: 0.9555\n",
      "Entity: Washington, Label: LOC, Score: 0.9981\n",
      "Entity: D, Label: LOC, Score: 0.9980\n",
      "Entity: C, Label: LOC, Score: 0.9992\n",
      "Entity: Regulation, Label: ORG, Score: 0.4722\n",
      "Entity: PostgreSQL, Label: MISC, Score: 0.8554\n",
      "Entity: NoSQL, Label: MISC, Score: 0.9255\n",
      "Entity: R, Label: MISC, Score: 0.9847\n",
      "Entity: Python, Label: MISC, Score: 0.9538\n",
      "Entity: Python, Label: MISC, Score: 0.9085\n",
      "Entity: R, Label: MISC, Score: 0.7607\n",
      "Entity: Power, Label: ORG, Score: 0.4565\n",
      "Entity: BI, Label: MISC, Score: 0.4526\n",
      "Entity: Table, Label: ORG, Score: 0.5572\n",
      "Entity: ##au, Label: MISC, Score: 0.5457\n",
      "Entity: S, Label: MISC, Score: 0.8331\n",
      "Entity: Based S, Label: MISC, Score: 0.8241\n",
      "Entity: FINRA, Label: ORG, Score: 0.9622\n",
      "Entity: FINRA, Label: ORG, Score: 0.9660\n",
      "Entity: Georgetown Advanced Analytics Program, Label: MISC, Score: 0.7878\n",
      "Entity: Based Swa, Label: MISC, Score: 0.8259\n",
      "Entity: FINRA, Label: ORG, Score: 0.9642\n",
      "Entity: Data, Label: ORG, Score: 0.6258\n"
     ]
    }
   ],
   "source": [
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7b1f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_entities = [entity for entity in entities if entity['entity_group'] != 'MISC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "011758b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Nicholas E, Label: PER, Score: 0.8347\n",
      "Entity: Reese, Label: PER, Score: 0.8619\n",
      "Entity: Van Ness, Label: LOC, Score: 0.6532\n",
      "Entity: Washington D, Label: LOC, Score: 0.9981\n",
      "Entity: C, Label: LOC, Score: 0.9990\n",
      "Entity: Nicholas, Label: PER, Score: 0.9735\n",
      "Entity: E, Label: PER, Score: 0.6905\n",
      "Entity: Reese, Label: PER, Score: 0.9786\n",
      "Entity: Georgetown University, Label: ORG, Score: 0.9974\n",
      "Entity: Business, Label: ORG, Score: 0.3938\n",
      "Entity: ##BA, Label: ORG, Score: 0.6136\n",
      "Entity: Dickinson College, Label: ORG, Score: 0.9974\n",
      "Entity: & Political, Label: ORG, Score: 0.6406\n",
      "Entity: University of Bologna, Label: ORG, Score: 0.9910\n",
      "Entity: AWS, Label: ORG, Score: 0.8358\n",
      "Entity: FINRA, Label: ORG, Score: 0.9555\n",
      "Entity: Washington, Label: LOC, Score: 0.9981\n",
      "Entity: D, Label: LOC, Score: 0.9980\n",
      "Entity: C, Label: LOC, Score: 0.9992\n",
      "Entity: Regulation, Label: ORG, Score: 0.4722\n",
      "Entity: Power, Label: ORG, Score: 0.4565\n",
      "Entity: Table, Label: ORG, Score: 0.5572\n",
      "Entity: FINRA, Label: ORG, Score: 0.9622\n",
      "Entity: FINRA, Label: ORG, Score: 0.9660\n",
      "Entity: FINRA, Label: ORG, Score: 0.9642\n",
      "Entity: Data, Label: ORG, Score: 0.6258\n"
     ]
    }
   ],
   "source": [
    "for entity in filtered_entities:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e21cd27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nicholas.E.Reese15@gmail.com']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Regex pattern for email extraction\n",
    "email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "\n",
    "# Find all email addresses in the text\n",
    "emails = re.findall(email_pattern, resume_text)\n",
    "\n",
    "# Display found email addresses\n",
    "print(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98760ee5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Nicholas E, Label: PER, Score: 0.8347\n",
      "Entity: Reese, Label: PER, Score: 0.8619\n",
      "Entity: Van Ness, Label: LOC, Score: 0.6532\n",
      "Entity: Washington D, Label: LOC, Score: 0.9981\n",
      "Entity: C, Label: LOC, Score: 0.9990\n",
      "Entity: Nicholas, Label: PER, Score: 0.9735\n",
      "Entity: E, Label: PER, Score: 0.6905\n",
      "Entity: Reese, Label: PER, Score: 0.9786\n",
      "Entity: Georgetown University, Label: ORG, Score: 0.9974\n",
      "Entity: Science, Label: MISC, Score: 0.7188\n",
      "Entity: Business, Label: ORG, Score: 0.3938\n",
      "Entity: ##tics, Label: MISC, Score: 0.6904\n",
      "Entity: MS, Label: MISC, Score: 0.6772\n",
      "Entity: ##BA, Label: ORG, Score: 0.6136\n",
      "Entity: Dickinson College, Label: ORG, Score: 0.9974\n",
      "Entity: & Political, Label: ORG, Score: 0.6406\n",
      "Entity: Science, Label: MISC, Score: 0.6226\n",
      "Entity: University of Bologna, Label: ORG, Score: 0.9910\n",
      "Entity: Python, Label: MISC, Score: 0.7331\n",
      "Entity: B, Label: MISC, Score: 0.3749\n",
      "Entity: S, Label: MISC, Score: 0.4090\n",
      "Entity: N, Label: MISC, Score: 0.3621\n",
      "Entity: Networks, Label: MISC, Score: 0.5680\n",
      "Entity: AWS, Label: ORG, Score: 0.8358\n",
      "Entity: E, Label: MISC, Score: 0.4678\n",
      "Entity: FINRA, Label: ORG, Score: 0.9555\n",
      "Entity: Washington, Label: LOC, Score: 0.9981\n",
      "Entity: D, Label: LOC, Score: 0.9980\n",
      "Entity: C, Label: LOC, Score: 0.9992\n",
      "Entity: Regulation, Label: ORG, Score: 0.4722\n",
      "Entity: PostgreSQL, Label: MISC, Score: 0.8554\n",
      "Entity: NoSQL, Label: MISC, Score: 0.9255\n",
      "Entity: R, Label: MISC, Score: 0.9847\n",
      "Entity: Python, Label: MISC, Score: 0.9538\n",
      "Entity: Python, Label: MISC, Score: 0.9085\n",
      "Entity: R, Label: MISC, Score: 0.7607\n",
      "Entity: Power, Label: ORG, Score: 0.4565\n",
      "Entity: BI, Label: MISC, Score: 0.4526\n",
      "Entity: Table, Label: ORG, Score: 0.5572\n",
      "Entity: ##au, Label: MISC, Score: 0.5457\n",
      "Entity: S, Label: MISC, Score: 0.8331\n",
      "Entity: Based S, Label: MISC, Score: 0.8241\n",
      "Entity: FINRA, Label: ORG, Score: 0.9622\n",
      "Entity: FINRA, Label: ORG, Score: 0.9660\n",
      "Entity: Georgetown Advanced Analytics Program, Label: MISC, Score: 0.7878\n",
      "Entity: Based Swa, Label: MISC, Score: 0.8259\n",
      "Entity: FINRA, Label: ORG, Score: 0.9642\n",
      "Entity: Data, Label: ORG, Score: 0.6258\n"
     ]
    }
   ],
   "source": [
    "# Load the NER pipeline\n",
    "ner_pipeline2 = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", aggregation_strategy=\"simple\")\n",
    "\n",
    "\n",
    "# Detect entities using the NER pipeline\n",
    "entities2 = ner_pipeline2(resume_text)\n",
    "\n",
    "# Regex pattern for email extraction\n",
    "email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "\n",
    "# Find all email addresses in the text\n",
    "emails = re.findall(email_pattern, resume_text)\n",
    "\n",
    "# Print detected entities from NER\n",
    "for entity in entities2:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70122958",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c44ad",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f08d9402",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_test = \"\"\"\n",
    "Nicholas E. Reese\n",
    "Van Ness, Washington D.C.\n",
    "412-216-2398\n",
    "Nicholas.E.Reese@gmail.com\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19f5cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = ner_pipeline(resume_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68970e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Nicholas E. Reese Van Ness, Label: PER, Score: 0.8019\n",
      "Entity: Washington D, Label: LOC, Score: 0.9986\n",
      "Entity: C, Label: LOC, Score: 0.9995\n",
      "Entity: Nicholas, Label: PER, Score: 0.9980\n",
      "Entity: E. Reese, Label: PER, Score: 0.9686\n"
     ]
    }
   ],
   "source": [
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78cf5536",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds ={\n",
    "    'PER': .7,\n",
    "    'ORG': .8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa71d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "redacted_text = resume_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52dfd0ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nicholas E. Reese\n",
      "Van Ness, Washington D.C.\n",
      "412-216-2398\n",
      "[Redacted Email]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for entity in entities:\n",
    "    entity_type = entity['entity_group']\n",
    "    score = entity['score']\n",
    "    \n",
    "    if entity_type == entity and score >= thresholds[entity]:\n",
    "        entity_text = entity['word']\n",
    "        redacted_text = re.sub(re.escape(entity_text), '[Redacted]', redacted_text)\n",
    "\n",
    "# Redact the email addresses\n",
    "redacted_text = re.sub(r'\\S+@\\S+', '[Redacted Email]', redacted_text)\n",
    "\n",
    "\n",
    "\n",
    "print(redacted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3096cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(redacted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fca6c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_test = \"\"\"\n",
    "Nicholas E. Reese\n",
    "Van Ness, Washington D.C.\n",
    "412-216-2398\n",
    "Nicholas.E.Reese@gmail.com\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04cd0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = ner_pipeline(resume_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cab91ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Nicholas E. Reese Van Ness, Label: PER, Score: 0.8019\n",
      "Entity: Washington D, Label: LOC, Score: 0.9986\n",
      "Entity: C, Label: LOC, Score: 0.9995\n",
      "Entity: Nicholas, Label: PER, Score: 0.9980\n",
      "Entity: E. Reese, Label: PER, Score: 0.9686\n"
     ]
    }
   ],
   "source": [
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c881cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds ={\n",
    "    'PER': .8,\n",
    "    'ORG': .9,\n",
    "    'LOC': .8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74b0c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "redacted_text = resume_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0807a691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entities_sorted = sorted(entities, key=lambda x: len(x['word']), reverse=True)\n",
    "\n",
    "\n",
    "for entity in entities_sorted:\n",
    "    entity_type = entity['entity_group']\n",
    "    score = entity['score']\n",
    "    \n",
    "    if entity_type == entity_type and score >= thresholds[entity_type]:\n",
    "        entity_text = entity['word']\n",
    "        redacted_text = re.sub(re.escape(entity_text), '[Redacted]', redacted_text)\n",
    "\n",
    "\n",
    "        \n",
    "for entity in entities_sorted:\n",
    "    entity_type = entity['entity_group']\n",
    "    score = entity['score']\n",
    "    \n",
    "    if entity_type in thresholds and score >= thresholds[entity_type]:\n",
    "        entity_text = entity['word']\n",
    "        # Make sure to redact the smaller parts again if needed\n",
    "        redacted_text = re.sub(re.escape(entity_text), '[Redacted]', redacted_text)\n",
    "\n",
    "# Redact the email addresses and phone numbers \n",
    "redacted_text = re.sub(r'\\S+@\\S+', '[Redacted Email]', redacted_text)\n",
    "redacted_text = re.sub(r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}', '[Redacted Phone]', redacted_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75240a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Redacted] [Redacted]\n",
      "Van Ness, [Redacted].[Redacted].\n",
      "[Redacted Phone]\n",
      "[Redacted Email]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(redacted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1296530",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af0f6f",
   "metadata": {},
   "source": [
    "## Adding In Resumes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "890024d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added .docx: Genesis Roberto 2024 Resume.docx\n",
      "Added .docx: Jonathan J Saville resume.docx\n",
      "Added .pdf: Dezmond Richardson GU Q3.2024 Resume.docx.pdf\n",
      "Added .docx: Nicholas Reese Resume .docx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from docx import Document\n",
    "import pdfplumber\n",
    "\n",
    "def convert_files_to_json(folder_path, output_json_file):\n",
    "    corpus = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Skip temporary files created by Word\n",
    "        if filename.startswith('~$'):\n",
    "            print(f\"Skipped temporary file: {filename}\")\n",
    "            continue\n",
    "        \n",
    "        if filename.endswith('.docx'):\n",
    "            try:\n",
    "                doc = Document(file_path)\n",
    "                text = '\\n'.join([para.text for para in doc.paragraphs])\n",
    "                document_data = {\n",
    "                    'title': filename,\n",
    "                    'text': text, \n",
    "                    'type': 'word',\n",
    "                    'file_path': file_path\n",
    "                }\n",
    "                corpus.append(document_data)\n",
    "                print(f\"Added .docx: {filename}\") \n",
    "        \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing .docx file {filename}: {e}\")\n",
    "        \n",
    "        elif filename.endswith('.pdf'):\n",
    "            try:\n",
    "                with pdfplumber.open(file_path) as pdf:\n",
    "                    text = '\\n'.join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
    "                    document_data = {\n",
    "                        'title': filename, \n",
    "                        'text': text,\n",
    "                        'type': 'pdf',\n",
    "                        'file_path': file_path\n",
    "                    }\n",
    "                    corpus.append(document_data)\n",
    "                    print(f\"Added .pdf: {filename}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing .pdf file {filename}: {e}\")\n",
    "                \n",
    "    with open(output_json_file, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(corpus, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Call the function with your paths\n",
    "convert_files_to_json('/Users/nicholasreese/Desktop/Georgetown/Capstone/capstone_github/Capstone_Introduction/Saxa-4-Capstone', 'output_corpus.json')\n",
    "# change your file path to where you saved the resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "892438ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = pd.read_json('output_corpus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81c6e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = pd.DataFrame(resumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5853ff08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genesis Roberto 2024 Resume.docx</td>\n",
       "      <td>Ms. Genesis U. Roberto \\n     Rockville, MD   ...</td>\n",
       "      <td>word</td>\n",
       "      <td>/Users/nicholasreese/Desktop/Georgetown/Capsto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jonathan J Saville resume.docx</td>\n",
       "      <td>Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...</td>\n",
       "      <td>word</td>\n",
       "      <td>/Users/nicholasreese/Desktop/Georgetown/Capsto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dezmond Richardson GU Q3.2024 Resume.docx.pdf</td>\n",
       "      <td>D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...</td>\n",
       "      <td>pdf</td>\n",
       "      <td>/Users/nicholasreese/Desktop/Georgetown/Capsto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nicholas Reese Resume .docx</td>\n",
       "      <td>Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...</td>\n",
       "      <td>word</td>\n",
       "      <td>/Users/nicholasreese/Desktop/Georgetown/Capsto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0               Genesis Roberto 2024 Resume.docx   \n",
       "1                 Jonathan J Saville resume.docx   \n",
       "2  Dezmond Richardson GU Q3.2024 Resume.docx.pdf   \n",
       "3                    Nicholas Reese Resume .docx   \n",
       "\n",
       "                                                text  type  \\\n",
       "0  Ms. Genesis U. Roberto \\n     Rockville, MD   ...  word   \n",
       "1  Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...  word   \n",
       "2  D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...   pdf   \n",
       "3  Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...  word   \n",
       "\n",
       "                                           file_path  \n",
       "0  /Users/nicholasreese/Desktop/Georgetown/Capsto...  \n",
       "1  /Users/nicholasreese/Desktop/Georgetown/Capsto...  \n",
       "2  /Users/nicholasreese/Desktop/Georgetown/Capsto...  \n",
       "3  /Users/nicholasreese/Desktop/Georgetown/Capsto...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "421c3084",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = resumes.drop('file_path', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd495fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genesis Roberto 2024 Resume.docx</td>\n",
       "      <td>Ms. Genesis U. Roberto \\n     Rockville, MD   ...</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jonathan J Saville resume.docx</td>\n",
       "      <td>Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dezmond Richardson GU Q3.2024 Resume.docx.pdf</td>\n",
       "      <td>D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...</td>\n",
       "      <td>pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nicholas Reese Resume .docx</td>\n",
       "      <td>Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0               Genesis Roberto 2024 Resume.docx   \n",
       "1                 Jonathan J Saville resume.docx   \n",
       "2  Dezmond Richardson GU Q3.2024 Resume.docx.pdf   \n",
       "3                    Nicholas Reese Resume .docx   \n",
       "\n",
       "                                                text  type  \n",
       "0  Ms. Genesis U. Roberto \\n     Rockville, MD   ...  word  \n",
       "1  Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...  word  \n",
       "2  D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...   pdf  \n",
       "3  Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...  word  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52d1c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f886b400",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ner_pipeline = pipeline('ner', model = \"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "                       aggregation_strategy = 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4947ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes['text_list'] = resumes['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0371706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes['clean_text'] = resumes['text'].fillna(\"\").astype(str)\n",
    "\n",
    "resume_text = resumes['clean_text'].tolist()\n",
    "\n",
    "entities = ner_pipeline(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04543640",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = resumes.drop('text_clean', axis = 1)\n",
    "resumes = resumes.drop('text_list', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5fc3c42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genesis Roberto 2024 Resume.docx</td>\n",
       "      <td>Ms. Genesis U. Roberto \\n     Rockville, MD   ...</td>\n",
       "      <td>word</td>\n",
       "      <td>Ms. Genesis U. Roberto \\n     Rockville, MD   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jonathan J Saville resume.docx</td>\n",
       "      <td>Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...</td>\n",
       "      <td>word</td>\n",
       "      <td>Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dezmond Richardson GU Q3.2024 Resume.docx.pdf</td>\n",
       "      <td>D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...</td>\n",
       "      <td>pdf</td>\n",
       "      <td>D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nicholas Reese Resume .docx</td>\n",
       "      <td>Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...</td>\n",
       "      <td>word</td>\n",
       "      <td>Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0               Genesis Roberto 2024 Resume.docx   \n",
       "1                 Jonathan J Saville resume.docx   \n",
       "2  Dezmond Richardson GU Q3.2024 Resume.docx.pdf   \n",
       "3                    Nicholas Reese Resume .docx   \n",
       "\n",
       "                                                text  type  \\\n",
       "0  Ms. Genesis U. Roberto \\n     Rockville, MD   ...  word   \n",
       "1  Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...  word   \n",
       "2  D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...   pdf   \n",
       "3  Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...  word   \n",
       "\n",
       "                                          clean_text  \n",
       "0  Ms. Genesis U. Roberto \\n     Rockville, MD   ...  \n",
       "1  Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...  \n",
       "2  D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...  \n",
       "3  Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2d827690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nfrom transformers import pipeline\\n\\nner_pipeline = pipeline(\\'ner\\', model = \"dbmdz/bert-large-cased-finetuned-conll03-english\",\\n                       aggregation_strategy = \\'simple\\')\\n\\n#entities = ner_pipeline(resume_text)\\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "ner_pipeline = pipeline('ner', model = \"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "                       aggregation_strategy = 'simple')\n",
    "\n",
    "#entities = ner_pipeline(resume_text)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0b92f05",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Genesis U. Roberto Rockville, Label: PER, Score: 0.9323\n",
      "Entity: MD, Label: LOC, Score: 0.9810\n",
      "Entity: MD, Label: LOC, Score: 0.9903\n",
      "Entity: VA, Label: LOC, Score: 0.9143\n",
      "Entity: US GAAP, Label: MISC, Score: 0.7830\n",
      "Entity: SOX, Label: ORG, Score: 0.8475\n",
      "Entity: M & A, Label: ORG, Score: 0.8706\n",
      "Entity: Master, Label: MISC, Score: 0.4755\n",
      "Entity: Analysis, Label: MISC, Score: 0.4144\n",
      "Entity: Georgetown University, Label: ORG, Score: 0.9939\n",
      "Entity: Saggar, Label: PER, Score: 0.9326\n",
      "Entity: Rosenberg, Label: PER, Score: 0.9968\n",
      "Entity: Rockville, Label: LOC, Score: 0.9400\n",
      "Entity: MD, Label: LOC, Score: 0.9427\n",
      "Entity: Audit Services, Label: ORG, Score: 0.8769\n",
      "Entity: ASC, Label: MISC, Score: 0.6365\n",
      "Entity: Ernst and Young LLP, Label: ORG, Score: 0.9961\n",
      "Entity: Tysons, Label: LOC, Score: 0.9479\n",
      "Entity: Virginia, Label: LOC, Score: 0.9918\n",
      "Entity: Strategy and Transactions, Label: ORG, Score: 0.8156\n",
      "Entity: & A, Label: ORG, Score: 0.8782\n",
      "Entity: Alteryx, Label: ORG, Score: 0.8925\n",
      "Entity: PowerBi, Label: ORG, Score: 0.8365\n",
      "Entity: Technical Accounting and Advisory Services, Label: ORG, Score: 0.9893\n",
      "Entity: FAAS, Label: ORG, Score: 0.9710\n",
      "Entity: Audit & Assurance, Label: ORG, Score: 0.9223\n",
      "Entity: AS, Label: ORG, Score: 0.5883\n",
      "Entity: Canadian, Label: MISC, Score: 0.9955\n",
      "Entity: US, Label: MISC, Score: 0.6204\n",
      "Entity: GAA, Label: ORG, Score: 0.5875\n",
      "Entity: VA, Label: ORG, Score: 0.8660\n",
      "Entity: Jonathan J Saville, Label: PER, Score: 0.8632\n",
      "Entity: Edwards Ave, Label: LOC, Score: 0.8707\n",
      "Entity: Richmond, Label: LOC, Score: 0.9937\n",
      "Entity: Kentucky Lexington, Label: LOC, Score: 0.9745\n",
      "Entity: Marriott, Label: ORG, Score: 0.7979\n",
      "Entity: City Center, Label: LOC, Score: 0.9315\n",
      "Entity: Mar, Label: LOC, Score: 0.6524\n",
      "Entity: ##riott, Label: ORG, Score: 0.5960\n",
      "Entity: City Center Lexington, Label: LOC, Score: 0.9419\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9958\n",
      "Entity: Fedex Ground, Label: ORG, Score: 0.8165\n",
      "Entity: Lexington, Label: LOC, Score: 0.9817\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9969\n",
      "Entity: EZgigs Staffing Service, Label: ORG, Score: 0.9561\n",
      "Entity: Lexington, Label: LOC, Score: 0.9485\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9920\n",
      "Entity: Chris Stapleton, Label: PER, Score: 0.9293\n",
      "Entity: Rup, Label: LOC, Score: 0.7404\n",
      "Entity: Arena Harrodsburg, Label: LOC, Score: 0.8480\n",
      "Entity: Oktoberfest, Label: MISC, Score: 0.8395\n",
      "Entity: Hyatt Regency, Label: ORG, Score: 0.8098\n",
      "Entity: Lexington, Label: LOC, Score: 0.8495\n",
      "Entity: Lexington, Label: LOC, Score: 0.9959\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9964\n",
      "Entity: Hyttops Sports Bar, Label: LOC, Score: 0.5458\n",
      "Entity: Bluefire Bar, Label: LOC, Score: 0.7279\n",
      "Entity: Grill, Label: LOC, Score: 0.5772\n",
      "Entity: Keeneland Hospitality, Label: ORG, Score: 0.9142\n",
      "Entity: Lexington, Label: LOC, Score: 0.9314\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9924\n",
      "Entity: Dupree Catering, Label: ORG, Score: 0.9843\n",
      "Entity: Lexington, Label: LOC, Score: 0.9092\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9923\n",
      "Entity: Lexington, Label: LOC, Score: 0.9687\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9667\n",
      "Entity: ##ience, Label: ORG, Score: 0.6774\n",
      "Entity: EZ, Label: ORG, Score: 0.7416\n",
      "Entity: ##ND ICHARDSON, Label: ORG, Score: 0.6285\n",
      "Entity: ##GETOW, Label: ORG, Score: 0.5843\n",
      "Entity: M, Label: ORG, Score: 0.5348\n",
      "Entity: ##Donough, Label: ORG, Score: 0.5409\n",
      "Entity: ##f, Label: ORG, Score: 0.7519\n",
      "Entity: ##iness, Label: ORG, Score: 0.8213\n",
      "Entity: Washington, Label: LOC, Score: 0.9688\n",
      "Entity: DC, Label: LOC, Score: 0.9802\n",
      "Entity: ##GE, Label: ORG, Score: 0.6753\n",
      "Entity: GeorgetownS, Label: ORG, Score: 0.8681\n",
      "Entity: ##fC, Label: ORG, Score: 0.6986\n",
      "Entity: Washington, Label: LOC, Score: 0.9808\n",
      "Entity: DC, Label: LOC, Score: 0.9879\n",
      "Entity: ##GE, Label: ORG, Score: 0.5883\n",
      "Entity: GeorgetownC, Label: ORG, Score: 0.8524\n",
      "Entity: ##Arts & Science, Label: ORG, Score: 0.7664\n",
      "Entity: Washington, Label: LOC, Score: 0.9739\n",
      "Entity: DC, Label: LOC, Score: 0.9905\n",
      "Entity: SQL, Label: MISC, Score: 0.6730\n",
      "Entity: Java, Label: MISC, Score: 0.9417\n",
      "Entity: Python, Label: MISC, Score: 0.7048\n",
      "Entity: Excel, Label: MISC, Score: 0.7036\n",
      "Entity: AWS, Label: ORG, Score: 0.5011\n",
      "Entity: Excel, Label: MISC, Score: 0.9101\n",
      "Entity: Pi, Label: MISC, Score: 0.5548\n",
      "Entity: Salesforce, Label: ORG, Score: 0.9055\n",
      "Entity: ##A, Label: ORG, Score: 0.6056\n",
      "Entity: ##L, Label: ORG, Score: 0.6379\n",
      "Entity: JIRA, Label: ORG, Score: 0.8310\n",
      "Entity: ETL, Label: ORG, Score: 0.6672\n",
      "Entity: Microsoft, Label: MISC, Score: 0.5206\n",
      "Entity: Microsoft, Label: MISC, Score: 0.4802\n",
      "Entity: Washington, Label: LOC, Score: 0.3889\n",
      "Entity: DC, Label: ORG, Score: 0.4081\n",
      "Entity: USA, Label: LOC, Score: 0.5551\n",
      "Entity: Nicholas E, Label: PER, Score: 0.9242\n",
      "Entity: Reese, Label: PER, Score: 0.9529\n",
      "Entity: Van Ness, Label: LOC, Score: 0.6164\n",
      "Entity: Washington D, Label: LOC, Score: 0.9983\n",
      "Entity: C, Label: LOC, Score: 0.9990\n",
      "Entity: Nicholas. E, Label: PER, Score: 0.7995\n",
      "Entity: Reese, Label: PER, Score: 0.9900\n",
      "Entity: Georgetown University, Label: ORG, Score: 0.9981\n",
      "Entity: Master, Label: MISC, Score: 0.4842\n",
      "Entity: Science, Label: MISC, Score: 0.6786\n",
      "Entity: Ana, Label: MISC, Score: 0.4281\n",
      "Entity: ##tics, Label: MISC, Score: 0.7451\n",
      "Entity: MSBA, Label: ORG, Score: 0.6407\n",
      "Entity: Dickinson College, Label: ORG, Score: 0.9969\n",
      "Entity: Science, Label: MISC, Score: 0.6827\n",
      "Entity: Major Varsity Tennis, Label: MISC, Score: 0.6279\n",
      "Entity: University of Bologna, Label: ORG, Score: 0.9712\n",
      "Entity: FINRA, Label: ORG, Score: 0.9380\n",
      "Entity: Washington, Label: LOC, Score: 0.9978\n",
      "Entity: D, Label: LOC, Score: 0.9986\n",
      "Entity: C, Label: LOC, Score: 0.9988\n",
      "Entity: PostgreSQL, Label: MISC, Score: 0.8501\n",
      "Entity: NoSQL, Label: MISC, Score: 0.9160\n",
      "Entity: R & Python, Label: MISC, Score: 0.8393\n",
      "Entity: Python, Label: MISC, Score: 0.9269\n",
      "Entity: R, Label: MISC, Score: 0.9422\n",
      "Entity: Power BI, Label: MISC, Score: 0.7778\n",
      "Entity: Tableau, Label: MISC, Score: 0.8167\n",
      "Entity: SQL, Label: MISC, Score: 0.7720\n",
      "Entity: Based S, Label: MISC, Score: 0.7409\n",
      "Entity: FINRA, Label: ORG, Score: 0.9751\n",
      "Entity: FINRA, Label: ORG, Score: 0.9750\n",
      "Entity: Georgetown, Label: ORG, Score: 0.7613\n",
      "Entity: Advanced Analytics Program, Label: MISC, Score: 0.6055\n",
      "Entity: Based S, Label: MISC, Score: 0.7396\n",
      "Entity: FINRA, Label: ORG, Score: 0.9024\n",
      "Entity: Power B, Label: MISC, Score: 0.6652\n",
      "Entity: MS, Label: ORG, Score: 0.5474\n"
     ]
    }
   ],
   "source": [
    "for doc_entities in entities:\n",
    "    for entity in doc_entities:\n",
    "        print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "abad7ceb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: US GAAP, Label: MISC, Score: 0.7830\n",
      "Entity: Master, Label: MISC, Score: 0.4755\n",
      "Entity: Analysis, Label: MISC, Score: 0.4144\n",
      "Entity: ASC, Label: MISC, Score: 0.6365\n",
      "Entity: Canadian, Label: MISC, Score: 0.9955\n",
      "Entity: US, Label: MISC, Score: 0.6204\n",
      "Entity: Oktoberfest, Label: MISC, Score: 0.8395\n",
      "Entity: SQL, Label: MISC, Score: 0.6730\n",
      "Entity: Java, Label: MISC, Score: 0.9417\n",
      "Entity: Python, Label: MISC, Score: 0.7048\n",
      "Entity: Excel, Label: MISC, Score: 0.7036\n",
      "Entity: Excel, Label: MISC, Score: 0.9101\n",
      "Entity: Pi, Label: MISC, Score: 0.5548\n",
      "Entity: Microsoft, Label: MISC, Score: 0.5206\n",
      "Entity: Microsoft, Label: MISC, Score: 0.4802\n",
      "Entity: Master, Label: MISC, Score: 0.4842\n",
      "Entity: Science, Label: MISC, Score: 0.6786\n",
      "Entity: Ana, Label: MISC, Score: 0.4281\n",
      "Entity: ##tics, Label: MISC, Score: 0.7451\n",
      "Entity: Science, Label: MISC, Score: 0.6827\n",
      "Entity: Major Varsity Tennis, Label: MISC, Score: 0.6279\n",
      "Entity: PostgreSQL, Label: MISC, Score: 0.8501\n",
      "Entity: NoSQL, Label: MISC, Score: 0.9160\n",
      "Entity: R & Python, Label: MISC, Score: 0.8393\n",
      "Entity: Python, Label: MISC, Score: 0.9269\n",
      "Entity: R, Label: MISC, Score: 0.9422\n",
      "Entity: Power BI, Label: MISC, Score: 0.7778\n",
      "Entity: Tableau, Label: MISC, Score: 0.8167\n",
      "Entity: SQL, Label: MISC, Score: 0.7720\n",
      "Entity: Based S, Label: MISC, Score: 0.7409\n",
      "Entity: Advanced Analytics Program, Label: MISC, Score: 0.6055\n",
      "Entity: Based S, Label: MISC, Score: 0.7396\n",
      "Entity: Power B, Label: MISC, Score: 0.6652\n"
     ]
    }
   ],
   "source": [
    "for doc_entities in entities:\n",
    "    for entity in doc_entities:\n",
    "        if entity['entity_group'] == \"MISC\":\n",
    "            print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182e407a",
   "metadata": {},
   "source": [
    "We are going to keep MISC because there are alot of skills and other needed information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7bb9c5d0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Genesis U. Roberto Rockville, Label: PER, Score: 0.9323\n",
      "Entity: Saggar, Label: PER, Score: 0.9326\n",
      "Entity: Rosenberg, Label: PER, Score: 0.9968\n",
      "Entity: Jonathan J Saville, Label: PER, Score: 0.8632\n",
      "Entity: Chris Stapleton, Label: PER, Score: 0.9293\n",
      "Entity: Nicholas E, Label: PER, Score: 0.9242\n",
      "Entity: Reese, Label: PER, Score: 0.9529\n",
      "Entity: Nicholas. E, Label: PER, Score: 0.7995\n",
      "Entity: Reese, Label: PER, Score: 0.9900\n"
     ]
    }
   ],
   "source": [
    "for doc_entities in entities:\n",
    "    for entity in doc_entities:\n",
    "        if entity['entity_group'] == \"PER\":\n",
    "            print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "026456c2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: MD, Label: LOC, Score: 0.9810\n",
      "Entity: MD, Label: LOC, Score: 0.9903\n",
      "Entity: VA, Label: LOC, Score: 0.9143\n",
      "Entity: Rockville, Label: LOC, Score: 0.9400\n",
      "Entity: MD, Label: LOC, Score: 0.9427\n",
      "Entity: Tysons, Label: LOC, Score: 0.9479\n",
      "Entity: Virginia, Label: LOC, Score: 0.9918\n",
      "Entity: Edwards Ave, Label: LOC, Score: 0.8707\n",
      "Entity: Richmond, Label: LOC, Score: 0.9937\n",
      "Entity: Kentucky Lexington, Label: LOC, Score: 0.9745\n",
      "Entity: City Center, Label: LOC, Score: 0.9315\n",
      "Entity: Mar, Label: LOC, Score: 0.6524\n",
      "Entity: City Center Lexington, Label: LOC, Score: 0.9419\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9958\n",
      "Entity: Lexington, Label: LOC, Score: 0.9817\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9969\n",
      "Entity: Lexington, Label: LOC, Score: 0.9485\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9920\n",
      "Entity: Rup, Label: LOC, Score: 0.7404\n",
      "Entity: Arena Harrodsburg, Label: LOC, Score: 0.8480\n",
      "Entity: Lexington, Label: LOC, Score: 0.8495\n",
      "Entity: Lexington, Label: LOC, Score: 0.9959\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9964\n",
      "Entity: Hyttops Sports Bar, Label: LOC, Score: 0.5458\n",
      "Entity: Bluefire Bar, Label: LOC, Score: 0.7279\n",
      "Entity: Grill, Label: LOC, Score: 0.5772\n",
      "Entity: Lexington, Label: LOC, Score: 0.9314\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9924\n",
      "Entity: Lexington, Label: LOC, Score: 0.9092\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9923\n",
      "Entity: Lexington, Label: LOC, Score: 0.9687\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9667\n",
      "Entity: Washington, Label: LOC, Score: 0.9688\n",
      "Entity: DC, Label: LOC, Score: 0.9802\n",
      "Entity: Washington, Label: LOC, Score: 0.9808\n",
      "Entity: DC, Label: LOC, Score: 0.9879\n",
      "Entity: Washington, Label: LOC, Score: 0.9739\n",
      "Entity: DC, Label: LOC, Score: 0.9905\n",
      "Entity: Washington, Label: LOC, Score: 0.3889\n",
      "Entity: USA, Label: LOC, Score: 0.5551\n",
      "Entity: Van Ness, Label: LOC, Score: 0.6164\n",
      "Entity: Washington D, Label: LOC, Score: 0.9983\n",
      "Entity: C, Label: LOC, Score: 0.9990\n",
      "Entity: Washington, Label: LOC, Score: 0.9978\n",
      "Entity: D, Label: LOC, Score: 0.9986\n",
      "Entity: C, Label: LOC, Score: 0.9988\n"
     ]
    }
   ],
   "source": [
    "for doc_entities in entities:\n",
    "    for entity in doc_entities:\n",
    "        if entity['entity_group'] == \"LOC\":\n",
    "            print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "79179def",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: SOX, Label: ORG, Score: 0.8475\n",
      "Entity: M & A, Label: ORG, Score: 0.8706\n",
      "Entity: Georgetown University, Label: ORG, Score: 0.9939\n",
      "Entity: Audit Services, Label: ORG, Score: 0.8769\n",
      "Entity: Ernst and Young LLP, Label: ORG, Score: 0.9961\n",
      "Entity: Strategy and Transactions, Label: ORG, Score: 0.8156\n",
      "Entity: & A, Label: ORG, Score: 0.8782\n",
      "Entity: Alteryx, Label: ORG, Score: 0.8925\n",
      "Entity: PowerBi, Label: ORG, Score: 0.8365\n",
      "Entity: Technical Accounting and Advisory Services, Label: ORG, Score: 0.9893\n",
      "Entity: FAAS, Label: ORG, Score: 0.9710\n",
      "Entity: Audit & Assurance, Label: ORG, Score: 0.9223\n",
      "Entity: AS, Label: ORG, Score: 0.5883\n",
      "Entity: GAA, Label: ORG, Score: 0.5875\n",
      "Entity: VA, Label: ORG, Score: 0.8660\n",
      "Entity: Marriott, Label: ORG, Score: 0.7979\n",
      "Entity: ##riott, Label: ORG, Score: 0.5960\n",
      "Entity: Fedex Ground, Label: ORG, Score: 0.8165\n",
      "Entity: EZgigs Staffing Service, Label: ORG, Score: 0.9561\n",
      "Entity: Hyatt Regency, Label: ORG, Score: 0.8098\n",
      "Entity: Keeneland Hospitality, Label: ORG, Score: 0.9142\n",
      "Entity: Dupree Catering, Label: ORG, Score: 0.9843\n",
      "Entity: ##ience, Label: ORG, Score: 0.6774\n",
      "Entity: EZ, Label: ORG, Score: 0.7416\n",
      "Entity: ##ND ICHARDSON, Label: ORG, Score: 0.6285\n",
      "Entity: ##GETOW, Label: ORG, Score: 0.5843\n",
      "Entity: M, Label: ORG, Score: 0.5348\n",
      "Entity: ##Donough, Label: ORG, Score: 0.5409\n",
      "Entity: ##f, Label: ORG, Score: 0.7519\n",
      "Entity: ##iness, Label: ORG, Score: 0.8213\n",
      "Entity: ##GE, Label: ORG, Score: 0.6753\n",
      "Entity: GeorgetownS, Label: ORG, Score: 0.8681\n",
      "Entity: ##fC, Label: ORG, Score: 0.6986\n",
      "Entity: ##GE, Label: ORG, Score: 0.5883\n",
      "Entity: GeorgetownC, Label: ORG, Score: 0.8524\n",
      "Entity: ##Arts & Science, Label: ORG, Score: 0.7664\n",
      "Entity: AWS, Label: ORG, Score: 0.5011\n",
      "Entity: Salesforce, Label: ORG, Score: 0.9055\n",
      "Entity: ##A, Label: ORG, Score: 0.6056\n",
      "Entity: ##L, Label: ORG, Score: 0.6379\n",
      "Entity: JIRA, Label: ORG, Score: 0.8310\n",
      "Entity: ETL, Label: ORG, Score: 0.6672\n",
      "Entity: DC, Label: ORG, Score: 0.4081\n",
      "Entity: Georgetown University, Label: ORG, Score: 0.9981\n",
      "Entity: MSBA, Label: ORG, Score: 0.6407\n",
      "Entity: Dickinson College, Label: ORG, Score: 0.9969\n",
      "Entity: University of Bologna, Label: ORG, Score: 0.9712\n",
      "Entity: FINRA, Label: ORG, Score: 0.9380\n",
      "Entity: FINRA, Label: ORG, Score: 0.9751\n",
      "Entity: FINRA, Label: ORG, Score: 0.9750\n",
      "Entity: Georgetown, Label: ORG, Score: 0.7613\n",
      "Entity: FINRA, Label: ORG, Score: 0.9024\n",
      "Entity: MS, Label: ORG, Score: 0.5474\n"
     ]
    }
   ],
   "source": [
    "for doc_entities in entities:\n",
    "    for entity in doc_entities:\n",
    "        if entity['entity_group'] == \"ORG\":\n",
    "            print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "aac51731",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds ={\n",
    "    'PER': .8,\n",
    "    'ORG': .5,\n",
    "    'LOC': .7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "530f5516",
   "metadata": {},
   "outputs": [],
   "source": [
    "redacted_text = resume_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8671619c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m entity_type \u001b[38;5;241m==\u001b[39m entity_type \u001b[38;5;129;01mand\u001b[39;00m score \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m thresholds[entity_type]:\n\u001b[1;32m     17\u001b[0m         entity_text \u001b[38;5;241m=\u001b[39m entity[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m         redacted_text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(re\u001b[38;5;241m.\u001b[39mescape(entity_text), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Redacted]\u001b[39m\u001b[38;5;124m'\u001b[39m, redacted_text)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Redact the email addresses and phone numbers \u001b[39;00m\n\u001b[1;32m     22\u001b[0m redacted_text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS+@\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Redacted Email]\u001b[39m\u001b[38;5;124m'\u001b[39m, redacted_text)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/re/__init__.py:185\u001b[0m, in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags)\u001b[38;5;241m.\u001b[39msub(repl, string, count)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object, got 'list'"
     ]
    }
   ],
   "source": [
    "resumes['clean_text'] = resumes['text'].fillna(\"\").astype(str)\n",
    "resume_text = resumes['clean_text'].tolist()\n",
    "\n",
    "entities = ner_pipeline(resume_text)\n",
    "\n",
    "entities_flatten = [entity for doc_entities in entities for entity in doc_entities]\n",
    "\n",
    "entities_sorted = sorted(entities_flatten, key=lambda x: len(x['word']), reverse=True)\n",
    "\n",
    "redacted_text = resume_text\n",
    "\n",
    "for entity in entities_sorted:\n",
    "    entity_type = entity['entity_group']\n",
    "    score = entity['score']\n",
    "        \n",
    "    if entity_type == entity_type and score >= thresholds[entity_type]:\n",
    "        entity_text = entity['word']\n",
    "        redacted_text = re.sub(re.escape(entity_text), '[Redacted]', redacted_text)\n",
    "\n",
    "\n",
    "# Redact the email addresses and phone numbers \n",
    "redacted_text = re.sub(r'\\S+@\\S+', '[Redacted Email]', redacted_text)\n",
    "redacted_text = re.sub(r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}', '[Redacted Phone]', redacted_text)\n",
    "\n",
    "for doc in redacted_text:\n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "73368b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Redacted]s. Genesis U. Roberto \n",
      "     [Redacted], [Redacted]   \t [Redacted Phone]\t      [Redacted Email] \t             Active [Redacted]PA ([Redacted], [Redacted])\n",
      "\n",
      "Profile: A data driven, results oriented finance and accounting professional with deep experience in financial statements reporting requirement under US [Redacted]P and [Redacted] internal controls. Well-versed in financial statement analysis, [Redacted]&A due diligence reviews and government contracting process with [Redacted]aster’s degree in Business Analysis from [Redacted]. \n",
      "\n",
      "Professional Experience\t\t\t\t\n",
      "[Redacted] and [Redacted], [Redacted]PAs – [Redacted], [Redacted]\t[Redacted]ec 2023 - Present\n",
      "Senior [Redacted]anager, [Redacted]\n",
      "[Redacted]anaged financial audits & reviews for corporate clients in the defense contractors, retail and engineering industry.\n",
      "Supported clients in corporate growth strategy and valuation modeling initiatives, including buy and sell-side advisory services.\n",
      "Evaluated compliance with [Redacted][Redacted] 606, [Redacted][Redacted] 842, and [Redacted][Redacted] 326 for clients, improving financial reporting accuracy.\n",
      "Prepare technical accounting memos and documentation to support accounting conclusions and positions\n",
      "\n",
      "[Redacted] - [Redacted], [Redacted]\tNov 2021 - Jun 2023\n",
      "[Redacted]anager, [Redacted] advisory services\t\n",
      "Led buy and sell side financial due diligence [Redacted]&A deals with focus on manufacturing buy side and bio-tech life sciences sectors. Work entailed information gathering, data room management, facilitate diligence meetings, draft and review tailored due diligence reports specific to key issues such as normalized earnings, achievability of management’s budget, indebtedness considerations, and working capital analysis. \n",
      "[Redacted]anaged a team in preparing management call agendas, performed price volume analysis to address inflationary concerns using [Redacted] and [Redacted].\n",
      "\n",
      "[Redacted]anager, [Redacted] ([Redacted]), [Redacted] \t\n",
      "Fresh start technical accounting advisory support ([Redacted][Redacted] 852 Reorganization) for a large public telecommunication company including [Redacted][Redacted] 842 lease accounting adoption and transition, entailing technical information gathering, design of lease abstraction form and mapping to third party lease software (Visual Lease). \n",
      "[Redacted]losing balance sheet review for a business combination supporting purchaser’s internal audit review \n",
      "Accounting subject matter ability under International Financial Reporting Standards (IFRS) for a [Redacted]anadian client, primarily in expected credit loss methodology; IFRS to US [Redacted]P bridging and technical review of goodwill memos. \n",
      "\n",
      "Grant Thornton LLP - Arlington, [Redacted] \tOct 2018 - Nov 2021\n",
      "Experienced [Redacted]anager, Financial due diligence, [Redacted] advisory services\t\n",
      "[Redacted]oordinated and managed transaction support and financial due diligence for client industries in the telecommunications, manufacturing, government, defense & trade, and IT industries. \n",
      "Performed financial analysis and modelling of [Redacted]&A opportunities, including analyzing and explaining historical and projected financial information, proforma financial models and key assumptions. \n",
      "\n",
      "Advisory Experienced [Redacted]anager, Grant Thornton Public Sector advisory services\t\n",
      "Project 1: [Redacted]eputy Account Lead/ Audit & Project [Redacted]anager, [Redacted]ontractors for PBG[Redacted] federal contract  \t\n",
      "[Redacted]anaged seven (7) contract task orders under a five-year $12m contract award entailing due diligence historical reviews of trusteed single-employer pension plans for completeness, accuracy and proper valuation of plan assets and liabilities.\n",
      "[Redacted]anaged a staff of 15-20 on all areas of client delivery, audit technical reviews and project management \n",
      "Successfully advised client management of their implementation of Team[Redacted]ate audit management system \n",
      "Served as audit technical reviewer over three contract task orders with total award value of $21m \n",
      "\n",
      "Project 2:  Business development key initiatives for Grant Thornton Public Sector LLP\t\n",
      "Led technical proposal writing and managed consolidation of proposal package to win a 5-year sole source contract award for data extraction and analysis using A[Redacted]L based computer-assisted auditing techniques.\n",
      "[Redacted]eveloped thought leadership, detailed stakeholder mapping analysis, and maintained client relations for a $20m award\n",
      "[Redacted]anaged past performance and teaming partnership negotiations for the [Redacted]ept. of Housing and Urban [Redacted]evelopment (HU[Redacted]) Strategic [Redacted]anagement and [Redacted]onsulting Services resulting in a $180m 5-year Blanket Purchase award win. \n",
      "Served as co-technical lead/ writer for a [Redacted]FPB IT Project [Redacted]anagement support services 5-year contract award of $19m.          \n",
      "[Redacted]ynamic, organized, and meticulous leader supporting successful bid submissions for 15+ government solicitations for [Redacted]OJ, [Redacted]FPB, F[Redacted]I[Redacted], HU[Redacted], SE[Redacted], PBG[Redacted] & various state, and local governments. \n",
      "\n",
      "\n",
      "\n",
      "Republic of Palau National Government, Office of Public Auditor - Koror, Palau \t[Redacted]ec 2016 - Sept 2018\n",
      "Audit [Redacted]anager\t\n",
      "Refined existing process on monitoring outsourced National government single audits and its 6 component units. \n",
      "[Redacted]anaged procurement and vendor selection process for outsourced national and state financial statement audits (cash basis) and single audit (accrual)\n",
      "Initiated pilot efforts and worked as champion on employing new audit management system Teammate. \n",
      "Heavily involved in the drafting and publishing of firm wide SOPs, manuals, and policy mandate on financial audits following regulatory mandates.\n",
      "[Redacted]eveloped structured program relating to staff development in technical expertise and business acumen.\n",
      "Advised on national project relating to local governance strengthening project with United Nations [Redacted]evelopment Program and [Redacted]inistry of State, resulting in training frameworks, local governance SOPs, and personnel competency framework.\n",
      "\n",
      "Grant Thornton, LLP - Portland, OR\t Aug 2015 - [Redacted]ec 2016\n",
      "Audit Senior III, Assurance services\t\n",
      "[Redacted]anaged audit and review engagements for publicly traded clients and private clients in the manufacturing, professional consulting, real estate, employee benefit plans and wholesale industries.\n",
      "Led teams remotely from shared service centers in Bangalore, India on audit engagements.\n",
      "Involved with and preparing technical and consultation memos over complex auditing of estimates including goodwill impairment analysis, business combinations, debt restructuring, and fair value valuations..\n",
      "Understanding and experience with US [Redacted]P, US [Redacted]S, P[Redacted]AOB auditing standards, Sarbanes-Oxley ([Redacted]) compliance control testing, Internal controls over Financial Reporting (I[Redacted]FR) audits.\n",
      "Trained junior resources on technical execution and conducted staff performance evaluations contribution to overall staff retention and continuity on engagements.\n",
      "[Redacted]ollaborated closely with partners and senior leadership on budgeting, staffing, and proposed client fees.\n",
      "\n",
      "N&K [Redacted]PAs, Inc. - Honolulu, HI \tOct 2011 - Jul 2015\n",
      "Audit Supervisor, Assurance services\t\t\n",
      "Assumed full responsibility for planning and performing audit and review engagements for various client industries, including government, construction, employee benefit plans, low-income housing, and not-for-profit organizations.\n",
      "Organized, coordinate, and supervised large engagements while taking proactive measures to solve complex issues, with in-depth understanding of general ledger, journal entries, accounting system flows and efficient ways to perform audit risk planning and testing of controls and substantive work.\n",
      "Independently planned and supervised tests of controls over various clients’ accounting systems.\n",
      "Performed single audits in compliance with generally accepted government auditing standard including complex government clients (State [Redacted]ept. of Education, State [Redacted]ept. of Human Services and [Redacted]ounty of [Redacted]aui.)\n",
      "\n",
      "Palau Office of Public Auditor - Koror, Palau \tAug 2010 - Aug 2011\n",
      "Junior Auditor, Assurance services\n",
      "Issued 5-year State government performance audit report under Gen. Accepted Govt. Auditing Standards (GAG[Redacted]).\n",
      "\n",
      "\n",
      "Education\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "[Redacted]aster of Science in Business Analytics, [Redacted], expected graduation [Redacted]ec. 2024\n",
      "Bachelor of Science in Accounting, Brigham Young University-Hawaii\n",
      "\n",
      "\t\t\n",
      "[Redacted]ertification\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "[Redacted]ertified Public Accountant (HI, [Redacted], [Redacted])\n",
      "State of [Redacted]aryland # 45308 (exp. Jun. 2025), State of [Redacted] # 51887 (exp. Jun. 2024),\n",
      "[Redacted]ertified Government Financial [Redacted]anager ([Redacted]GF[Redacted]), [Redacted][Redacted], 2019 (Inactive)\n",
      "\n",
      "\n",
      "[Redacted]ore [Redacted]ompetencies\t\t\t\t\t\t\t\t\t\t\t\n",
      "Financial statement reporting (balance sheet, income statement, statement of cash flows, treasury, accounts payable, accounts receivable, general ledger, journal entries, technical accounting, [Redacted][Redacted] 606, [Redacted][Redacted] 842, [Redacted][Redacted] 805) \n",
      "Audit and internal controls ([Redacted] compliance, internal controls over financial reporting, US [Redacted]S, U.S Yellow Book standards, internal audit reviews, audit risk assessment, auditing estimates)\n",
      "Financial due diligence (quality of earnings report, working capital analysis, net debt, finance KPI metrics)\n",
      "[Redacted]odeling and analysis (advanced excel, Tableau, R programming, Blackline, Visual Lease, I[Redacted]EA, A[Redacted]L) \n",
      "[Redacted]\n",
      "503 [Redacted], Apt #7    | [Redacted Phone]    | [Redacted Email]\n",
      "[Redacted], [Redacted]         \n",
      "[Redacted] [Redacted] [Redacted] Bar Supervisor\n",
      "[Redacted]ecember 7, 2019-October 31 2021\n",
      "[Redacted] [Redacted]                                                                        [Redacted], [Redacted]\n",
      "\n",
      "Provided food and beverage service to several guests, Performed several management duties such as Purchasing, Inventory, [Redacted]enu [Redacted]reation, Pricing, etc.\n",
      "Awarded Associate of the [Redacted]onth for July 2020\n",
      "Awarded Front of House Associate of the Year for 2020\n",
      "\n",
      "Office Admin                                                                                 \n",
      "September 2018-September 2019\n",
      "[Redacted]                                                                                [Redacted], [Redacted]\n",
      "\n",
      "[Redacted]ajor Accomplishments\n",
      "\n",
      "\n",
      "Promoted from Package Handler to Office Admin\n",
      "\n",
      "Event Bartender                                                                                \n",
      "October 2018-[Redacted]arch 2020\n",
      "[Redacted]                                                                  [Redacted], [Redacted] \n",
      "\n",
      "[Redacted]ajor Events\n",
      "\n",
      "\n",
      "[Redacted] concert at [Redacted]p Arena\n",
      "Harrodsburg Oktoberfest\n",
      "\n",
      "Event and Restaurant Bartender                                                \n",
      "November 2018-[Redacted]arch 2020\n",
      "[Redacted] [Redacted].                                                              [Redacted], [Redacted]\n",
      "\n",
      "Provided drink service to several upscale events along with working in the Hyttops Sports Bar as well as briefly in [Redacted] and Grill making sure to provide quality customer service in any atmosphere. Also performed several inventory and set up tasks as well as Serving as a banquet captain for several events.\n",
      "\n",
      "[Redacted]oncessions and [Redacted]ining Hall Bartender\n",
      "April 4th, 2018-[Redacted]arch 2020\n",
      "[Redacted]                                                                    [Redacted], [Redacted]\n",
      "\n",
      "Provided drink service to thousands of guests, making sure bars were stocked and organized. [Redacted]oved to different bars and register locations each day, and performed inventory tasks on liquor, mixers, and produce.  Also worked not only during the meet, but for the horse auctions as well.\n",
      "\n",
      "Event Bartender\n",
      "[Redacted]arch 23, 2019-Present\n",
      "[Redacted]                                                                             [Redacted], [Redacted]\n",
      "\n",
      "Provided drink service to guests, as well as setup and teardown of different bars at various locations around the state, such as Buffalo Trace, Limestone Hall, private farms, etc.\n",
      "\n",
      "Office Admin                                                                                 \n",
      "September 2018-September 2019\n",
      "[Redacted]                                                                                [Redacted], [Redacted]\n",
      "\n",
      "[Redacted]ajor Accomplishments\n",
      "\n",
      "\n",
      "Promoted from Package Handler to Office Admin\n",
      "\n",
      "Night [Redacted]anager                                                                                        \n",
      "September 2014-August 2018\n",
      "Broadmoor Heights [Redacted]ar [Redacted]are And [Redacted]onvenience                             Loveland, [Redacted]O             \n",
      "\n",
      "[Redacted]ajor Accomplishments\n",
      "\n",
      "\n",
      "Led a sales initiative to find lower prices on products raising the profit margin by 60%\n",
      "Re-wrote checklists, inventory, and guide sheets to better help new employees fulfill tasks\n",
      "Expanded the regular customer base by a large margin through leading with new standards of customer service and contributing to a friendly and helpful atmosphere\n",
      "[Redacted]ontributed to lowering the turnover rate by listening to employees concerns and helping to communicate complaints to the owner and to each other, effectively reducing the need for termination and resignation\n",
      "\n",
      "Roof Repairman                                                                                               \n",
      "[Redacted]ay 2011- August 2018\n",
      "Saville Roofing \t\t\t\t\t\t\t        Loveland, [Redacted]O\n",
      "\n",
      "Specialized in leak repairs and large maintenance projects on commercial buildings and condominium associations; provided quality customer service to customers; gave detailed explanations of what problems were present\n",
      "\t\n",
      "[Redacted]ajor Accomplishments\n",
      "\n",
      "\n",
      "[Redacted]ompleted a large scale roofing and metal capping maintenance project for a condominium association in Boulder, [Redacted]olorado involving detailed EP[Redacted][Redacted] repair and metal work, along with use of chemicals and adhesives\n",
      "[Redacted]ompleted a large scale waterproofing project in Boulder, [Redacted]olorado involving detailed work with chemicals, adhesives, and polyurethane deck systems, in addition to calmly settling complaints by residents with quality customer service skills\n",
      "\n",
      "[Redacted]iploma\n",
      "Loveland [Redacted]lassical Schools, Loveland, [Redacted]O                                                                    2011-2015\n",
      "\n",
      "Graduate\n",
      "[Redacted] Bartending School, [Redacted], KY                                                                          2018\n",
      "[Redacted] R\n",
      "[Redacted][Redacted]ON[Redacted] I[Redacted]HAR[Redacted]SON\n",
      "[Redacted Email] ▪ [Redacted Phone] ▪ https://www.linkedin.com/in/dezrich2/\n",
      "E[Redacted]U[Redacted]ATION\n",
      "GEORGETOWNUNIVERSITY,[Redacted]c[Redacted]onoughSchoolofBusiness [Redacted],[Redacted]\n",
      "[Redacted]asterofScienceinBusinessAnalytics [Redacted]ecember2024\n",
      "GEORGETOWNUNIVERSITY,[Redacted]choolof[Redacted]ontinuingStudies [Redacted],[Redacted]\n",
      "[Redacted]asterofProfessionalStudiesinTechnology[Redacted]anagement,EnterpriseAnalytics&[Redacted]odernization [Redacted]ecember2019\n",
      "GEORGETOWNUNIVERSITY,[Redacted]ollegeofArts&Science [Redacted],[Redacted]\n",
      "BachelorofScienceinPsychology&Sociology;[Redacted]inor:Theology [Redacted]ay2016\n",
      "TE[Redacted]HNI[Redacted]ALSKILLS&[Redacted]ERTIFI[Redacted]ATIONS\n",
      "▪ ProgrammingSkills:SQL,Java,Python(Numpy,matplotlib,pandas,sklearn,vega-altai,plotly.pyr),R(ggplot2,dplyr,tidyr),Excel\n",
      "▪ [Redacted]ertifications:[Redacted]ataProgramming,[Redacted]ataScientist(Python,R,and[Redacted]ataVisualization),[Redacted]AcademyGraduate-[Redacted]\n",
      "Academy[Redacted]loudFoundations\n",
      "▪ AdditionalSkills:Excel(PivotTables),[Redacted][Redacted]R[Redacted],PredictiveAnalytics(dataminingandmodeling,database\n",
      "management),[Redacted]achineLearning,[Redacted],[Redacted](Extract/Transform/Load),[Redacted]icrosoftSuites,[Redacted]icrosoftPowerQuery,Visual\n",
      "Studio,SQLServer[Redacted]anagementStudio,Slideshare,PowerPoint,Audit[Redacted]ompliance\n",
      "RELE[Redacted]NTEXPERIEN[Redacted]E\n",
      "GEORGETOWNUNIVERSITY,OFFI[Redacted]EOFA[Redacted][Redacted]N[Redacted]E[Redacted]ENT [Redacted],[Redacted],USA\n",
      "Assistant[Redacted]irectorfor[Redacted]ataAnalytics&Strategy(AnnualGiving) August2022–[Redacted]urrent\n",
      "▪ Performongoinganalysisandreportingforfundraisinginitiativesacross29VarsityProgramsandAnnualGivingteams\n",
      "spanning5businessunits.\n",
      "▪ [Redacted]rivetheenhancementandoptimizationoffundraisingsystems,processes,reports,dashboards,anddatavisualizationtools\n",
      "utilizingExcel,[Redacted],Tableau,andR(ggplot2).\n",
      "▪ EstablishcomprehensivepoliciesandprocedurestoensureprioritizedandeffectivefulfillmentofAnnualGiving'sreportingand\n",
      "analyticsrequirements.\n",
      "UTSOUTHWESTERN[Redacted]E[Redacted]I[Redacted]AL[Redacted]ENTER,INFOR[Redacted]ATIONRESOUR[Redacted]ES [Redacted]allas,Tx,USA\n",
      "Senior[Redacted]ataAnalyst,[Redacted]iversity,Equity,Inclusion(Lead[Redacted]ept.Analyst) [Redacted]ay2023-July2023\n",
      "▪ Leddatasteward,ensuring100%dataaccuracyandmitigatingaudit/datarisks.\n",
      "▪ Efficientlymanagedanddeliveredprojects,maintainingadherencetotimelinesanddeliverables,resultingina15%increasein\n",
      "projectcompletionrate.Fosteredtransparentcommunicationthroughregularstatusreportstodepartmentalleadership.\n",
      "▪ [Redacted]oordinateddatasubmissiontothefederalgovernment,regulatoryagencies,andfundingorganizationswith100%compliance.\n",
      "Streamlined[Redacted]EIdatamodeling,mapping,andarchitectureefforts,reducingrequestlifecycleby30%.\n",
      "GEORGETOWNUNIVERSITY,OFFI[Redacted]EOFA[Redacted][Redacted]N[Redacted]E[Redacted]ENT [Redacted],[Redacted],USA\n",
      "Senior[Redacted]ataAnalyst,[Redacted]R[Redacted]Group[Redacted]oding([Redacted]onstituentRecords[Redacted]epartment) [Redacted]ay2022–November2022\n",
      "▪ ServedasthekeypointofcontactbetweenUniversityEventStaffand[Redacted]vent,overseeinghundredsofeventsthatcollected\n",
      "millionsofdatapointsfromconstituentsannually.\n",
      "▪ RegularlymanagedAPIintegrationsbetweeni-modules,[Redacted]vent,and[Redacted],ensuringaseamlessflowofconstituentdata.\n",
      "▪ ImplementedefficientdataorganizationandcleansingprocessesusingSQL,[Redacted],and[Redacted]ulesoft's[Redacted]ataLoaderfor\n",
      "signatureevents\n",
      "[Redacted]ataAnalyst,[Redacted]R[Redacted]([Redacted]onstituentRecords[Redacted]epartment) July2018–April2022\n",
      "▪ Providedefficienttroubleshootingandresolutionofsystemanddataintegrityinquiriesacrossmultiplechannelsincluding\n",
      "G-chat,Email,Freshservice,[Redacted][Redacted]R[Redacted],andphone.\n",
      "▪ Ledthetrainingandmanagementofateamof5employeesforroutinedataintegrityprojectswithin[Redacted][Redacted]R[Redacted],ensuring\n",
      "accurateandreliabledata.\n",
      "▪ Successfullyexecutedlarge-scaledataintegrityprojectsutilizing[Redacted]ulesoft's[Redacted]ataLoadertool,impactingthousandsof\n",
      "constituentrecords\n",
      "GEORGETOWNUNIVERSITYLAW[Redacted]ENTER,INFOR[Redacted]ATIONSYSTE[Redacted]TE[Redacted]HNOLOGY [Redacted],[Redacted],USA\n",
      "Tier1Help[Redacted]eskTechnician August2017–February2020\n",
      "[Redacted]. [Redacted]\n",
      "Van Ness, [Redacted].[Redacted].\n",
      "[Redacted Phone]\n",
      "[Redacted Email] \n",
      "Education \n",
      "[Redacted] - August 2023 – [Redacted]ecember 2024\n",
      "[Redacted]aster of Science Business Analytics – [Redacted] candidate\n",
      "Peer-Elected [Redacted]lass Representative \n",
      "[Redacted] - August 2014 – September 2018\n",
      "Economics & Political Science [Redacted]ouble [Redacted]ajor\n",
      "Varsity Tennis [Redacted]aptain \n",
      "[Redacted] - August 2016\n",
      "Skills\n",
      "Professional Experience\n",
      "[Redacted], [Redacted], [Redacted].[Redacted].\tJune 2020 – Present \n",
      "Senior Analyst, [Redacted]arket Regulation\tSeptember 2022 – Present \n",
      "Earned top 10% of performance of analysts for past two years.\n",
      "Led team in research implementing PostgreSQL and NoSQL queries for large data pulls.\n",
      "Spearheaded new analytical approaches to financial workflow with tools such as R & Python for model development.\n",
      "[Redacted]eveloped working predictive modeling schemas for senior staff using statistical analysis.\n",
      "Leveraged skills in platforms like Python, R, Power BI, Tableau and SQL accompanied with strong statistical background in financial markets.\n",
      "Built the Security-Based Swap training manual deck & produced the recorded info session for all of [Redacted]. \n",
      "Selected for the [Redacted]’s first [Redacted] Advanced Analytics Program as one of the most junior staff awarded opportunity.\n",
      "Incorporated statistical analytics to assist in creating a NPL tool to analyze financial documents language to minimize time on manual analysis.\n",
      "Produced unsupervised and supervised models to perform analysis for Security-Based Swaps trade patterns.\n",
      "Improved [Redacted] platforms with [Redacted]ata Scientists for higher accuracy and efficiency. \n",
      "[Redacted]anaged process of re-engineering supervisory reviews through advanced analytic tools for senior staff.\n",
      "Implements advanced analytics to assist senior staff with maximizing efficiencies in daily workloads and trade pattern creations.\n",
      "Presented visualization case work using Power BI & Tableau to senior leadership.\n",
      "Persuaded senior staff to allow for statistical analytics tools like R.\n",
      "[Redacted]entored over 20 junior & senior staff members on improving processes with analytical tools for financial reviews.\n",
      "[Redacted]anaged junior staff with day-to-day workload while teaching the staff how to use advanced analytics.\n",
      "Analyst, [Redacted]arket Regulation\tJune 2021-September 2022\n",
      "[Redacted]reated macroeconomic models for newly implemented [Redacted] Rule 2232 and [Redacted]RB Rule G-15.\n",
      "[Redacted]entored junior staff with creating macro models, synthesizing responses from [Redacted] member firms.\n",
      "Won the Regulator Scholarship for continued financial learning based on individual performance.\n",
      "Received six internal awards for expertise in [Redacted]unicipal and [Redacted]orporate Bond analysis as an analyst.\n",
      "Associate Analyst, [Redacted]arket Regulation\tJune 2020 – June 2021\n",
      "[Redacted]reated macroeconomic models to quantify business models of selected firms for [Redacted] Rule 2232.\n",
      "             BNY [Redacted]ellon, Pittsburgh, PA\t\t\t\t\t\t                 September 2019 – June 2020\n",
      "[Redacted]orporate Trust Associate\n",
      "Leader & instructor of the Bloomberg software for the [Redacted]orporate Trust Team.\n",
      "LendingHome, Internship, Pittsburgh, PA\n",
      "Funding Specialist & Post [Redacted]losing [Redacted]ember\t[Redacted]arch 2019 – August 2019\n",
      "Reviewed closing documents to ensure precise execution for funding staff.\n",
      "              Veraction/Trax, Junior Business Analyst, [Redacted]emphis, TN\t                                                      June 2016 - August 2016\n",
      "Led the creation, development, and implementation of Request For Proposal (RFP) database.\n"
     ]
    }
   ],
   "source": [
    "# Assuming `resume_text` is a list of text documents\n",
    "resumes['clean_text'] = resumes['text'].fillna(\"\").astype(str)\n",
    "resume_text = resumes['clean_text'].tolist()\n",
    "\n",
    "# Process the resumes to extract entities\n",
    "entities = ner_pipeline(resume_text)\n",
    "\n",
    "# Flatten the list of entities\n",
    "entities_flatten = [entity for doc_entities in entities for entity in doc_entities]\n",
    "\n",
    "# Sort the entities by the length of the word\n",
    "entities_sorted = sorted(entities_flatten, key=lambda x: len(x['word']), reverse=True)\n",
    "\n",
    "# Initialize redacted_text as a copy of the original resume_text\n",
    "redacted_text = resume_text\n",
    "\n",
    "# Create a thresholds dictionary for entity redaction\n",
    "thresholds = {\n",
    "    'PER': .8,\n",
    "    'ORG': .5,\n",
    "    'LOC': .7\n",
    "}\n",
    "\n",
    "# Iterate over sorted entities for redaction\n",
    "for entity in entities_sorted:\n",
    "    entity_type = entity['entity_group']\n",
    "    score = entity['score']\n",
    "    \n",
    "    # Ensure entity_type exists in thresholds\n",
    "    if entity_type in thresholds and score >= thresholds[entity_type]:\n",
    "        entity_text = entity['word']\n",
    "        \n",
    "        # Redact the entity from each document in redacted_text\n",
    "        redacted_text = [re.sub(re.escape(entity_text), '[Redacted]', doc) for doc in redacted_text]\n",
    "\n",
    "# Redact the email addresses and phone numbers\n",
    "redacted_text = [re.sub(r'\\S+@\\S+', '[Redacted Email]', doc) for doc in redacted_text]\n",
    "redacted_text = [re.sub(r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}', '[Redacted Phone]', doc) for doc in redacted_text]\n",
    "\n",
    "# Optional: Print the redacted documents\n",
    "for doc in redacted_text:\n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d39b0815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(redacted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66894ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#email_data = pd.read_csv('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d9886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#email_data = pd.DataFrame(email_data)\n",
    "\n",
    "#email_data.to_csv('emails.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de2d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#email_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85332175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = Dataset.from_pandas(email_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#email_data = Dataset.from_pandas(email_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
