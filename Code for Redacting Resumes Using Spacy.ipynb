{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35d756c",
   "metadata": {},
   "source": [
    "# Code for Redacting Resumes Using Spacy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16d73e",
   "metadata": {},
   "source": [
    "# Redacted Dataset name = 'spacy_redacted_documents_with_id_and_category.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c2dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "#from docx import Document\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import pdfplumber\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from textblob import TextBlob\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import os\n",
    "import json\n",
    "#from docx import Document\n",
    "import pdfplumber\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "#spacy.cli.download(\"en_core_web_sm\")\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "from plotly.offline import plot\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd4cfee",
   "metadata": {},
   "source": [
    "## spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a143e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = pd.read_csv('Resumes_with_PII_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust this number to scale the size of the corpus\n",
    "resumes = resumes.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0f73cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54094559",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddeacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_pipeline(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [{'word': ent.text, 'entity': ent.label_, 'score': ent.kb_id_} for ent in doc.ents]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624c1de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_documents_spacy_corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fff2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in resumes.iterrows():\n",
    "    document_ID = row['ID']\n",
    "    document_Category = row['Category']\n",
    "    document_text = row['text']\n",
    "\n",
    "    entities = ner_pipeline(document_text)\n",
    "\n",
    "    document_data = {\n",
    "        'ID': document_ID,\n",
    "        'Category': document_Category,\n",
    "        'text': document_text,\n",
    "        'entities': entities  \n",
    "    }\n",
    "\n",
    "    structured_documents_spacy_corpus.append(document_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad37c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in structured_documents_spacy_corpus:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb7985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total documents in structured_documents: {len(structured_documents_spacy_corpus)}\")\n",
    "for doc in structured_documents_spacy_corpus:\n",
    "    print(f\"ID: {doc['ID']}, Entities Count: {len(doc['entities'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1cacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_corpus_redacted_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7780427",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "    'PERSON': 0.75,\n",
    "    'ORG': 0.99,\n",
    "    'GPE': 0.99, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff07fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, document in enumerate(structured_documents_spacy_corpus):\n",
    "    original_text = document['text']\n",
    "    redacted_text = original_text\n",
    "    entities_sorted = sorted(document.get('entities', []), key=lambda x: len(x['word']), reverse=True)\n",
    "\n",
    "    print(f\"Processing Document {i + 1}: {document['ID']}\")\n",
    "    print(f\"Entities from document {i + 1}:\")\n",
    "    \n",
    "    for entity in entities_sorted:\n",
    "        entity_text = entity['word']\n",
    "        entity_label = entity['entity']\n",
    "        score = entity.get('score', 1.0)\n",
    "        \n",
    "       #Makes sure score is treated as a float\n",
    "    score = entity.get('score')\n",
    "    if isinstance(score, str):\n",
    "        try:\n",
    "            score = float(score)\n",
    "        except ValueError:\n",
    "            score = 0.0  #default if conversion fails\n",
    "    else:\n",
    "        score = score if score is not None else 1.0  #fallback to 1.0 if score no score\n",
    " \n",
    "    \n",
    "        if entity_label in thresholds and score >= thresholds[entity_label]:\n",
    "            print(f\"Entity: {entity['word']}, Label: {entity['entity']}, Score: {entity['score']:.4f}\")\n",
    "\n",
    "    for entity in entities_sorted:\n",
    "        entity_text = entity['word']\n",
    "        redacted_text = re.sub(re.escape(entity_text), '[Redacted]', redacted_text)\n",
    "\n",
    "    redacted_text = re.sub(r'\\S+@\\S+', '[Redacted Email]', redacted_text)\n",
    "    redacted_text = re.sub(r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}', '[Redacted Phone]', redacted_text)\n",
    "    redacted_text = re.sub(r'\\b(?:https?://)?(?:www\\.)?linkedin\\.com/in/[a-zA-Z0-9._-]+\\b', '[Redacted Website]', redacted_text)\n",
    "    \n",
    "    \n",
    "    spacy_corpus_redacted_text.append({\n",
    "        'ID': document['ID'],  #use document instead of row be wary of rerunning code multiple times, dataset builds upon itsself\n",
    "        'Category': document['Category'],    \n",
    "        'Redacted Text': redacted_text  \n",
    "    \n",
    "    #spacy_corpus_redacted_text.append({\n",
    "       # 'ID': row['ID'],                #row instead of document to build seperate columns in output\n",
    "       # 'Category': row['Category'],    \n",
    "       # 'Redacted Text': redacted_text   \n",
    "    })\n",
    "\n",
    "#list to a df\n",
    "spacy_redacted_resumes = pd.DataFrame(spacy_corpus_redacted_text)\n",
    "\n",
    "#Save to CSV\n",
    "spacy_redacted_resumes.to_csv('spacy_redacted_documents_with_id_and_category.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of redacted documents: {len(spacy_corpus_redacted_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734f7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in enumerate(spacy_corpus_redacted_text):\n",
    "    print(f\"Redacted Text for Document {i + 1}:\")\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7213c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a1429f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if document_index < len(spacy_corpus_redacted_text):\n",
    "    print(f\"Redacted Text for Document 1:\")\n",
    "    print(spacy_corpus_redacted_text[document_index])\n",
    "else:\n",
    "    print(\"Document does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ec515",
   "metadata": {},
   "outputs": [],
   "source": [
    "## spacy\n",
    "\n",
    "resumes = pd.read_csv('Resumes_with_PII_updated.csv')\n",
    "\n",
    "#adjust this number to scale the size of the corpus\n",
    "resumes = resumes.head(2000)\n",
    "\n",
    "resumes\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def ner_pipeline(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [{'word': ent.text, 'entity': ent.label_, 'score': ent.kb_id_} for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "structured_documents_spacy_corpus = []\n",
    "\n",
    "for index, row in resumes.iterrows():\n",
    "    document_ID = row['ID']\n",
    "    document_Category = row['Category']\n",
    "    document_text = row['text']\n",
    "\n",
    "    entities = ner_pipeline(document_text)\n",
    "\n",
    "    document_data = {\n",
    "        'ID': document_ID,\n",
    "        'Category': document_Category,\n",
    "        'text': document_text,\n",
    "        'entities': entities  \n",
    "    }\n",
    "\n",
    "    structured_documents_spacy_corpus.append(document_data)\n",
    "\n",
    "for doc in structured_documents_spacy_corpus:\n",
    "    print(doc)\n",
    "\n",
    "print(f\"Total documents in structured_documents: {len(structured_documents_spacy_corpus)}\")\n",
    "for doc in structured_documents_spacy_corpus:\n",
    "    print(f\"ID: {doc['ID']}, Entities Count: {len(doc['entities'])}\")\n",
    "\n",
    "\n",
    "spacy_corpus_redacted_text = []\n",
    "\n",
    "thresholds = {\n",
    "    'PERSON': 0.75,\n",
    "    'ORG': 0.99,\n",
    "    'GPE': 0.99, \n",
    "}\n",
    "\n",
    "for i, document in enumerate(structured_documents_spacy_corpus):\n",
    "    original_text = document['text']\n",
    "    redacted_text = original_text\n",
    "    entities_sorted = sorted(document.get('entities', []), key=lambda x: len(x['word']), reverse=True)\n",
    "\n",
    "    print(f\"Processing Document {i + 1}: {document['ID']}\")\n",
    "    print(f\"Entities from document {i + 1}:\")\n",
    "    \n",
    "    for entity in entities_sorted:\n",
    "        entity_text = entity['word']\n",
    "        entity_label = entity['entity']\n",
    "        score = entity.get('score', 1.0)\n",
    "        \n",
    "       #Makes sure score is treated as a float\n",
    "    score = entity.get('score')\n",
    "    if isinstance(score, str):\n",
    "        try:\n",
    "            score = float(score)\n",
    "        except ValueError:\n",
    "            score = 0.0  #default if conversion fails\n",
    "    else:\n",
    "        score = score if score is not None else 1.0  #fallback to 1.0 if score no score\n",
    " \n",
    "    \n",
    "        if entity_label in thresholds and score >= thresholds[entity_label]:\n",
    "            print(f\"Entity: {entity['word']}, Label: {entity['entity']}, Score: {entity['score']:.4f}\")\n",
    "\n",
    "    for entity in entities_sorted:\n",
    "        entity_text = entity['word']\n",
    "        redacted_text = re.sub(re.escape(entity_text), '[Redacted]', redacted_text)\n",
    "\n",
    "    redacted_text = re.sub(r'\\S+@\\S+', '[Redacted Email]', redacted_text)\n",
    "    redacted_text = re.sub(r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}', '[Redacted Phone]', redacted_text)\n",
    "    redacted_text = re.sub(r'\\b(?:https?://)?(?:www\\.)?linkedin\\.com/in/[a-zA-Z0-9._-]+\\b', '[Redacted Website]', redacted_text)\n",
    "    \n",
    "    \n",
    "    spacy_corpus_redacted_text.append({\n",
    "        'ID': document['ID'],  #use document instead of row be wary of rerunning code multiple times, dataset builds upon itsself\n",
    "        'Category': document['Category'],    \n",
    "        'Redacted Text': redacted_text  \n",
    "    \n",
    "    #spacy_corpus_redacted_text.append({\n",
    "       # 'ID': row['ID'],                #row instead of document to build seperate columns in output\n",
    "       # 'Category': row['Category'],    \n",
    "       # 'Redacted Text': redacted_text   \n",
    "    })\n",
    "\n",
    "#list to a df\n",
    "spacy_redacted_resumes = pd.DataFrame(spacy_corpus_redacted_text)\n",
    "\n",
    "#Save to CSV\n",
    "spacy_redacted_resumes.to_csv('spacy_redacted_documents_with_id_and_category.csv', index=False)\n",
    "\n",
    "\n",
    "print(f\"Total number of redacted documents: {len(spacy_corpus_redacted_text)}\")\n",
    "\n",
    "for i, text in enumerate(spacy_corpus_redacted_text):\n",
    "    print(f\"Redacted Text for Document {i + 1}:\")\n",
    "    print(text)\n",
    "\n",
    "document_index = 0\n",
    "\n",
    "if document_index < len(spacy_corpus_redacted_text):\n",
    "    print(f\"Redacted Text for Document 1:\")\n",
    "    print(spacy_corpus_redacted_text[document_index])\n",
    "else:\n",
    "    print(\"Document does not exist.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
