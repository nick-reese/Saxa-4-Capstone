{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74182c4d",
   "metadata": {},
   "source": [
    "# GENESIS' ORIGINAL CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71e8a23",
   "metadata": {},
   "source": [
    "# OBJECTIVE: (TO MY BEST UNDERSTANDING)\n",
    "1. Build a Recommender System\n",
    "- Recommender system for matching job descriptions to resumes\n",
    "- recommdner system that suggests jobs to candidates based on resumes\n",
    "- build recommender system for matching job descriptions for gov databases\n",
    "2. Do something with government data\n",
    "3. Build an app\n",
    "\n",
    "\n",
    "Key Methods:\n",
    "- embedding-based recommendations\n",
    "- fine-tuned transformer model\n",
    "\n",
    "## code reactions\n",
    "\n",
    "- embedding models review needed\n",
    "- review langchain embeddings library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239c18ea",
   "metadata": {},
   "source": [
    "# Dez Next Steps\n",
    "\n",
    "1. Reproduce and run Genesis code with redacted pii data\n",
    "2. Add additional LLMs\n",
    "3. Figure Out How to make the prompt engineering run quicker, maybe do 1 resume at a time then slowly increase the dataset size\n",
    "4. Figure Out How difficult is it to get api access to the suggested prompt engineering models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d15f74",
   "metadata": {
    "id": "19d15f74"
   },
   "source": [
    "Scraped Resumes and Prompt Enegineering (GR Version)\n",
    "###LLMs used: GPT4, Cohere and Llama 2\n",
    "###Date: 10/30/2024\n",
    "###Saxa 4#\n",
    "\n",
    "**Data source:**  Used \"modified_file 1.csv” which is the 2,483 resumes that was scraped online. This file was cleaned up into a “more_resume.json” fine. I used this file as a case study for prompt engineering.\n",
    "o\tNote: This code does NOT incorporate PII identification and redaction, which is Dezmond’s code.\n",
    "\n",
    "\n",
    "**Key Highlights of\tPrompt engineering steps:**\n",
    "\n",
    "*Step 1.* --> Embedding: Used Hugging Face \"all-mpnet-base-v2\" as a pre-trained sentence transformer base model designed for generating sentence embeddings (numerical represetnations of sentences that capture semantics (i.e finance, HR, technology etc).\n",
    "\n",
    "*Step 2* -->Prompt Engineering- started shell of code, but did not get code to run as step 1 above took 2+ hours and was still running.\n",
    "\n",
    "*   Prompt Engineering 1: Open AI's GPT 4\n",
    "      -  Updated code to call GR's specific API\n",
    "      - Updated query prompts for resumes, but did not see output yet\n",
    "*   Prompt Engineering 2:  Cohere - need to add in Specific API\n",
    "*   Prompt Engineering 3:  Llama 2- Requested user access request to Meta via Hugging Face, awaiting access approval\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f6574",
   "metadata": {
    "id": "be9f6574"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VIOtS5IW8r0w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIOtS5IW8r0w",
    "outputId": "63e1f7be-0d6d-43d6-80c6-fc1a7948d08c"
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install python-docx==1.1.0\n",
    "!pip install pdfplumber==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e171d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d46e171d",
    "outputId": "46ece2c0-b40b-42cd-f25f-c4e929ea9e02"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "from docx import Document\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import pdfplumber\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from textblob import TextBlob\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wUfmuuT4_-Wv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wUfmuuT4_-Wv",
    "outputId": "b55ba029-69d7-4091-f0a3-3d6766cb9c34"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ca3b6",
   "metadata": {
    "id": "c65ca3b6"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fec546",
   "metadata": {
    "id": "39fec546"
   },
   "source": [
    "## Adding in the Other Resumes for Prompt Engineering exercise\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e186bfd",
   "metadata": {
    "id": "0e186bfd"
   },
   "outputs": [],
   "source": [
    "more_resumes = pd.read_csv('/content/drive/My Drive/Capstone(Saxa 4)/04Code/modified_file 1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4f1fe",
   "metadata": {
    "id": "3ff4f1fe"
   },
   "outputs": [],
   "source": [
    "more_resumes.to_json('more_resumes.json', orient = 'records', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be42bd",
   "metadata": {
    "id": "71be42bd"
   },
   "outputs": [],
   "source": [
    "more_resumes.rename(columns = {'Resume_str': 'text'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052be8fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "052be8fe",
    "outputId": "e43b1308-ac96-446e-8c76-13045fdff0c8"
   },
   "outputs": [],
   "source": [
    "more_resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e6f60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "334e6f60",
    "outputId": "ab8bfa39-5afa-4485-833a-344d8565ce3b"
   },
   "outputs": [],
   "source": [
    "more_resumes = pd.DataFrame(more_resumes)\n",
    "more_resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0693e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "da0693e4",
    "outputId": "8b7fcc73-9c9f-4160-ecad-6d90a56d92d4"
   },
   "outputs": [],
   "source": [
    "more_resumes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83650ce1",
   "metadata": {
    "id": "83650ce1"
   },
   "outputs": [],
   "source": [
    "#more_resumes['text'] = more_resumes['text'].apply(lambda x: x.encode('utf-8').decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b0013",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "a89b0013",
    "outputId": "af139e84-96ab-4692-d84b-f0923824ddbf"
   },
   "outputs": [],
   "source": [
    "more_resumes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f1e25b",
   "metadata": {
    "id": "02f1e25b"
   },
   "outputs": [],
   "source": [
    "#more_resumes.drop(columns = ['Resume_html'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da510d6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "da510d6f",
    "outputId": "71fc29cc-f01b-4c31-ede7-e880d259e4cf"
   },
   "outputs": [],
   "source": [
    "more_resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ddb088",
   "metadata": {
    "id": "16ddb088"
   },
   "outputs": [],
   "source": [
    "more_resumes.columns = more_resumes.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875c23ac",
   "metadata": {
    "id": "875c23ac"
   },
   "outputs": [],
   "source": [
    "more_resumes['text'] = more_resumes['text'].apply(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76e1d9",
   "metadata": {
    "id": "ac76e1d9"
   },
   "outputs": [],
   "source": [
    "more_resumes['text'] = more_resumes['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2995b254",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "2995b254",
    "outputId": "d0c1f699-b34c-4fa3-8489-b3c217d595d2"
   },
   "outputs": [],
   "source": [
    "more_resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c08d99",
   "metadata": {
    "id": "16c08d99"
   },
   "outputs": [],
   "source": [
    "more_resumes['text'] = more_resumes['text'].str.replace('[^\\w\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4a00a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9b4a00a",
    "outputId": "9263db9a-0e9b-439f-d431-aaeb4602241e"
   },
   "outputs": [],
   "source": [
    "cats_more_res = more_resumes['Category'].nunique()\n",
    "cats_more_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af86713c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "id": "af86713c",
    "outputId": "cf24b557-fa97-49d3-be3e-a4531361eed5"
   },
   "outputs": [],
   "source": [
    "cat_counts = more_resumes['Category'].value_counts()    #Look at CSV and get get rid of the 1's\n",
    "cat_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29960eee",
   "metadata": {
    "id": "29960eee"
   },
   "outputs": [],
   "source": [
    "finance = more_resumes[more_resumes['Category'] == 'FINANCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd62768",
   "metadata": {
    "id": "cdd62768"
   },
   "outputs": [],
   "source": [
    "engineering = more_resumes[more_resumes['Category'] == 'ENGINEERING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rGjcui4TsPrv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "rGjcui4TsPrv",
    "outputId": "1140e69e-fba0-4d6d-e453-a48300727c3f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "more_resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_gbzNSuNsjjf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_gbzNSuNsjjf",
    "outputId": "f9a40baf-f5bc-467f-e9a3-d63babdc723f"
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.0.240 transformers sentence_transformers datasets faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tvQ_8HlK4tLp",
   "metadata": {
    "id": "tvQ_8HlK4tLp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bcv-ebB4wSj",
   "metadata": {
    "id": "0bcv-ebB4wSj"
   },
   "source": [
    "### PROMPT ENGINEERING ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7hFNhMYsnAu",
   "metadata": {
    "id": "b7hFNhMYsnAu"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document # Import the Document class\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O5GwI8u1shZ5",
   "metadata": {
    "id": "O5GwI8u1shZ5"
   },
   "outputs": [],
   "source": [
    "# 1. Load the Hugging Face Embeddings model\n",
    "  ##Notes##\n",
    "   # Code Purpose: loads a pre-trained sentence transformer model called \"all-mpnet-base-v2\" from Hugging Face.\n",
    "   # Model insight: \"all-mpnet-base-v2\" is used to convert text (in this case, resume content) into numerical vectors called embeddings.\n",
    "   # Functionality: Embeddings capture the semantic meaning of the text, allowing you to compare the similarity between different pieces of text based on their vector representations.\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "\n",
    "# 2. Load the more_resumes dataset\n",
    "  # Assumption about dataset: Assuming 'more_resumes.json' is in the current directory\n",
    "more_resumes = load_dataset('json', data_files='more_resumes.json')\n",
    "\n",
    "# 3. Split resumes into smaller chunks for embedding\n",
    "  #Code purpose: Divides each resume's text content into smaller chunks to handle potentially large documents.\n",
    "  # Functionality: RecursiveCharacterTextSplitter: This object is used to split the text. It's configured to create\n",
    "  # chunks of approximately 1000 characters with an overlap of 200 characters between chunks.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = []\n",
    "for resume in more_resumes['train']:\n",
    "    texts = text_splitter.split_text(resume['text'])\n",
    "    # Create Document objects instead of dictionaries\n",
    "    docs.extend([Document(page_content=t, metadata={'source': resume['Category']}) for t in texts])\n",
    "\n",
    "# 4. Embed the resume chunks and store them in a FAISS vectorstore\n",
    "  #Purpose: Purpose: Creates a vector database using FAISS (Facebook AI Similarity Search) and\n",
    "  # stores the embeddings of the resume chunks in it.\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "db.save_local(\"more_resumes_faiss\")\n",
    "\n",
    "# Now the 'more_resumes' dataset is embedded and stored in a FAISS vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1CB-iTi40QO7",
   "metadata": {
    "id": "1CB-iTi40QO7"
   },
   "outputs": [],
   "source": [
    "###Prompt Engineering 1: Open AI's GPT 4 ###\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "import os        #for API Key\n",
    "import openai\n",
    "\n",
    "\n",
    "# 1. Load the FAISS vectorstore\n",
    "db = FAISS.load_local(\"more_resumes_faiss\", embeddings)\n",
    "\n",
    "# 2. Initialize OpenAI's GPT-4\n",
    "# Make sure you set your OPENAI_API_KEY environment variable\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "# Set's GR's API key as an environment variable (recommended)\n",
    "os.environ[\"genesis_gpt4_API_key\"] = \"genesis_gpt4_API_key\" #Replace YOUR_API_KEY with your actual OpenAI key\n",
    "\n",
    "# 3. Create a RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever()\n",
    ")\n",
    "\n",
    "# 4. Define your prompt template\n",
    "prompt_template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't have enough information to answer the question, just say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# 5. Function to run a query\n",
    "def run_query(query):\n",
    "    \"\"\"Runs a query against the resume dataset using prompt engineering.\"\"\"\n",
    "    response = qa_chain.run(\n",
    "        prompt_template.format(context=db.as_retriever().get_relevant_documents(query)[0].page_content, question=query)\n",
    "    )\n",
    "    return response #Corrected to return the response\n",
    "\n",
    "# 6a. Example usage 1\n",
    "query = \"Based on this resume, what are the top jobs I can qualify for?\"\n",
    "result = run_query(query)\n",
    "print(result)\n",
    "\n",
    "# 6b. Example usage 2\n",
    "query1 = \"I live in a high cost city and need to make at least $80k salary per year, based on my resume, what jobs should I apply for to get me this salary?\"\n",
    "result1 = run_query(query1)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nIxUKpZHw-61",
   "metadata": {
    "id": "nIxUKpZHw-61"
   },
   "outputs": [],
   "source": [
    "###Prompt Engineering 2:  Cohere ###\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import Cohere\n",
    "\n",
    "# 1. Load the FAISS vectorstore\n",
    "db = FAISS.load_local(\"more_resumes_faiss\", embeddings)\n",
    "\n",
    "# 2. Initialize Cohere\n",
    "# Make sure you set your COHERE_API_KEY environment variable\n",
    "llm = Cohere(model=\"command-xlarge-nightly\", temperature=0)\n",
    "\n",
    "# 3. Create a RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever()\n",
    ")\n",
    "\n",
    "# 4. Define your prompt template\n",
    "prompt_template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't have enough information to answer the question, just say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# 5. Function to run a query\n",
    "def run_query(query):\n",
    "    \"\"\"Runs a query against the resume dataset using prompt engineering.\"\"\"\n",
    "    response = qa_chain.run(\n",
    "        prompt_template.format(context=db.as_retriever().get_relevant_documents(query)[0].page_content, question=query)\n",
    "    )\n",
    "    return response #Corrected to return the response\n",
    "\n",
    "# 6. Example usage\n",
    "query = \"What are the skills of candidates in the Finance category?\"\n",
    "result = run_query(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tBK_Mh4N1GoU",
   "metadata": {
    "id": "tBK_Mh4N1GoU"
   },
   "outputs": [],
   "source": [
    "###Prompt Engineering 3:  Llama 2 ###\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import LlamaCpp\n",
    "\n",
    "# 1. Load the FAISS vectorstore\n",
    "db = FAISS.load_local(\"more_resumes_faiss\", embeddings)\n",
    "\n",
    "# 2. Initialize Llama 2\n",
    "# Replace with the path to your Llama 2 model file\n",
    "llm = LlamaCpp(model_path=\"/path/to/your/llama-2-7b-chat.ggmlv3.q4_0.bin\")\n",
    "\n",
    "\n",
    "# 3. Create a RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever()\n",
    ")\n",
    "\n",
    "# 4. Define your prompt template\n",
    "prompt_template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't have enough information to answer the question, just say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# 5. Function to run a query\n",
    "def run_query(query):\n",
    "    \"\"\"Runs a query against the resume dataset using prompt engineering.\"\"\"\n",
    "    response = qa_chain.run(\n",
    "        prompt_template.format(context=db.as_retriever().get_relevant_documents(query)[0].page_content, question=query)\n",
    "    )\n",
    "    return response #Corrected to return the response\n",
    "\n",
    "# 6. Example usage\n",
    "query = \"What are the skills of candidates in the Finance category?\"\n",
    "result = run_query(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35799bb1",
   "metadata": {
    "id": "RPnv3Y28sl6f"
   },
   "source": [
    "# Testing Code with Redacted PII data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1D7OaRBssiW5",
   "metadata": {
    "id": "1D7OaRBssiW5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dezri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\dezri\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning:\n",
      "\n",
      "`torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "#from docx import Document\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import pdfplumber\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from textblob import TextBlob\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import os\n",
    "import json\n",
    "#from docx import Document\n",
    "import pdfplumber\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "#spacy.cli.download(\"en_core_web_sm\")\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "from plotly.offline import plot\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f602c7da",
   "metadata": {},
   "source": [
    "# Redacted with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a143e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = pd.read_csv('Resumes_with_PII_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c54d9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust this number to scale the size of the corpus\n",
    "resumes = resumes.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b0f73cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HR</td>\n",
       "      <td>Alexis Lee \\n\\nalexis.lee@gmail.com\\n\\n(728) 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID Category                                               text\n",
       "0  1       HR  Alexis Lee \\n\\nalexis.lee@gmail.com\\n\\n(728) 6..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54094559",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbf04976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_pipeline(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [{'word': ent.text, 'entity': ent.label_, 'score': ent.kb_id_} for ent in doc.ents]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "624c1de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_documents_spacy_corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6fff2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in resumes.iterrows():\n",
    "    document_ID = row['ID']\n",
    "    document_Category = row['Category']\n",
    "    document_text = row['text']\n",
    "\n",
    "    entities = ner_pipeline(document_text)\n",
    "\n",
    "    document_data = {\n",
    "        'ID': document_ID,\n",
    "        'Category': document_Category,\n",
    "        'text': document_text,\n",
    "        'entities': entities  \n",
    "    }\n",
    "\n",
    "    structured_documents_spacy_corpus.append(document_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad37c687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': '1', 'Category': 'HR', 'text': \"Alexis Lee \\n\\nalexis.lee@gmail.com\\n\\n(728) 660-2201\\n         HR ADMINISTRATOR/MARKETING ASSOCIATE\\n\\nHR ADMINISTRATOR       Summary     Dedicated Customer Service Manager with 15+ years of experience in Hospitality and Customer Service Management.   Respected builder and leader of customer-focused teams; strives to instill a shared, enthusiastic commitment to customer service.         Highlights         Focused on customer satisfaction  Team management  Marketing savvy  Conflict resolution techniques     Training and development  Skilled multi-tasker  Client relations specialist           Accomplishments      Missouri DOT Supervisor Training Certification  Certified by IHG in Customer Loyalty and Marketing by Segment   Hilton Worldwide General Manager Training Certification  Accomplished Trainer for cross server hospitality systems such as    Hilton OnQ  ,   Micros    Opera PMS   , Fidelio    OPERA    Reservation System (ORS) ,   Holidex    Completed courses and seminars in customer service, sales strategies, inventory control, loss prevention, safety, time management, leadership and performance assessment.        Experience      HR Administrator/Marketing Associate\\n\\nHR Administrator     Dec 2013   to   Current Carrillo, Cruz and Edwards  －    Wagnerburgh, MH  Helps to develop policies, directs and coordinates activities such as employment, compensation, labor relations, benefits, training, and employee services.  Prepares employee separation notices and related documentation  Keeps records of benefits plans participation such as insurance and pension plan, personnel transactions such as hires, promotions, transfers, performance reviews, and terminations, and employee statistics for government reporting.  Advises management in appropriate resolution of employee relations issues.  Administers benefits programs such as life, health, dental, insurance, pension plans, vacation, sick leave, leave of absence, and employee assistance.     Marketing Associate \\xa0   Designed and created marketing collateral for sales meetings, trade shows and company executives.  Managed the in-house advertising program consisting of print and media collateral pieces.  Assisted in the complete design and launch of the company's website in 2 months.  Created an official company page on Facebook to facilitate interaction with customers.  Analyzed ratings and programming features of competitors to evaluate the effectiveness of marketing strategies.         Advanced Medical Claims Analyst     Mar 2012   to   Dec 2013 Rose PLC  －    Wagnerburgh, MH  Reviewed medical bills for the accuracy of the treatments, tests, and hospital stays prior to sanctioning the claims.  Trained to interpret the codes (ICD-9, CPT) and terminology commonly used in medical billing to fully understand the paperwork that is submitted by healthcare providers.  Required to have organizational and analytical skills as well as computer skills, knowledge of medical terminology and procedures, statistics, billing standards, data analysis and laws regarding medical billing.         Assistant General Manager     Jun 2010   to   Dec 2010 Humphrey, Rodriguez and Jones  －    Wagnerburgh, MH  Performed duties including but not limited to, budgeting and financial management, accounting, human resources, payroll and purchasing.  Established and maintained close working relationships with all departments of the hotel to ensure maximum operation, productivity, morale and guest service.  Handled daily operations and reported directly to the corporate office.  Hired and trained staff on overall objectives and goals with an emphasis on high customer service.  Marketing and Advertising, working on public relations with the media, government and local businesses and Chamber of Commerce.         Executive Support / Marketing Assistant     Jul 2007   to   Jun 2010 Herrera-Villanueva  －    Wagnerburgh, MH  Provided assistance to various department heads - Executive, Marketing, Customer Service, Human Resources.  Managed front-end operations to ensure friendly and efficient transactions.  Ensured the swift resolution of customer issues to preserve customer loyalty while complying with company policies.  Exemplified the second-to-none customer service delivery in all interactions with customers and potential clients.         Reservation & Front Office Manager     Jun 2004   to   Jul 2007 Wilson-Wheeler  －    Wagnerburgh, MH  Owner/ Partner     Dec 2001   to   May 2004 Jones-Cunningham  －    Wagnerburgh, MH  Price Integrity Coordinator     Aug 1999   to   Dec 2001 Mitchell, Hampton and White  －    Wagnerburgh, MH  Education      N/A  ,   Business Administration   1999     Jefferson College   －    Wagnerburgh, MH  Business Administration  Marketing / Advertising         High School Diploma  ,   College Prep. studies   1998     Sainte Genevieve Senior High   －    Wagnerburgh, MH  Awarded American Shrubel Leadership Scholarship to Jefferson College         Skills     Accounting, ads, advertising, analytical skills, benefits, billing, budgeting, clients, Customer Service, data analysis, delivery, documentation, employee relations, financial management, government relations, Human Resources, insurance, labor relations, layout, Marketing, marketing collateral, medical billing, medical terminology, office, organizational, payroll, performance reviews, personnel, policies, posters, presentations, public relations, purchasing, reporting, statistics, website.    \", 'entities': [{'word': 'Alexis Lee', 'entity': 'PERSON', 'score': ''}, {'word': '728', 'entity': 'CARDINAL', 'score': ''}, {'word': '660', 'entity': 'CARDINAL', 'score': ''}, {'word': '15+ years', 'entity': 'DATE', 'score': ''}, {'word': 'Hospitality and Customer Service Management', 'entity': 'ORG', 'score': ''}, {'word': 'Team', 'entity': 'ORG', 'score': ''}, {'word': 'Accomplishments      ', 'entity': 'PERSON', 'score': ''}, {'word': 'Missouri', 'entity': 'GPE', 'score': ''}, {'word': 'IHG', 'entity': 'ORG', 'score': ''}, {'word': 'Customer Loyalty and Marketing by Segment   ', 'entity': 'ORG', 'score': ''}, {'word': 'Hilton OnQ', 'entity': 'PERSON', 'score': ''}, {'word': 'Micros    Opera PMS', 'entity': 'ORG', 'score': ''}, {'word': 'Dec 2013', 'entity': 'DATE', 'score': ''}, {'word': 'Carrillo', 'entity': 'ORG', 'score': ''}, {'word': 'Cruz', 'entity': 'GPE', 'score': ''}, {'word': 'Edwards', 'entity': 'PERSON', 'score': ''}, {'word': 'Wagnerburgh', 'entity': 'PERSON', 'score': ''}, {'word': 'MH  Helps', 'entity': 'ORG', 'score': ''}, {'word': 'Marketing Associate \\xa0   Designed', 'entity': 'ORG', 'score': ''}, {'word': '2 months', 'entity': 'DATE', 'score': ''}, {'word': 'Facebook', 'entity': 'ORG', 'score': ''}, {'word': 'Advanced Medical', 'entity': 'ORG', 'score': ''}, {'word': 'Mar 2012', 'entity': 'DATE', 'score': ''}, {'word': 'Dec 2013', 'entity': 'DATE', 'score': ''}, {'word': 'Rose PLC  －', 'entity': 'ORG', 'score': ''}, {'word': 'Wagnerburgh', 'entity': 'PERSON', 'score': ''}, {'word': 'MH  Reviewed', 'entity': 'ORG', 'score': ''}, {'word': 'Jun 2010', 'entity': 'DATE', 'score': ''}, {'word': 'Dec 2010', 'entity': 'DATE', 'score': ''}, {'word': 'Humphrey, Rodriguez and Jones  －', 'entity': 'ORG', 'score': ''}, {'word': 'Wagnerburgh', 'entity': 'PERSON', 'score': ''}, {'word': 'MH  Performed', 'entity': 'ORG', 'score': ''}, {'word': 'daily', 'entity': 'DATE', 'score': ''}, {'word': 'Marketing and Advertising', 'entity': 'ORG', 'score': ''}, {'word': 'Chamber of Commerce', 'entity': 'ORG', 'score': ''}, {'word': 'Jul 2007', 'entity': 'DATE', 'score': ''}, {'word': 'Jun 2010', 'entity': 'DATE', 'score': ''}, {'word': 'Herrera-Villanueva  －', 'entity': 'ORG', 'score': ''}, {'word': 'Wagnerburgh', 'entity': 'PERSON', 'score': ''}, {'word': 'MH', 'entity': 'ORG', 'score': ''}, {'word': 'Customer Service', 'entity': 'ORG', 'score': ''}, {'word': 'Human Resources', 'entity': 'ORG', 'score': ''}, {'word': 'second', 'entity': 'ORDINAL', 'score': ''}, {'word': 'Reservation & Front Office', 'entity': 'ORG', 'score': ''}, {'word': 'Jun 2004', 'entity': 'DATE', 'score': ''}, {'word': 'Jul 2007', 'entity': 'DATE', 'score': ''}, {'word': 'Wilson-Wheeler  －', 'entity': 'ORG', 'score': ''}, {'word': 'Wagnerburgh', 'entity': 'PERSON', 'score': ''}, {'word': 'MH  Owner/', 'entity': 'ORG', 'score': ''}, {'word': 'Dec 2001', 'entity': 'DATE', 'score': ''}, {'word': 'May 2004', 'entity': 'DATE', 'score': ''}, {'word': 'Jones-Cunningham  －', 'entity': 'ORG', 'score': ''}, {'word': 'Wagnerburgh', 'entity': 'PERSON', 'score': ''}, {'word': 'MH  Price Integrity', 'entity': 'ORG', 'score': ''}, {'word': 'Aug 1999', 'entity': 'DATE', 'score': ''}, {'word': 'Dec 2001', 'entity': 'DATE', 'score': ''}, {'word': 'Hampton', 'entity': 'GPE', 'score': ''}, {'word': 'Wagnerburgh', 'entity': 'PERSON', 'score': ''}, {'word': 'MH  Education      N', 'entity': 'ORG', 'score': ''}, {'word': 'Business Administration', 'entity': 'ORG', 'score': ''}, {'word': '1999', 'entity': 'DATE', 'score': ''}, {'word': 'Jefferson College', 'entity': 'ORG', 'score': ''}, {'word': 'Wagnerburgh', 'entity': 'PERSON', 'score': ''}, {'word': 'MH  Business Administration  Marketing / Advertising         High School Diploma', 'entity': 'ORG', 'score': ''}, {'word': 'College Prep', 'entity': 'ORG', 'score': ''}, {'word': '1998', 'entity': 'DATE', 'score': ''}, {'word': 'Sainte Genevieve', 'entity': 'PERSON', 'score': ''}, {'word': 'Wagnerburgh', 'entity': 'PERSON', 'score': ''}, {'word': 'MH  Awarded', 'entity': 'ORG', 'score': ''}, {'word': 'American Shrubel Leadership Scholarship', 'entity': 'WORK_OF_ART', 'score': ''}, {'word': 'Jefferson College         Skills     Accounting', 'entity': 'ORG', 'score': ''}, {'word': 'Customer Service', 'entity': 'ORG', 'score': ''}, {'word': 'Human Resources', 'entity': 'ORG', 'score': ''}]}\n"
     ]
    }
   ],
   "source": [
    "for doc in structured_documents_spacy_corpus:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cb7985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in structured_documents: 1\n",
      "ID: 1, Entities Count: 73\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total documents in structured_documents: {len(structured_documents_spacy_corpus)}\")\n",
    "for doc in structured_documents_spacy_corpus:\n",
    "    print(f\"ID: {doc['ID']}, Entities Count: {len(doc['entities'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f1cacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_corpus_redacted_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7780427",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "    'PERSON': 0.75,\n",
    "    'ORG': 0.99,\n",
    "    'GPE': 0.99, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cff07fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Document 1: 1\n",
      "Entities from document 1:\n"
     ]
    }
   ],
   "source": [
    "for i, document in enumerate(structured_documents_spacy_corpus):\n",
    "    original_text = document['text']\n",
    "    redacted_text = original_text\n",
    "    entities_sorted = sorted(document.get('entities', []), key=lambda x: len(x['word']), reverse=True)\n",
    "\n",
    "    print(f\"Processing Document {i + 1}: {document['ID']}\")\n",
    "    print(f\"Entities from document {i + 1}:\")\n",
    "    \n",
    "    for entity in entities_sorted:\n",
    "        entity_text = entity['word']\n",
    "        entity_label = entity['entity']\n",
    "        score = entity.get('score', 1.0)\n",
    "        \n",
    "       #Makes sure score is treated as a float\n",
    "    score = entity.get('score')\n",
    "    if isinstance(score, str):\n",
    "        try:\n",
    "            score = float(score)\n",
    "        except ValueError:\n",
    "            score = 0.0  #default if conversion fails\n",
    "    else:\n",
    "        score = score if score is not None else 1.0  #fallback to 1.0 if score no score\n",
    " \n",
    "    \n",
    "        if entity_label in thresholds and score >= thresholds[entity_label]:\n",
    "            print(f\"Entity: {entity['word']}, Label: {entity['entity']}, Score: {entity['score']:.4f}\")\n",
    "\n",
    "    for entity in entities_sorted:\n",
    "        entity_text = entity['word']\n",
    "        redacted_text = re.sub(re.escape(entity_text), '[Redacted]', redacted_text)\n",
    "\n",
    "    redacted_text = re.sub(r'\\S+@\\S+', '[Redacted Email]', redacted_text)\n",
    "    redacted_text = re.sub(r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}', '[Redacted Phone]', redacted_text)\n",
    "    redacted_text = re.sub(r'\\b(?:https?://)?(?:www\\.)?linkedin\\.com/in/[a-zA-Z0-9._-]+\\b', '[Redacted Website]', redacted_text)\n",
    "    \n",
    "    \n",
    "    spacy_corpus_redacted_text.append({\n",
    "        'ID': row['ID'],                #row instead of document to build seperate columns in output\n",
    "        'Category': row['Category'],    \n",
    "        'Redacted Text': redacted_text   \n",
    "    })\n",
    "\n",
    "#list to a df\n",
    "spacy_redacted_resumes = pd.DataFrame(spacy_corpus_redacted_text)\n",
    "\n",
    "#Save to CSV\n",
    "spacy_redacted_resumes.to_csv('spacy_redacted_documents_with_id_and_category.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86dc313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of redacted documents: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of redacted documents: {len(spacy_corpus_redacted_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "734f7d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redacted Text for Document 1:\n",
      "{'ID': '1', 'Category': 'HR', 'Redacted Text': \"[Redacted] \\n\\n[Redacted Email]\\n\\n([Redacted]) [Redacted]-2201\\n         HR ADMINISTRATOR/MARKETING ASSOCIATE\\n\\nHR ADMINISTRATOR       Summary     Dedicated [Redacted] Manager with [Redacted] of experience in [Redacted].   Respected builder and leader of customer-focused teams; strives to instill a shared, enthusiastic commitment to customer service.         Highlights         Focused on customer satisfaction  [Redacted] management  Marketing savvy  Conflict resolution techniques     Training and development  Skilled multi-tasker  Client relations specialist           [Redacted][Redacted] DOT Supervisor Training Certification  Certified by [Redacted] in [Redacted]Hilton Worldwide General Manager Training Certification  Accomplished Trainer for cross server hospitality systems such as    [Redacted]  ,   [Redacted]   , Fidelio    OPERA    Reservation System (ORS) ,   Holidex    Completed courses and seminars in customer service, sales strategies, inventory control, loss prevention, safety, time management, leadership and performance assessment.        Experience      HR Administrator/Marketing Associate\\n\\nHR Administrator     [Redacted]   to   Current [Redacted], [Redacted] and [Redacted]  －    [Redacted], [Redacted] to develop policies, directs and coordinates activities such as employment, compensation, labor relations, benefits, training, and employee services.  Prepares employee separation notices and related documentation  Keeps records of benefits plans participation such as insurance and pension plan, personnel transactions such as hires, promotions, transfers, performance reviews, and terminations, and employee statistics for government reporting.  Advises management in appropriate resolution of employee relations issues.  Administers benefits programs such as life, health, dental, insurance, pension plans, vacation, sick leave, leave of absence, and employee assistance.     [Redacted] and created marketing collateral for sales meetings, trade shows and company executives.  Managed the in-house advertising program consisting of print and media collateral pieces.  Assisted in the complete design and launch of the company's website in [Redacted].  Created an official company page on [Redacted] to facilitate interaction with customers.  Analyzed ratings and programming features of competitors to evaluate the effectiveness of marketing strategies.         [Redacted] Claims Analyst     [Redacted]   to   [Redacted] [Redacted]    [Redacted], [Redacted] medical bills for the accuracy of the treatments, tests, and hospital stays prior to sanctioning the claims.  Trained to interpret the codes (ICD-9, CPT) and terminology commonly used in medical billing to fully understand the paperwork that is submitted by healthcare providers.  Required to have organizational and analytical skills as well as computer skills, knowledge of medical terminology and procedures, statistics, billing standards, data analysis and laws regarding medical billing.         Assistant General Manager     [Redacted]   to   [Redacted] [Redacted]    [Redacted], [Redacted] duties including but not limited to, budgeting and financial management, accounting, human resources, payroll and purchasing.  Established and maintained close working relationships with all departments of the hotel to ensure maximum operation, productivity, morale and guest service.  Handled [Redacted] operations and reported directly to the corporate office.  Hired and trained staff on overall objectives and goals with an emphasis on high customer service.  [Redacted], working on public relations with the media, government and local businesses and [Redacted].         Executive Support / Marketing Assistant     [Redacted]   to   [Redacted] [Redacted]    [Redacted], [Redacted]  Provided assistance to various department heads - Executive, Marketing, [Redacted], [Redacted].  Managed front-end operations to ensure friendly and efficient transactions.  Ensured the swift resolution of customer issues to preserve customer loyalty while complying with company policies.  Exemplified the [Redacted]-to-none customer service delivery in all interactions with customers and potential clients.         [Redacted] Manager     [Redacted]   to   [Redacted] [Redacted]    [Redacted], [Redacted] Partner     [Redacted]   to   [Redacted] [Redacted]    [Redacted], [Redacted] Coordinator     [Redacted]   to   [Redacted] Mitchell, [Redacted] and White  －    [Redacted], [Redacted]/A  ,   [Redacted]   [Redacted]     [Redacted]   －    [Redacted], [Redacted]  ,   [Redacted]. studies   [Redacted]     [Redacted] Senior High   －    [Redacted], [Redacted] [Redacted] to [Redacted], ads, advertising, analytical skills, benefits, billing, budgeting, clients, [Redacted], data analysis, delivery, documentation, employee relations, financial management, government relations, [Redacted], insurance, labor relations, layout, Marketing, marketing collateral, medical billing, medical terminology, office, organizational, payroll, performance reviews, personnel, policies, posters, presentations, public relations, purchasing, reporting, statistics, website.    \"}\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(spacy_corpus_redacted_text):\n",
    "    print(f\"Redacted Text for Document {i + 1}:\")\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7213c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2a1429f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redacted Text for Document 1:\n",
      "{'ID': '1', 'Category': 'HR', 'Redacted Text': \"[Redacted] \\n\\n[Redacted Email]\\n\\n([Redacted]) [Redacted]-2201\\n         HR ADMINISTRATOR/MARKETING ASSOCIATE\\n\\nHR ADMINISTRATOR       Summary     Dedicated [Redacted] Manager with [Redacted] of experience in [Redacted].   Respected builder and leader of customer-focused teams; strives to instill a shared, enthusiastic commitment to customer service.         Highlights         Focused on customer satisfaction  [Redacted] management  Marketing savvy  Conflict resolution techniques     Training and development  Skilled multi-tasker  Client relations specialist           [Redacted][Redacted] DOT Supervisor Training Certification  Certified by [Redacted] in [Redacted]Hilton Worldwide General Manager Training Certification  Accomplished Trainer for cross server hospitality systems such as    [Redacted]  ,   [Redacted]   , Fidelio    OPERA    Reservation System (ORS) ,   Holidex    Completed courses and seminars in customer service, sales strategies, inventory control, loss prevention, safety, time management, leadership and performance assessment.        Experience      HR Administrator/Marketing Associate\\n\\nHR Administrator     [Redacted]   to   Current [Redacted], [Redacted] and [Redacted]  －    [Redacted], [Redacted] to develop policies, directs and coordinates activities such as employment, compensation, labor relations, benefits, training, and employee services.  Prepares employee separation notices and related documentation  Keeps records of benefits plans participation such as insurance and pension plan, personnel transactions such as hires, promotions, transfers, performance reviews, and terminations, and employee statistics for government reporting.  Advises management in appropriate resolution of employee relations issues.  Administers benefits programs such as life, health, dental, insurance, pension plans, vacation, sick leave, leave of absence, and employee assistance.     [Redacted] and created marketing collateral for sales meetings, trade shows and company executives.  Managed the in-house advertising program consisting of print and media collateral pieces.  Assisted in the complete design and launch of the company's website in [Redacted].  Created an official company page on [Redacted] to facilitate interaction with customers.  Analyzed ratings and programming features of competitors to evaluate the effectiveness of marketing strategies.         [Redacted] Claims Analyst     [Redacted]   to   [Redacted] [Redacted]    [Redacted], [Redacted] medical bills for the accuracy of the treatments, tests, and hospital stays prior to sanctioning the claims.  Trained to interpret the codes (ICD-9, CPT) and terminology commonly used in medical billing to fully understand the paperwork that is submitted by healthcare providers.  Required to have organizational and analytical skills as well as computer skills, knowledge of medical terminology and procedures, statistics, billing standards, data analysis and laws regarding medical billing.         Assistant General Manager     [Redacted]   to   [Redacted] [Redacted]    [Redacted], [Redacted] duties including but not limited to, budgeting and financial management, accounting, human resources, payroll and purchasing.  Established and maintained close working relationships with all departments of the hotel to ensure maximum operation, productivity, morale and guest service.  Handled [Redacted] operations and reported directly to the corporate office.  Hired and trained staff on overall objectives and goals with an emphasis on high customer service.  [Redacted], working on public relations with the media, government and local businesses and [Redacted].         Executive Support / Marketing Assistant     [Redacted]   to   [Redacted] [Redacted]    [Redacted], [Redacted]  Provided assistance to various department heads - Executive, Marketing, [Redacted], [Redacted].  Managed front-end operations to ensure friendly and efficient transactions.  Ensured the swift resolution of customer issues to preserve customer loyalty while complying with company policies.  Exemplified the [Redacted]-to-none customer service delivery in all interactions with customers and potential clients.         [Redacted] Manager     [Redacted]   to   [Redacted] [Redacted]    [Redacted], [Redacted] Partner     [Redacted]   to   [Redacted] [Redacted]    [Redacted], [Redacted] Coordinator     [Redacted]   to   [Redacted] Mitchell, [Redacted] and White  －    [Redacted], [Redacted]/A  ,   [Redacted]   [Redacted]     [Redacted]   －    [Redacted], [Redacted]  ,   [Redacted]. studies   [Redacted]     [Redacted] Senior High   －    [Redacted], [Redacted] [Redacted] to [Redacted], ads, advertising, analytical skills, benefits, billing, budgeting, clients, [Redacted], data analysis, delivery, documentation, employee relations, financial management, government relations, [Redacted], insurance, labor relations, layout, Marketing, marketing collateral, medical billing, medical terminology, office, organizational, payroll, performance reviews, personnel, policies, posters, presentations, public relations, purchasing, reporting, statistics, website.    \"}\n"
     ]
    }
   ],
   "source": [
    "if document_index < len(spacy_corpus_redacted_text):\n",
    "    print(f\"Redacted Text for Document 1:\")\n",
    "    print(spacy_corpus_redacted_text[document_index])\n",
    "else:\n",
    "    print(\"Document does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbf74db",
   "metadata": {},
   "source": [
    "# adding Genesis Code\n",
    "- dataset csv name = spacy_redacted_documents_with_id_and_category.csv\n",
    "https://python.langchain.com/docs/introduction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c27d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee2bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08047df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Obtaining dependency information for langchain-community from https://files.pythonhosted.org/packages/c8/4c/28602f96a6b5a2cad9ad474906a6eff0c65550bed844ce6c81478589a089/langchain_community-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.3.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-community) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-community) (3.8.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/c3/be/d0d44e092656fe7a06b55e6103cbce807cdbdee17884a5367c68c9860853/dataclasses_json-0.6.7-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Obtaining dependency information for httpx-sse<0.5.0,>=0.4.0 from https://files.pythonhosted.org/packages/e1/9b/a181f281f65d776426002f330c31849b86b31fc9d848db62e16f03ff739f/httpx_sse-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.6)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.14 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.14)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-community) (0.1.138)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-community) (1.24.3)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Obtaining dependency information for pydantic-settings<3.0.0,>=2.4.0 from https://files.pythonhosted.org/packages/34/19/26bb6bdb9fdad5f0dfce538780814084fb667b4bc37fcb28459c14b8d3b5/pydantic_settings-2.6.0-py3-none-any.whl.metadata\n",
      "  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/9a/9e/f8f0308b66ff5fcc3b351ffa5fcba19ae725dfeda75d3c673f4427f3fc99/marshmallow-3.23.0-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.14->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.14->langchain-community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.14->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (2.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.14->langchain-community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading langchain_community-0.3.4-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/2.4 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.1/2.4 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.5/2.4 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 12.8 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.5/49.5 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, marshmallow, httpx-sse, dataclasses-json, pydantic-settings, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.4 marshmallow-3.23.0 pydantic-settings-2.6.0 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f392699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ce4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de51b9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in c:\\users\\dezri\\anaconda3\\lib\\site-packages (2.9.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from pydantic) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from pydantic) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install --upgrade pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a64e7a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Obtaining dependency information for tf-keras from https://files.pythonhosted.org/packages/8a/ed/e08afca471299b04a34cd548e64e89d0153eda0e6cf9b715356777e24774/tf_keras-2.18.0-py3-none-any.whl.metadata\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow<2.19,>=2.18 (from tf-keras)\n",
      "  Obtaining dependency information for tensorflow<2.19,>=2.18 from https://files.pythonhosted.org/packages/cf/24/271e77c22724f370c24c705f394b8035b4d27e4c2c6339f3f45ab9b8258e/tensorflow-2.18.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Obtaining dependency information for tensorflow-intel==2.18.0 from https://files.pythonhosted.org/packages/76/ad/fa6c508a15ff79cb5409294c293388e0999b7d480f84b65e4287277434fe/tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.66.2)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Obtaining dependency information for tensorboard<2.19,>=2.18 from https://files.pythonhosted.org/packages/b1/de/021c1d407befb505791764ad2cbd56ceaaa53a746baed01d2e2143f05f18/tensorboard-2.18.0-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.5.0)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Obtaining dependency information for numpy<2.1.0,>=1.26.0 from https://files.pythonhosted.org/packages/eb/57/3a3f14d3a759dcf9bf6e9eda905794726b758819df4663f217d658a58695/numpy-2.0.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading numpy-2.0.2-cp311-cp311-win_amd64.whl.metadata (59 kB)\n",
      "     ---------------------------------------- 0.0/59.7 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/59.7 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 30.7/59.7 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 59.7/59.7 kB 798.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.38.4)\n",
      "Requirement already satisfied: rich in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (13.8.0)\n",
      "Requirement already satisfied: namex in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.0)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.7 MB 2.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.2/1.7 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.1/1.7 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.4/1.7 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 7.3 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl (390.2 MB)\n",
      "   ---------------------------------------- 0.0/390.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/390.2 MB 64.6 MB/s eta 0:00:07\n",
      "   ---------------------------------------- 1.5/390.2 MB 24.1 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 2.1/390.2 MB 22.3 MB/s eta 0:00:18\n",
      "   ---------------------------------------- 3.2/390.2 MB 22.7 MB/s eta 0:00:18\n",
      "   ---------------------------------------- 3.2/390.2 MB 22.7 MB/s eta 0:00:18\n",
      "   ---------------------------------------- 3.2/390.2 MB 22.7 MB/s eta 0:00:18\n",
      "   ---------------------------------------- 3.2/390.2 MB 22.7 MB/s eta 0:00:18\n",
      "   ---------------------------------------- 3.5/390.2 MB 12.5 MB/s eta 0:00:32\n",
      "   ---------------------------------------- 3.9/390.2 MB 12.6 MB/s eta 0:00:31\n",
      "   ---------------------------------------- 4.4/390.2 MB 12.8 MB/s eta 0:00:31\n",
      "   ---------------------------------------- 4.7/390.2 MB 11.7 MB/s eta 0:00:34\n",
      "   ---------------------------------------- 4.7/390.2 MB 11.7 MB/s eta 0:00:34\n",
      "    --------------------------------------- 4.9/390.2 MB 10.5 MB/s eta 0:00:37\n",
      "    --------------------------------------- 5.6/390.2 MB 10.9 MB/s eta 0:00:36\n",
      "    --------------------------------------- 6.1/390.2 MB 11.4 MB/s eta 0:00:34\n",
      "    --------------------------------------- 6.3/390.2 MB 10.6 MB/s eta 0:00:37\n",
      "    --------------------------------------- 6.7/390.2 MB 11.0 MB/s eta 0:00:35\n",
      "    --------------------------------------- 7.7/390.2 MB 11.7 MB/s eta 0:00:33\n",
      "    --------------------------------------- 8.2/390.2 MB 12.1 MB/s eta 0:00:32\n",
      "    --------------------------------------- 8.8/390.2 MB 12.0 MB/s eta 0:00:32\n",
      "    --------------------------------------- 9.5/390.2 MB 12.4 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 10.1/390.2 MB 12.4 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 10.5/390.2 MB 12.4 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 11.4/390.2 MB 12.6 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 11.7/390.2 MB 11.9 MB/s eta 0:00:32\n",
      "   - -------------------------------------- 12.4/390.2 MB 12.1 MB/s eta 0:00:32\n",
      "   - -------------------------------------- 13.4/390.2 MB 11.7 MB/s eta 0:00:33\n",
      "   - -------------------------------------- 13.5/390.2 MB 13.4 MB/s eta 0:00:29\n",
      "   - -------------------------------------- 14.5/390.2 MB 14.2 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 14.8/390.2 MB 14.6 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 15.9/390.2 MB 16.8 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 16.3/390.2 MB 15.6 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 16.9/390.2 MB 16.8 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 17.2/390.2 MB 16.8 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 17.5/390.2 MB 16.4 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 18.0/390.2 MB 15.6 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 18.9/390.2 MB 16.0 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 19.4/390.2 MB 15.6 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 19.9/390.2 MB 16.0 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 20.4/390.2 MB 15.6 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 21.0/390.2 MB 15.6 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 21.9/390.2 MB 16.0 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 22.1/390.2 MB 15.6 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 23.0/390.2 MB 16.0 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 23.3/390.2 MB 15.6 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 24.2/390.2 MB 16.0 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 24.4/390.2 MB 15.6 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 25.4/390.2 MB 16.0 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 25.5/390.2 MB 15.6 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 26.5/390.2 MB 15.6 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 27.0/390.2 MB 15.2 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 27.6/390.2 MB 16.4 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 28.2/390.2 MB 16.4 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 28.7/390.2 MB 16.0 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 29.8/390.2 MB 16.4 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 30.3/390.2 MB 16.8 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 30.8/390.2 MB 16.4 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 31.5/390.2 MB 16.4 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 32.4/390.2 MB 17.2 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 32.4/390.2 MB 17.2 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 32.7/390.2 MB 15.6 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 33.8/390.2 MB 16.8 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 33.8/390.2 MB 16.8 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 33.8/390.2 MB 16.8 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 34.5/390.2 MB 14.9 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 35.0/390.2 MB 14.9 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 36.0/390.2 MB 15.6 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 36.0/390.2 MB 15.6 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 36.5/390.2 MB 14.2 MB/s eta 0:00:25\n",
      "   --- ------------------------------------ 37.2/390.2 MB 14.6 MB/s eta 0:00:25\n",
      "   --- ------------------------------------ 37.9/390.2 MB 15.2 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 38.3/390.2 MB 14.9 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 39.0/390.2 MB 14.6 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 39.8/390.2 MB 14.2 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 40.3/390.2 MB 14.6 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 40.7/390.2 MB 14.6 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 41.3/390.2 MB 14.2 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 42.1/390.2 MB 14.6 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 42.5/390.2 MB 13.6 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 43.0/390.2 MB 14.9 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 43.5/390.2 MB 14.2 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 44.3/390.2 MB 15.6 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 44.7/390.2 MB 16.0 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 45.3/390.2 MB 15.6 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 46.0/390.2 MB 14.9 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 46.5/390.2 MB 16.4 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 47.2/390.2 MB 16.0 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 48.0/390.2 MB 16.0 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 48.3/390.2 MB 15.6 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 49.2/390.2 MB 16.0 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 49.4/390.2 MB 15.6 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 50.5/390.2 MB 16.4 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 50.8/390.2 MB 16.0 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 51.7/390.2 MB 16.4 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 52.0/390.2 MB 16.0 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 53.0/390.2 MB 16.8 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 53.2/390.2 MB 16.0 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 54.2/390.2 MB 16.8 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 54.5/390.2 MB 16.4 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 55.3/390.2 MB 16.8 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 55.4/390.2 MB 16.0 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 56.5/390.2 MB 17.2 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 56.9/390.2 MB 16.8 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 57.8/390.2 MB 17.7 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 58.0/390.2 MB 16.4 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 59.1/390.2 MB 17.3 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 59.7/390.2 MB 18.2 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 60.1/390.2 MB 17.7 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 60.1/390.2 MB 16.0 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 60.7/390.2 MB 16.4 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 61.0/390.2 MB 15.6 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 61.7/390.2 MB 15.2 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 61.9/390.2 MB 16.0 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 62.3/390.2 MB 15.2 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 62.8/390.2 MB 14.9 MB/s eta 0:00:23\n",
      "   ------ --------------------------------- 63.0/390.2 MB 13.9 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 63.7/390.2 MB 14.6 MB/s eta 0:00:23\n",
      "   ------ --------------------------------- 64.1/390.2 MB 13.9 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 64.5/390.2 MB 13.6 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 65.3/390.2 MB 13.9 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 65.6/390.2 MB 14.2 MB/s eta 0:00:23\n",
      "   ------ --------------------------------- 66.0/390.2 MB 13.9 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 66.5/390.2 MB 13.6 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 67.4/390.2 MB 13.6 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 67.6/390.2 MB 13.4 MB/s eta 0:00:25\n",
      "   ------- -------------------------------- 68.6/390.2 MB 13.6 MB/s eta 0:00:24\n",
      "   ------- -------------------------------- 68.9/390.2 MB 13.6 MB/s eta 0:00:24\n",
      "   ------- -------------------------------- 69.6/390.2 MB 13.6 MB/s eta 0:00:24\n",
      "   ------- -------------------------------- 69.9/390.2 MB 13.6 MB/s eta 0:00:24\n",
      "   ------- -------------------------------- 71.0/390.2 MB 14.6 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 71.6/390.2 MB 15.6 MB/s eta 0:00:21\n",
      "   ------- -------------------------------- 71.6/390.2 MB 15.6 MB/s eta 0:00:21\n",
      "   ------- -------------------------------- 72.6/390.2 MB 15.2 MB/s eta 0:00:21\n",
      "   ------- -------------------------------- 73.3/390.2 MB 16.8 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 73.3/390.2 MB 16.8 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 73.7/390.2 MB 14.9 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 74.4/390.2 MB 16.0 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 74.4/390.2 MB 16.0 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 75.3/390.2 MB 15.2 MB/s eta 0:00:21\n",
      "   ------- -------------------------------- 76.6/390.2 MB 16.4 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 77.9/390.2 MB 18.7 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 77.9/390.2 MB 18.7 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 77.9/390.2 MB 18.7 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 77.9/390.2 MB 18.7 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 77.9/390.2 MB 18.7 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 77.9/390.2 MB 18.7 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 77.9/390.2 MB 18.7 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 77.9/390.2 MB 18.7 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 78.4/390.2 MB 11.9 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 79.2/390.2 MB 12.1 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 80.1/390.2 MB 12.1 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 80.6/390.2 MB 12.4 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 81.0/390.2 MB 12.4 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 81.2/390.2 MB 11.5 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 81.2/390.2 MB 11.5 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 81.2/390.2 MB 11.5 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 81.4/390.2 MB 10.4 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 82.4/390.2 MB 10.9 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 83.1/390.2 MB 10.7 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 83.9/390.2 MB 11.3 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 84.3/390.2 MB 11.1 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 85.0/390.2 MB 11.7 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 85.3/390.2 MB 11.3 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 86.4/390.2 MB 11.3 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 86.4/390.2 MB 11.3 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 87.4/390.2 MB 10.7 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 87.9/390.2 MB 10.4 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 88.6/390.2 MB 14.9 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 88.6/390.2 MB 14.9 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 89.5/390.2 MB 14.2 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 90.2/390.2 MB 14.2 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 90.9/390.2 MB 14.2 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 91.4/390.2 MB 14.9 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 92.0/390.2 MB 17.2 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 92.0/390.2 MB 16.4 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 92.2/390.2 MB 15.6 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 92.5/390.2 MB 15.2 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 93.3/390.2 MB 14.9 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 93.9/390.2 MB 14.6 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 94.6/390.2 MB 15.2 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 95.2/390.2 MB 14.2 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 95.5/390.2 MB 14.9 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 96.1/390.2 MB 14.2 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 96.5/390.2 MB 13.6 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 97.2/390.2 MB 14.2 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 97.5/390.2 MB 13.9 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 98.3/390.2 MB 14.2 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 98.9/390.2 MB 15.6 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 99.4/390.2 MB 14.5 MB/s eta 0:00:21\n",
      "   ---------- ---------------------------- 100.1/390.2 MB 13.9 MB/s eta 0:00:21\n",
      "   ---------- ---------------------------- 100.7/390.2 MB 14.6 MB/s eta 0:00:20\n",
      "   ---------- ---------------------------- 101.2/390.2 MB 13.6 MB/s eta 0:00:22\n",
      "   ---------- ---------------------------- 102.2/390.2 MB 14.6 MB/s eta 0:00:20\n",
      "   ---------- ---------------------------- 102.3/390.2 MB 15.6 MB/s eta 0:00:19\n",
      "   ---------- ---------------------------- 103.4/390.2 MB 16.0 MB/s eta 0:00:18\n",
      "   ---------- ---------------------------- 103.6/390.2 MB 15.6 MB/s eta 0:00:19\n",
      "   ---------- ---------------------------- 104.1/390.2 MB 15.2 MB/s eta 0:00:19\n",
      "   ---------- ---------------------------- 104.7/390.2 MB 15.2 MB/s eta 0:00:19\n",
      "   ---------- ---------------------------- 105.0/390.2 MB 14.9 MB/s eta 0:00:20\n",
      "   ---------- ---------------------------- 105.9/390.2 MB 15.2 MB/s eta 0:00:19\n",
      "   ---------- ---------------------------- 106.2/390.2 MB 14.6 MB/s eta 0:00:20\n",
      "   ---------- ---------------------------- 106.9/390.2 MB 15.2 MB/s eta 0:00:19\n",
      "   ---------- ---------------------------- 107.2/390.2 MB 14.6 MB/s eta 0:00:20\n",
      "   ---------- ---------------------------- 108.2/390.2 MB 15.2 MB/s eta 0:00:19\n",
      "   ---------- ---------------------------- 108.3/390.2 MB 14.9 MB/s eta 0:00:19\n",
      "   ---------- ---------------------------- 109.5/390.2 MB 14.9 MB/s eta 0:00:19\n",
      "   ---------- ---------------------------- 109.6/390.2 MB 14.9 MB/s eta 0:00:19\n",
      "   ----------- --------------------------- 110.2/390.2 MB 14.9 MB/s eta 0:00:19\n",
      "   ----------- --------------------------- 110.3/390.2 MB 14.5 MB/s eta 0:00:20\n",
      "   ----------- --------------------------- 110.9/390.2 MB 14.2 MB/s eta 0:00:20\n",
      "   ----------- --------------------------- 111.4/390.2 MB 14.6 MB/s eta 0:00:20\n",
      "   ----------- --------------------------- 111.9/390.2 MB 13.9 MB/s eta 0:00:20\n",
      "   ----------- --------------------------- 112.4/390.2 MB 13.6 MB/s eta 0:00:21\n",
      "   ----------- --------------------------- 112.9/390.2 MB 13.9 MB/s eta 0:00:20\n",
      "   ----------- --------------------------- 113.6/390.2 MB 13.6 MB/s eta 0:00:21\n",
      "   ----------- --------------------------- 113.9/390.2 MB 13.9 MB/s eta 0:00:20\n",
      "   ----------- --------------------------- 114.7/390.2 MB 14.2 MB/s eta 0:00:20\n",
      "   ----------- --------------------------- 115.2/390.2 MB 14.6 MB/s eta 0:00:19\n",
      "   ----------- --------------------------- 115.8/390.2 MB 14.2 MB/s eta 0:00:20\n",
      "   ----------- --------------------------- 116.5/390.2 MB 15.2 MB/s eta 0:00:18\n",
      "   ----------- --------------------------- 117.0/390.2 MB 14.6 MB/s eta 0:00:19\n",
      "   ----------- --------------------------- 117.6/390.2 MB 14.9 MB/s eta 0:00:19\n",
      "   ----------- --------------------------- 118.1/390.2 MB 14.6 MB/s eta 0:00:19\n",
      "   ----------- --------------------------- 118.2/390.2 MB 13.9 MB/s eta 0:00:20\n",
      "   ----------- --------------------------- 118.6/390.2 MB 14.2 MB/s eta 0:00:20\n",
      "   ----------- --------------------------- 119.4/390.2 MB 13.9 MB/s eta 0:00:20\n",
      "   ------------ -------------------------- 120.1/390.2 MB 14.6 MB/s eta 0:00:19\n",
      "   ------------ -------------------------- 120.5/390.2 MB 14.6 MB/s eta 0:00:19\n",
      "   ------------ -------------------------- 121.4/390.2 MB 14.9 MB/s eta 0:00:19\n",
      "   ------------ -------------------------- 121.8/390.2 MB 14.9 MB/s eta 0:00:19\n",
      "   ------------ -------------------------- 121.8/390.2 MB 14.9 MB/s eta 0:00:19\n",
      "   ------------ -------------------------- 122.9/390.2 MB 15.2 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 123.3/390.2 MB 15.2 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 123.8/390.2 MB 14.2 MB/s eta 0:00:19\n",
      "   ------------ -------------------------- 124.6/390.2 MB 14.9 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 125.1/390.2 MB 14.6 MB/s eta 0:00:19\n",
      "   ------------ -------------------------- 125.6/390.2 MB 14.9 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 126.3/390.2 MB 15.2 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 126.9/390.2 MB 14.9 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 127.9/390.2 MB 15.6 MB/s eta 0:00:17\n",
      "   ------------ -------------------------- 128.1/390.2 MB 14.9 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 128.9/390.2 MB 16.8 MB/s eta 0:00:16\n",
      "   ------------ -------------------------- 129.5/390.2 MB 15.6 MB/s eta 0:00:17\n",
      "   ------------ -------------------------- 129.8/390.2 MB 16.4 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 130.6/390.2 MB 15.2 MB/s eta 0:00:18\n",
      "   ------------- ------------------------- 131.4/390.2 MB 16.0 MB/s eta 0:00:17\n",
      "   ------------- ------------------------- 132.1/390.2 MB 17.3 MB/s eta 0:00:15\n",
      "   ------------- ------------------------- 132.5/390.2 MB 16.4 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 133.4/390.2 MB 16.4 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 133.6/390.2 MB 16.8 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 134.7/390.2 MB 16.8 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 135.0/390.2 MB 16.8 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 135.8/390.2 MB 16.8 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 136.5/390.2 MB 16.8 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 136.5/390.2 MB 16.8 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 137.8/390.2 MB 16.4 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 138.1/390.2 MB 16.0 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 138.8/390.2 MB 17.2 MB/s eta 0:00:15\n",
      "   ------------- ------------------------- 139.1/390.2 MB 15.6 MB/s eta 0:00:17\n",
      "   -------------- ------------------------ 140.1/390.2 MB 17.2 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 140.6/390.2 MB 16.4 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 141.3/390.2 MB 16.4 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 141.8/390.2 MB 16.4 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 142.5/390.2 MB 16.4 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 142.8/390.2 MB 16.0 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 143.4/390.2 MB 16.0 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 143.5/390.2 MB 14.9 MB/s eta 0:00:17\n",
      "   -------------- ------------------------ 144.9/390.2 MB 16.0 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 145.1/390.2 MB 16.4 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 145.8/390.2 MB 15.6 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 146.4/390.2 MB 16.4 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 147.1/390.2 MB 16.4 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 147.7/390.2 MB 16.0 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 148.0/390.2 MB 16.4 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 148.6/390.2 MB 15.6 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 149.5/390.2 MB 16.8 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 150.1/390.2 MB 15.6 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 150.5/390.2 MB 16.4 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 150.7/390.2 MB 15.2 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 151.7/390.2 MB 15.6 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 152.1/390.2 MB 15.6 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 152.7/390.2 MB 15.6 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 153.3/390.2 MB 15.6 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 153.8/390.2 MB 16.4 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 154.4/390.2 MB 16.0 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 154.8/390.2 MB 15.2 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 155.5/390.2 MB 15.6 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 155.8/390.2 MB 15.2 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 156.6/390.2 MB 16.0 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 157.1/390.2 MB 14.6 MB/s eta 0:00:17\n",
      "   --------------- ----------------------- 157.9/390.2 MB 15.2 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 158.5/390.2 MB 16.4 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 158.9/390.2 MB 16.4 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 159.2/390.2 MB 15.2 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 160.2/390.2 MB 16.0 MB/s eta 0:00:15\n",
      "   ---------------- ---------------------- 160.5/390.2 MB 15.2 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 161.5/390.2 MB 16.4 MB/s eta 0:00:14\n",
      "   ---------------- ---------------------- 162.0/390.2 MB 15.6 MB/s eta 0:00:15\n",
      "   ---------------- ---------------------- 162.6/390.2 MB 16.0 MB/s eta 0:00:15\n",
      "   ---------------- ---------------------- 163.1/390.2 MB 16.0 MB/s eta 0:00:15\n",
      "   ---------------- ---------------------- 163.9/390.2 MB 16.0 MB/s eta 0:00:15\n",
      "   ---------------- ---------------------- 164.4/390.2 MB 16.4 MB/s eta 0:00:14\n",
      "   ---------------- ---------------------- 165.0/390.2 MB 16.4 MB/s eta 0:00:14\n",
      "   ---------------- ---------------------- 165.4/390.2 MB 16.0 MB/s eta 0:00:15\n",
      "   ---------------- ---------------------- 166.2/390.2 MB 17.2 MB/s eta 0:00:14\n",
      "   ---------------- ---------------------- 166.3/390.2 MB 16.0 MB/s eta 0:00:15\n",
      "   ---------------- ---------------------- 166.3/390.2 MB 15.2 MB/s eta 0:00:15\n",
      "   ---------------- ---------------------- 168.0/390.2 MB 16.0 MB/s eta 0:00:14\n",
      "   ---------------- ---------------------- 168.9/390.2 MB 16.8 MB/s eta 0:00:14\n",
      "   ---------------- ---------------------- 169.5/390.2 MB 17.7 MB/s eta 0:00:13\n",
      "   ---------------- ---------------------- 170.0/390.2 MB 16.8 MB/s eta 0:00:14\n",
      "   ----------------- --------------------- 170.7/390.2 MB 17.2 MB/s eta 0:00:13\n",
      "   ----------------- --------------------- 171.3/390.2 MB 16.4 MB/s eta 0:00:14\n",
      "   ----------------- --------------------- 172.0/390.2 MB 16.8 MB/s eta 0:00:14\n",
      "   ----------------- --------------------- 172.2/390.2 MB 16.4 MB/s eta 0:00:14\n",
      "   ----------------- --------------------- 173.2/390.2 MB 17.7 MB/s eta 0:00:13\n",
      "   ----------------- --------------------- 173.9/390.2 MB 16.8 MB/s eta 0:00:13\n",
      "   ----------------- --------------------- 174.4/390.2 MB 17.3 MB/s eta 0:00:13\n",
      "   ----------------- --------------------- 175.0/390.2 MB 16.8 MB/s eta 0:00:13\n",
      "   ----------------- --------------------- 175.6/390.2 MB 17.2 MB/s eta 0:00:13\n",
      "   ----------------- --------------------- 176.2/390.2 MB 16.4 MB/s eta 0:00:14\n",
      "   ----------------- --------------------- 176.9/390.2 MB 19.2 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 177.5/390.2 MB 18.2 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 178.3/390.2 MB 17.2 MB/s eta 0:00:13\n",
      "   ----------------- --------------------- 178.8/390.2 MB 16.8 MB/s eta 0:00:13\n",
      "   ----------------- --------------------- 179.7/390.2 MB 17.3 MB/s eta 0:00:13\n",
      "   ----------------- --------------------- 180.0/390.2 MB 16.4 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 180.9/390.2 MB 17.3 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 181.4/390.2 MB 17.3 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 181.8/390.2 MB 16.8 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 182.7/390.2 MB 17.7 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 183.2/390.2 MB 16.8 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 183.9/390.2 MB 17.2 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 184.3/390.2 MB 16.8 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 185.2/390.2 MB 17.2 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 185.8/390.2 MB 17.3 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 186.2/390.2 MB 16.4 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 186.6/390.2 MB 17.2 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 186.9/390.2 MB 16.0 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 187.8/390.2 MB 16.8 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 188.4/390.2 MB 16.4 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 189.5/390.2 MB 16.8 MB/s eta 0:00:12\n",
      "   ------------------- ------------------- 190.4/390.2 MB 17.7 MB/s eta 0:00:12\n",
      "   ------------------- ------------------- 190.5/390.2 MB 16.8 MB/s eta 0:00:12\n",
      "   ------------------- ------------------- 191.2/390.2 MB 16.8 MB/s eta 0:00:12\n",
      "   ------------------- ------------------- 191.2/390.2 MB 16.4 MB/s eta 0:00:13\n",
      "   ------------------- ------------------- 191.9/390.2 MB 15.6 MB/s eta 0:00:13\n",
      "   ------------------- ------------------- 193.1/390.2 MB 16.8 MB/s eta 0:00:12\n",
      "   ------------------- ------------------- 193.4/390.2 MB 16.8 MB/s eta 0:00:12\n",
      "   ------------------- ------------------- 194.3/390.2 MB 17.2 MB/s eta 0:00:12\n",
      "   ------------------- ------------------- 194.8/390.2 MB 16.8 MB/s eta 0:00:12\n",
      "   ------------------- ------------------- 195.4/390.2 MB 16.4 MB/s eta 0:00:12\n",
      "   ------------------- ------------------- 196.2/390.2 MB 16.8 MB/s eta 0:00:12\n",
      "   ------------------- ------------------- 196.9/390.2 MB 18.2 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 197.7/390.2 MB 17.7 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 198.2/390.2 MB 17.7 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 198.8/390.2 MB 17.7 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 199.8/390.2 MB 17.7 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 200.1/390.2 MB 16.8 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 201.0/390.2 MB 17.7 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 201.5/390.2 MB 18.7 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 202.3/390.2 MB 18.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 202.7/390.2 MB 17.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 203.5/390.2 MB 16.8 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 204.1/390.2 MB 17.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 204.7/390.2 MB 17.7 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 205.1/390.2 MB 17.7 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 205.7/390.2 MB 17.3 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 206.4/390.2 MB 17.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 206.8/390.2 MB 17.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 207.4/390.2 MB 16.8 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 208.1/390.2 MB 17.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 208.9/390.2 MB 16.4 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 209.5/390.2 MB 16.8 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 209.8/390.2 MB 16.0 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 210.9/390.2 MB 16.8 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 211.2/390.2 MB 16.4 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 212.2/390.2 MB 16.8 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 212.7/390.2 MB 16.8 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 213.3/390.2 MB 17.2 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 214.0/390.2 MB 16.8 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 214.4/390.2 MB 16.8 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 215.6/390.2 MB 17.2 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 215.8/390.2 MB 16.8 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 216.7/390.2 MB 17.7 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 217.4/390.2 MB 17.7 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 217.9/390.2 MB 16.8 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 218.9/390.2 MB 17.7 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 219.3/390.2 MB 17.7 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 220.0/390.2 MB 17.7 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 220.3/390.2 MB 17.7 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 221.1/390.2 MB 16.8 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 221.4/390.2 MB 17.3 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 221.8/390.2 MB 16.0 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 222.5/390.2 MB 16.4 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 223.4/390.2 MB 16.8 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 223.6/390.2 MB 16.4 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 224.5/390.2 MB 16.8 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 224.9/390.2 MB 16.0 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 225.6/390.2 MB 15.6 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 226.1/390.2 MB 16.4 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 226.8/390.2 MB 16.0 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 227.4/390.2 MB 16.0 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 228.0/390.2 MB 15.6 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 228.9/390.2 MB 16.0 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 228.9/390.2 MB 15.6 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 229.8/390.2 MB 16.0 MB/s eta 0:00:11\n",
      "   ----------------------- --------------- 230.2/390.2 MB 15.2 MB/s eta 0:00:11\n",
      "   ----------------------- --------------- 230.9/390.2 MB 15.6 MB/s eta 0:00:11\n",
      "   ----------------------- --------------- 231.4/390.2 MB 15.2 MB/s eta 0:00:11\n",
      "   ----------------------- --------------- 232.1/390.2 MB 16.8 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 232.5/390.2 MB 15.6 MB/s eta 0:00:11\n",
      "   ----------------------- --------------- 233.6/390.2 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 233.8/390.2 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 234.8/390.2 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 235.0/390.2 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 236.0/390.2 MB 17.2 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 236.5/390.2 MB 16.8 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 237.1/390.2 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 237.8/390.2 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 238.3/390.2 MB 16.8 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 239.5/390.2 MB 17.7 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 239.7/390.2 MB 17.3 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 240.6/390.2 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 241.1/390.2 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 241.6/390.2 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 242.5/390.2 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 242.9/390.2 MB 18.2 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 243.5/390.2 MB 16.8 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 244.3/390.2 MB 18.2 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 245.3/390.2 MB 18.7 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 245.5/390.2 MB 18.2 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 246.5/390.2 MB 18.2 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 246.8/390.2 MB 17.2 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 247.4/390.2 MB 17.3 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 247.9/390.2 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 248.7/390.2 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 249.5/390.2 MB 17.2 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 249.7/390.2 MB 16.8 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 250.8/390.2 MB 17.3 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 251.0/390.2 MB 17.2 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 251.7/390.2 MB 17.3 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 252.3/390.2 MB 16.8 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 252.8/390.2 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 253.3/390.2 MB 16.8 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 254.0/390.2 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 254.7/390.2 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 255.1/390.2 MB 16.0 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 256.2/390.2 MB 16.8 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 256.6/390.2 MB 15.6 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 257.3/390.2 MB 16.8 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 257.5/390.2 MB 15.6 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 258.3/390.2 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 259.0/390.2 MB 16.4 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 259.8/390.2 MB 16.0 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 260.2/390.2 MB 16.0 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 261.1/390.2 MB 15.6 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 261.3/390.2 MB 15.6 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 262.0/390.2 MB 16.0 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 262.6/390.2 MB 16.0 MB/s eta 0:00:08\n",
      "   -------------------------- ------------ 263.1/390.2 MB 16.8 MB/s eta 0:00:08\n",
      "   -------------------------- ------------ 264.0/390.2 MB 16.4 MB/s eta 0:00:08\n",
      "   -------------------------- ------------ 264.1/390.2 MB 15.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 264.8/390.2 MB 16.0 MB/s eta 0:00:08\n",
      "   -------------------------- ------------ 265.2/390.2 MB 15.6 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 265.7/390.2 MB 16.0 MB/s eta 0:00:08\n",
      "   -------------------------- ------------ 266.4/390.2 MB 15.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 266.8/390.2 MB 15.6 MB/s eta 0:00:08\n",
      "   -------------------------- ------------ 267.4/390.2 MB 14.9 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 268.1/390.2 MB 15.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 268.6/390.2 MB 15.6 MB/s eta 0:00:08\n",
      "   -------------------------- ------------ 269.1/390.2 MB 15.2 MB/s eta 0:00:08\n",
      "   -------------------------- ------------ 270.0/390.2 MB 15.2 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 270.7/390.2 MB 15.6 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 271.1/390.2 MB 15.2 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 271.8/390.2 MB 15.6 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 272.3/390.2 MB 15.6 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 272.4/390.2 MB 14.9 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 273.2/390.2 MB 15.2 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 273.5/390.2 MB 14.9 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 274.1/390.2 MB 14.2 MB/s eta 0:00:09\n",
      "   --------------------------- ----------- 274.1/390.2 MB 14.2 MB/s eta 0:00:09\n",
      "   --------------------------- ----------- 274.8/390.2 MB 13.9 MB/s eta 0:00:09\n",
      "   --------------------------- ----------- 275.6/390.2 MB 14.9 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 275.9/390.2 MB 14.6 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 277.2/390.2 MB 15.6 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 277.2/390.2 MB 14.9 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 278.2/390.2 MB 14.9 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 278.7/390.2 MB 15.2 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 279.1/390.2 MB 14.5 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 280.1/390.2 MB 14.9 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 280.7/390.2 MB 14.9 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 281.5/390.2 MB 15.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 282.1/390.2 MB 15.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 282.8/390.2 MB 16.0 MB/s eta 0:00:07\n",
      "   ---------------------------- ---------- 283.1/390.2 MB 15.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 284.3/390.2 MB 16.8 MB/s eta 0:00:07\n",
      "   ---------------------------- ---------- 284.5/390.2 MB 17.7 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 285.5/390.2 MB 18.2 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 286.1/390.2 MB 17.7 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 286.8/390.2 MB 17.7 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 287.5/390.2 MB 18.2 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 287.9/390.2 MB 17.7 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 288.8/390.2 MB 17.2 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 289.1/390.2 MB 17.2 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 289.9/390.2 MB 17.7 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 290.4/390.2 MB 17.7 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 291.2/390.2 MB 17.2 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 291.6/390.2 MB 16.4 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 292.1/390.2 MB 17.2 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 292.9/390.2 MB 16.8 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 293.2/390.2 MB 17.2 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 293.7/390.2 MB 16.4 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 294.4/390.2 MB 16.0 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 294.9/390.2 MB 16.4 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 295.5/390.2 MB 16.0 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 296.1/390.2 MB 15.6 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 296.8/390.2 MB 15.6 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 297.6/390.2 MB 16.0 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 298.0/390.2 MB 15.6 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 298.7/390.2 MB 16.0 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 299.2/390.2 MB 15.2 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 299.6/390.2 MB 16.4 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 300.5/390.2 MB 16.4 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 300.9/390.2 MB 15.6 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 302.0/390.2 MB 16.4 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 302.1/390.2 MB 16.0 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 303.2/390.2 MB 16.4 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 303.4/390.2 MB 16.0 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 304.4/390.2 MB 16.4 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 304.8/390.2 MB 17.2 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 305.6/390.2 MB 16.4 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 306.0/390.2 MB 16.8 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 306.9/390.2 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 307.2/390.2 MB 17.3 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 307.9/390.2 MB 16.4 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 308.6/390.2 MB 16.4 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 309.4/390.2 MB 17.3 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 309.9/390.2 MB 17.3 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 310.6/390.2 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 310.8/390.2 MB 16.4 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 311.7/390.2 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 312.3/390.2 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 312.9/390.2 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 313.7/390.2 MB 17.2 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 314.0/390.2 MB 16.4 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 314.5/390.2 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 315.0/390.2 MB 16.0 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 315.4/390.2 MB 15.2 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 316.1/390.2 MB 16.0 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 316.5/390.2 MB 16.0 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 317.4/390.2 MB 16.0 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 318.0/390.2 MB 16.4 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 318.5/390.2 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 319.2/390.2 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 319.8/390.2 MB 16.4 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 320.3/390.2 MB 16.4 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 320.9/390.2 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 321.4/390.2 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 322.1/390.2 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 322.8/390.2 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 323.2/390.2 MB 16.4 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 323.9/390.2 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 324.5/390.2 MB 16.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 325.0/390.2 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 325.7/390.2 MB 16.8 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 326.0/390.2 MB 16.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 327.0/390.2 MB 16.4 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 327.4/390.2 MB 16.0 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 328.1/390.2 MB 16.4 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 328.9/390.2 MB 16.0 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 329.4/390.2 MB 16.0 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 330.0/390.2 MB 15.6 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 330.6/390.2 MB 16.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 331.4/390.2 MB 16.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 331.5/390.2 MB 16.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 332.3/390.2 MB 16.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 332.6/390.2 MB 15.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 333.0/390.2 MB 15.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 333.3/390.2 MB 14.6 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 334.2/390.2 MB 15.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 334.6/390.2 MB 14.9 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 335.3/390.2 MB 15.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 336.0/390.2 MB 15.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 336.4/390.2 MB 15.6 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 337.0/390.2 MB 15.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 337.7/390.2 MB 15.6 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 338.3/390.2 MB 14.9 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 339.0/390.2 MB 15.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 339.5/390.2 MB 15.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 340.2/390.2 MB 15.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 340.7/390.2 MB 15.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 341.0/390.2 MB 14.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 341.2/390.2 MB 14.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 341.9/390.2 MB 15.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 342.2/390.2 MB 14.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 342.8/390.2 MB 14.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 343.1/390.2 MB 14.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 344.1/390.2 MB 14.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 344.4/390.2 MB 14.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 344.8/390.2 MB 14.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 345.3/390.2 MB 14.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 346.0/390.2 MB 14.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 346.5/390.2 MB 14.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 346.8/390.2 MB 14.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 347.6/390.2 MB 14.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 348.0/390.2 MB 14.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 348.9/390.2 MB 14.6 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 349.0/390.2 MB 13.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 350.0/390.2 MB 13.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 350.4/390.2 MB 13.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 351.2/390.2 MB 14.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 351.2/390.2 MB 14.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 352.6/390.2 MB 16.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 353.0/390.2 MB 15.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 353.8/390.2 MB 15.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 354.2/390.2 MB 14.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 354.7/390.2 MB 15.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 355.2/390.2 MB 15.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 355.8/390.2 MB 16.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 356.1/390.2 MB 14.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 356.8/390.2 MB 15.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 357.3/390.2 MB 15.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 357.6/390.2 MB 14.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 358.7/390.2 MB 15.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 358.7/390.2 MB 14.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 359.4/390.2 MB 15.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 359.4/390.2 MB 15.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 359.4/390.2 MB 15.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 360.1/390.2 MB 13.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 361.6/390.2 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 361.9/390.2 MB 14.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 362.6/390.2 MB 14.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 362.8/390.2 MB 13.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 363.2/390.2 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 363.6/390.2 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 363.6/390.2 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 363.6/390.2 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 363.6/390.2 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 363.6/390.2 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 363.6/390.2 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 363.6/390.2 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 363.6/390.2 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 364.1/390.2 MB 9.9 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 364.9/390.2 MB 10.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 365.1/390.2 MB 10.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 365.1/390.2 MB 10.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 365.1/390.2 MB 10.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 367.5/390.2 MB 10.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 367.8/390.2 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 367.8/390.2 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 367.8/390.2 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 367.8/390.2 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 367.8/390.2 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 368.0/390.2 MB 8.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 369.0/390.2 MB 9.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 369.3/390.2 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 369.3/390.2 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 369.3/390.2 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 369.3/390.2 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 369.3/390.2 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 369.3/390.2 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 369.5/390.2 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 370.3/390.2 MB 8.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 371.4/390.2 MB 8.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 371.8/390.2 MB 7.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 372.5/390.2 MB 7.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 373.5/390.2 MB 8.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 373.5/390.2 MB 8.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 373.5/390.2 MB 7.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- - 374.1/390.2 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 374.1/390.2 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 375.8/390.2 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 376.1/390.2 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 376.7/390.2 MB 10.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 377.5/390.2 MB 9.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 378.1/390.2 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 378.5/390.2 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 378.9/390.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 380.0/390.2 MB 16.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 380.2/390.2 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  381.1/390.2 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  381.5/390.2 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  381.9/390.2 MB 14.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  382.6/390.2 MB 14.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  382.9/390.2 MB 14.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  383.8/390.2 MB 14.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  383.9/390.2 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.5/390.2 MB 16.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/390.2 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.8/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  386.3/390.2 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  387.3/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  387.5/390.2 MB 14.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  388.3/390.2 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  388.9/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  389.4/390.2 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.2 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 390.2/390.2 MB 7.0 MB/s eta 0:00:00\n",
      "Downloading numpy-2.0.2-cp311-cp311-win_amd64.whl (15.9 MB)\n",
      "   ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.4/15.9 MB 8.0 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.5/15.9 MB 10.2 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.6/15.9 MB 5.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.6/15.9 MB 18.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.6/15.9 MB 22.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.6/15.9 MB 22.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.6/15.9 MB 22.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.6/15.9 MB 22.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.6/15.9 MB 22.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.6/15.9 MB 22.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.6/15.9 MB 22.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.6/15.9 MB 22.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.8/15.9 MB 9.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.0/15.9 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.0/15.9 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.0/15.9 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.0/15.9 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.0/15.9 MB 10.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.9/15.9 MB 8.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.4/15.9 MB 8.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.6/15.9 MB 8.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.7/15.9 MB 8.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.8/15.9 MB 7.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 7.0/15.9 MB 7.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.2/15.9 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.5/15.9 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.6/15.9 MB 7.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.9/15.9 MB 7.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 8.1/15.9 MB 7.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 8.3/15.9 MB 7.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.7/15.9 MB 7.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.2/15.9 MB 7.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.2/15.9 MB 7.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.2/15.9 MB 7.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.2/15.9 MB 7.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.2/15.9 MB 7.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.2/15.9 MB 7.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.9 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.9 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.9 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.9 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.9 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.9 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.9 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.9 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.9 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.9 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.9 MB 8.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.5/15.9 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.7/15.9 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.1/15.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.5/15.9 MB 7.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 15.0/15.9 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.9 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.9/15.9 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.9/15.9 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/5.5 MB 20.5 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.0/5.5 MB 16.4 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.1/5.5 MB 18.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.3/5.5 MB 23.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.6/5.5 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 17.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.3/5.5 MB 21.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 20.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 18.5 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, tensorboard, tensorflow-intel, tensorflow, tf-keras\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.17.1\n",
      "    Uninstalling tensorboard-2.17.1:\n",
      "      Successfully uninstalled tensorboard-2.17.1\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.17.0\n",
      "    Uninstalling tensorflow-intel-2.17.0:\n",
      "      Successfully uninstalled tensorflow-intel-2.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\dezri\\\\anaconda3\\\\Lib\\\\site-packages\\\\~ensorflow\\\\compiler\\\\mlir\\\\lite\\\\python\\\\_pywrap_converter_api.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4e541d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\dezri\\anaconda3\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: langchain-huggingface in c:\\users\\dezri\\anaconda3\\lib\\site-packages (0.1.1)\n",
      "Collecting tf-keras\n",
      "  Obtaining dependency information for tf-keras from https://files.pythonhosted.org/packages/8a/ed/e08afca471299b04a34cd548e64e89d0153eda0e6cf9b715356777e24774/tf_keras-2.18.0-py3-none-any.whl.metadata\n",
      "  Using cached tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.14 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain) (0.3.14)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain) (0.3.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain) (0.1.138)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Obtaining dependency information for numpy<2,>=1 from https://files.pythonhosted.org/packages/3f/6b/5610004206cf7f8e7ad91c5a85a8c71b2f2f8051a0c0c4d5916b76d6cbb2/numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/61.0 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/61.0 kB 330.3 kB/s eta 0:00:01\n",
      "     ------------------------- ------------ 41.0/61.0 kB 393.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.0/61.0 kB 466.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-huggingface) (0.26.2)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-huggingface) (3.2.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-huggingface) (0.20.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-huggingface) (4.46.1)\n",
      "Collecting tensorflow<2.19,>=2.18 (from tf-keras)\n",
      "  Obtaining dependency information for tensorflow<2.19,>=2.18 from https://files.pythonhosted.org/packages/cf/24/271e77c22724f370c24c705f394b8035b4d27e4c2c6339f3f45ab9b8258e/tensorflow-2.18.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached tensorflow-2.18.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.14->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.11.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.0.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.25.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.5.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.31.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2022.7.9)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n",
      "Requirement already satisfied: anyio in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.14->langchain) (2.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (2.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.38.4)\n",
      "Requirement already satisfied: rich in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (13.8.0)\n",
      "Requirement already satisfied: namex in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.12.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dezri\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.0)\n",
      "Using cached tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/15.8 MB 2.6 MB/s eta 0:00:06\n",
      "    --------------------------------------- 0.3/15.8 MB 4.5 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.7/15.8 MB 6.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.3/15.8 MB 9.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.8/15.8 MB 10.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 2.3/15.8 MB 10.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 3.0/15.8 MB 12.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.6/15.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 4.1/15.8 MB 13.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 4.4/15.8 MB 12.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 4.5/15.8 MB 12.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 4.6/15.8 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 4.7/15.8 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.0/15.8 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.2/15.8 MB 9.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.3/15.8 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.4/15.8 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.7/15.8 MB 12.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.6/15.8 MB 12.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.6/15.8 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.7/15.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.6/15.8 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.7/15.8 MB 13.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 13.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.6/15.8 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.4/15.8 MB 13.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.8 MB 13.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.3/15.8 MB 13.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.8/15.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.3/15.8 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.8/15.8 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.4/15.8 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.6/15.8 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 13.9 MB/s eta 0:00:00\n",
      "Using cached tensorflow-2.18.0-cp311-cp311-win_amd64.whl (7.5 kB)\n",
      "Installing collected packages: numpy, tensorflow, tf-keras\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.17.0\n",
      "    Uninstalling tensorflow-2.17.0:\n",
      "      Successfully uninstalled tensorflow-2.17.0\n",
      "Successfully installed numpy-1.26.4 tensorflow-2.18.0 tf-keras-2.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-huggingface tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6a9f779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.11.0\n",
      "  Obtaining dependency information for keras==2.11.0 from https://files.pythonhosted.org/packages/de/44/bf1b0eef5b13e6201aef076ff34b91bc40aace8591cd273c1c2a94a9cc00/keras-2.11.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.7 MB 330.3 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.1/1.7 MB 469.7 kB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.2/1.7 MB 1.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.3/1.7 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.1/1.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.5/1.7 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 5.1 MB/s eta 0:00:00\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.5.0\n",
      "    Uninstalling keras-3.5.0:\n",
      "      Successfully uninstalled keras-3.5.0\n",
      "Successfully installed keras-2.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.18.0 requires keras>=3.5.0, but you have keras 2.11.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install keras==2.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ae01abe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from datasets import load_dataset\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cdb62a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e768a45d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tf_keras\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tf_keras\\__internal__\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tf_keras\\__internal__\\backend\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the TF-Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\applications\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Applications are premade architectures with pre-trained weights.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtBase\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtLarge\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\applications\\convnext.py:26\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\__init__.py:85\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen_data_flow_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_stitch \u001b[38;5;66;03m# line: 827\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen_experimental_dataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_pinned \u001b[38;5;66;03m# line: 725\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen_linalg_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m matrix_square_root \u001b[38;5;66;03m# line: 2108\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'check_pinned' from 'tensorflow.python.ops.gen_experimental_dataset_ops' (C:\\Users\\dezri\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_experimental_dataset_ops.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1778\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:38\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n",
      "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1778\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\integrations\\integration_utils.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1766\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1766\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1767\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1780\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1781\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1783\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Load the Hugging Face Embeddings model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;66;03m##Notes##\u001b[39;00m\n\u001b[0;32m      3\u001b[0m    \u001b[38;5;66;03m# Code Purpose: loads a pre-trained sentence transformer model called \"all-mpnet-base-v2\" from Hugging Face.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m    \u001b[38;5;66;03m# Model insight: \"all-mpnet-base-v2\" is used to convert text (in this case, resume content) into numerical vectors called embeddings.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m    \u001b[38;5;66;03m# Functionality: Embeddings capture the semantic meaning of the text, allowing you to compare the similarity between different pieces of text based on their vector representations.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall-mpnet-base-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 2. Load the more_resumes dataset\u001b[39;00m\n\u001b[0;32m      9\u001b[0m   \u001b[38;5;66;03m# Assumption about dataset: Assuming 'more_resumes.json' is in the current directory\u001b[39;00m\n\u001b[0;32m     10\u001b[0m more_resumes \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspacy_redacted_documents_with_id_and_category.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     emit_warning()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:84\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     warn_deprecated(\n\u001b[0;32m     75\u001b[0m         since\u001b[38;5;241m=\u001b[39msince,\n\u001b[0;32m     76\u001b[0m         removal\u001b[38;5;241m=\u001b[39mremoval,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m constructor instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     81\u001b[0m     )\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_dynamic_quantized_onnx_model, export_optimized_onnx_model\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceTransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fullname, get_device_name, import_from_string\n\u001b[0;32m     23\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torch_npu_available\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_class_from_dynamic_module, get_relative_import_files\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerModelCardData, generate_model_card\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimilarity_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimilarityFunction\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __MODEL_HUB_ORGANIZATION__, __version__\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\model_card.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerCallback\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeCarbonCallback\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelcard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_markdown_table\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_callback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerControl, TrainerState\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1766\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1764\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1766\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1767\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1780\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1781\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1783\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Load the Hugging Face Embeddings model\n",
    "  ##Notes##\n",
    "   # Code Purpose: loads a pre-trained sentence transformer model called \"all-mpnet-base-v2\" from Hugging Face.\n",
    "   # Model insight: \"all-mpnet-base-v2\" is used to convert text (in this case, resume content) into numerical vectors called embeddings.\n",
    "   # Functionality: Embeddings capture the semantic meaning of the text, allowing you to compare the similarity between different pieces of text based on their vector representations.\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "\n",
    "# 2. Load the more_resumes dataset\n",
    "  # Assumption about dataset: Assuming 'more_resumes.json' is in the current directory\n",
    "more_resumes = pd.read_csv('spacy_redacted_documents_with_id_and_category.csv')\n",
    "\n",
    "# 3. Split resumes into smaller chunks for embedding\n",
    "  #Code purpose: Divides each resume's text content into smaller chunks to handle potentially large documents.\n",
    "  # Functionality: RecursiveCharacterTextSplitter: This object is used to split the text. It's configured to create\n",
    "  # chunks of approximately 1000 characters with an overlap of 200 characters between chunks.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = []\n",
    "for resume in more_resumes['train']:\n",
    "    texts = text_splitter.split_text(resume['text'])\n",
    "    # Create Document objects instead of dictionaries\n",
    "    docs.extend([Document(page_content=t, metadata={'source': resume['Category']}) for t in texts])\n",
    "\n",
    "# 4. Embed the resume chunks and store them in a FAISS vectorstore\n",
    "  #Purpose: Purpose: Creates a vector database using FAISS (Facebook AI Similarity Search) and\n",
    "  # stores the embeddings of the resume chunks in it.\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "db.save_local(\"more_resumes_faiss\")\n",
    "\n",
    "# Now the 'more_resumes' dataset is embedded and stored in a FAISS vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9604f711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
