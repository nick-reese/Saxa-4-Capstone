{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39244000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nicholasreese/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/nicholasreese/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "from docx import Document\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import pdfplumber\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from textblob import TextBlob\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import os\n",
    "import json\n",
    "from docx import Document\n",
    "import pdfplumber\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "from plotly.offline import plot\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e044a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a22515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasreese/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning:\n",
      "\n",
      "`torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6b32b0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54816c",
   "metadata": {},
   "source": [
    "## Loading the Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3099f737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4731618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = \"\"\"\n",
    "\n",
    "Nicholas E. Reese\n",
    "Van Ness, Washington D.C.\n",
    "412-216-2398\n",
    "Nicholas.E.Reese15@gmail.com \n",
    "Education \n",
    "•Georgetown University - August 2023 – December 2024\n",
    "Master of Science Business Analytics – MSBA candidate\n",
    "Peer-Elected Class Representative \n",
    "•Dickinson College - August 2014 – September 2018\n",
    "Economics & Political Science Double Major\n",
    "Varsity Tennis Captain \n",
    "•University of Bologna - August 2016\n",
    "\n",
    "Skills\n",
    "- R studio\n",
    "- Python\n",
    "- Power BI\n",
    "- SQL\n",
    "- Neural Networks\n",
    "- Machine Learning\n",
    "- Macro Modeling\n",
    "- AWS Cloud Services\n",
    "- Pandas\n",
    "- A/B Testing\n",
    "- Scikit-Learn\n",
    "- Econometrics\n",
    "\n",
    "Professional Experience\n",
    "FINRA, Washington, D.C.\tJune 2020 – Present \n",
    "Senior Analyst, Market Regulation\tSeptember 2022 – Present \n",
    "•Earned top 10% of performance of analysts for past two years.\n",
    "•Led team in research implementing PostgreSQL and NoSQL queries for large data pulls.\n",
    "•Spearheaded new analytical approaches to financial workflow with tools such as R & Python for model development.\n",
    "•Developed working predictive modeling schemas for senior staff using statistical analysis.\n",
    "•Leveraged skills in platforms like Python, R, Power BI, Tableau and SQL accompanied with strong statistical background in financial markets.\n",
    "•Built the Security-Based Swap training manual deck & produced the recorded info session for all of FINRA. \n",
    "•Selected for the FINRA’s first Georgetown Advanced Analytics Program as one of the most junior staff awarded opportunity.\n",
    "•Incorporated statistical analytics to assist in creating a NPL tool to analyze financial documents language to minimize time on manual analysis.\n",
    "•Produced unsupervised and supervised models to perform analysis for Security-Based Swaps trade patterns.\n",
    "•Improved FINRA platforms with Data Scientists for higher accuracy and efficiency. \n",
    "•Managed process of re-engineering supervisory reviews through advanced analytic tools for senior staff.\n",
    "•Implements advanced analytics to assist senior staff with maximizing efficiencies in daily workloads and trade pattern creations.\n",
    "•Presented visualization case work using Power BI & Tableau to senior leadership.\n",
    "•Persuaded senior staff to allow for statistical analytics tools like R.\n",
    "•Mentored over 20 junior & senior staff members on improving processes with analytical tools for financial reviews.\n",
    "•Managed junior staff with day-to-day workload while teaching the staff how to use advanced analytics.\n",
    "Analyst, Market Regulation\tJune 2021-September 2022\n",
    "·Created macroeconomic models for newly implemented FINRA Rule 2232 and MSRB Rule G-15.\n",
    "·Mentored junior staff with creating macro models, synthesizing responses from FINRA member firms.\n",
    "·Won the Regulator Scholarship for continued financial learning based on individual performance.\n",
    "·Received six internal awards for expertise in Municipal and Corporate Bond analysis as an analyst.\n",
    "Associate Analyst, Market Regulation\tJune 2020 – June 2021\n",
    "·Created macroeconomic models to quantify business models of selected firms for FINRA Rule 2232.\n",
    "             BNY Mellon, Pittsburgh, PA\t\t\t\t\t\t                 September 2019 – June 2020\n",
    "Corporate Trust Associate\n",
    "·Leader & instructor of the Bloomberg software for the Corporate Trust Team.\n",
    "LendingHome, Internship, Pittsburgh, PA\n",
    "Funding Specialist & Post Closing Member\tMarch 2019 – August 2019\n",
    "·Reviewed closing documents to ensure precise execution for funding staff.\n",
    "              Veraction/Trax, Junior Business Analyst, Memphis, TN\t  June 2016 - August 2016                                                    June 2016 - August 2016\n",
    "·Led the creation, development, and implementation of Request For Proposal (RFP) database.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16774b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resume_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf437695",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93d14c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ffe6ca6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "ner_pipeline = pipeline('ner', model = \"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "                       aggregation_strategy = 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0187db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = ner_pipeline(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90ee7beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Nicholas E, Label: PER, Score: 0.8347\n",
      "Entity: Reese, Label: PER, Score: 0.8619\n",
      "Entity: Van Ness, Label: LOC, Score: 0.6532\n",
      "Entity: Washington D, Label: LOC, Score: 0.9981\n",
      "Entity: C, Label: LOC, Score: 0.9990\n",
      "Entity: Nicholas, Label: PER, Score: 0.9735\n",
      "Entity: E, Label: PER, Score: 0.6905\n",
      "Entity: Reese, Label: PER, Score: 0.9786\n",
      "Entity: Georgetown University, Label: ORG, Score: 0.9974\n",
      "Entity: Science, Label: MISC, Score: 0.7188\n",
      "Entity: Business, Label: ORG, Score: 0.3938\n",
      "Entity: ##tics, Label: MISC, Score: 0.6904\n",
      "Entity: MS, Label: MISC, Score: 0.6772\n",
      "Entity: ##BA, Label: ORG, Score: 0.6136\n",
      "Entity: Dickinson College, Label: ORG, Score: 0.9974\n",
      "Entity: & Political, Label: ORG, Score: 0.6406\n",
      "Entity: Science, Label: MISC, Score: 0.6226\n",
      "Entity: University of Bologna, Label: ORG, Score: 0.9910\n",
      "Entity: Python, Label: MISC, Score: 0.7331\n",
      "Entity: B, Label: MISC, Score: 0.3749\n",
      "Entity: S, Label: MISC, Score: 0.4090\n",
      "Entity: N, Label: MISC, Score: 0.3621\n",
      "Entity: Networks, Label: MISC, Score: 0.5680\n",
      "Entity: AWS, Label: ORG, Score: 0.8358\n",
      "Entity: E, Label: MISC, Score: 0.4678\n",
      "Entity: FINRA, Label: ORG, Score: 0.9555\n",
      "Entity: Washington, Label: LOC, Score: 0.9981\n",
      "Entity: D, Label: LOC, Score: 0.9980\n",
      "Entity: C, Label: LOC, Score: 0.9992\n",
      "Entity: Regulation, Label: ORG, Score: 0.4722\n",
      "Entity: PostgreSQL, Label: MISC, Score: 0.8554\n",
      "Entity: NoSQL, Label: MISC, Score: 0.9255\n",
      "Entity: R, Label: MISC, Score: 0.9847\n",
      "Entity: Python, Label: MISC, Score: 0.9538\n",
      "Entity: Python, Label: MISC, Score: 0.9085\n",
      "Entity: R, Label: MISC, Score: 0.7607\n",
      "Entity: Power, Label: ORG, Score: 0.4565\n",
      "Entity: BI, Label: MISC, Score: 0.4526\n",
      "Entity: Table, Label: ORG, Score: 0.5572\n",
      "Entity: ##au, Label: MISC, Score: 0.5457\n",
      "Entity: S, Label: MISC, Score: 0.8331\n",
      "Entity: Based S, Label: MISC, Score: 0.8241\n",
      "Entity: FINRA, Label: ORG, Score: 0.9622\n",
      "Entity: FINRA, Label: ORG, Score: 0.9660\n",
      "Entity: Georgetown Advanced Analytics Program, Label: MISC, Score: 0.7878\n",
      "Entity: Based Swa, Label: MISC, Score: 0.8259\n",
      "Entity: FINRA, Label: ORG, Score: 0.9642\n",
      "Entity: Data, Label: ORG, Score: 0.6258\n"
     ]
    }
   ],
   "source": [
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7b1f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_entities = [entity for entity in entities if entity['entity_group'] != 'MISC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "011758b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Nicholas E, Label: PER, Score: 0.8347\n",
      "Entity: Reese, Label: PER, Score: 0.8619\n",
      "Entity: Van Ness, Label: LOC, Score: 0.6532\n",
      "Entity: Washington D, Label: LOC, Score: 0.9981\n",
      "Entity: C, Label: LOC, Score: 0.9990\n",
      "Entity: Nicholas, Label: PER, Score: 0.9735\n",
      "Entity: E, Label: PER, Score: 0.6905\n",
      "Entity: Reese, Label: PER, Score: 0.9786\n",
      "Entity: Georgetown University, Label: ORG, Score: 0.9974\n",
      "Entity: Business, Label: ORG, Score: 0.3938\n",
      "Entity: ##BA, Label: ORG, Score: 0.6136\n",
      "Entity: Dickinson College, Label: ORG, Score: 0.9974\n",
      "Entity: & Political, Label: ORG, Score: 0.6406\n",
      "Entity: University of Bologna, Label: ORG, Score: 0.9910\n",
      "Entity: AWS, Label: ORG, Score: 0.8358\n",
      "Entity: FINRA, Label: ORG, Score: 0.9555\n",
      "Entity: Washington, Label: LOC, Score: 0.9981\n",
      "Entity: D, Label: LOC, Score: 0.9980\n",
      "Entity: C, Label: LOC, Score: 0.9992\n",
      "Entity: Regulation, Label: ORG, Score: 0.4722\n",
      "Entity: Power, Label: ORG, Score: 0.4565\n",
      "Entity: Table, Label: ORG, Score: 0.5572\n",
      "Entity: FINRA, Label: ORG, Score: 0.9622\n",
      "Entity: FINRA, Label: ORG, Score: 0.9660\n",
      "Entity: FINRA, Label: ORG, Score: 0.9642\n",
      "Entity: Data, Label: ORG, Score: 0.6258\n"
     ]
    }
   ],
   "source": [
    "for entity in filtered_entities:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e21cd27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nicholas.E.Reese15@gmail.com']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Regex pattern for email extraction\n",
    "email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "\n",
    "# Find all email addresses in the text\n",
    "emails = re.findall(email_pattern, resume_text)\n",
    "\n",
    "# Display found email addresses\n",
    "print(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98760ee5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Nicholas E, Label: PER, Score: 0.8347\n",
      "Entity: Reese, Label: PER, Score: 0.8619\n",
      "Entity: Van Ness, Label: LOC, Score: 0.6532\n",
      "Entity: Washington D, Label: LOC, Score: 0.9981\n",
      "Entity: C, Label: LOC, Score: 0.9990\n",
      "Entity: Nicholas, Label: PER, Score: 0.9735\n",
      "Entity: E, Label: PER, Score: 0.6905\n",
      "Entity: Reese, Label: PER, Score: 0.9786\n",
      "Entity: Georgetown University, Label: ORG, Score: 0.9974\n",
      "Entity: Science, Label: MISC, Score: 0.7188\n",
      "Entity: Business, Label: ORG, Score: 0.3938\n",
      "Entity: ##tics, Label: MISC, Score: 0.6904\n",
      "Entity: MS, Label: MISC, Score: 0.6772\n",
      "Entity: ##BA, Label: ORG, Score: 0.6136\n",
      "Entity: Dickinson College, Label: ORG, Score: 0.9974\n",
      "Entity: & Political, Label: ORG, Score: 0.6406\n",
      "Entity: Science, Label: MISC, Score: 0.6226\n",
      "Entity: University of Bologna, Label: ORG, Score: 0.9910\n",
      "Entity: Python, Label: MISC, Score: 0.7331\n",
      "Entity: B, Label: MISC, Score: 0.3749\n",
      "Entity: S, Label: MISC, Score: 0.4090\n",
      "Entity: N, Label: MISC, Score: 0.3621\n",
      "Entity: Networks, Label: MISC, Score: 0.5680\n",
      "Entity: AWS, Label: ORG, Score: 0.8358\n",
      "Entity: E, Label: MISC, Score: 0.4678\n",
      "Entity: FINRA, Label: ORG, Score: 0.9555\n",
      "Entity: Washington, Label: LOC, Score: 0.9981\n",
      "Entity: D, Label: LOC, Score: 0.9980\n",
      "Entity: C, Label: LOC, Score: 0.9992\n",
      "Entity: Regulation, Label: ORG, Score: 0.4722\n",
      "Entity: PostgreSQL, Label: MISC, Score: 0.8554\n",
      "Entity: NoSQL, Label: MISC, Score: 0.9255\n",
      "Entity: R, Label: MISC, Score: 0.9847\n",
      "Entity: Python, Label: MISC, Score: 0.9538\n",
      "Entity: Python, Label: MISC, Score: 0.9085\n",
      "Entity: R, Label: MISC, Score: 0.7607\n",
      "Entity: Power, Label: ORG, Score: 0.4565\n",
      "Entity: BI, Label: MISC, Score: 0.4526\n",
      "Entity: Table, Label: ORG, Score: 0.5572\n",
      "Entity: ##au, Label: MISC, Score: 0.5457\n",
      "Entity: S, Label: MISC, Score: 0.8331\n",
      "Entity: Based S, Label: MISC, Score: 0.8241\n",
      "Entity: FINRA, Label: ORG, Score: 0.9622\n",
      "Entity: FINRA, Label: ORG, Score: 0.9660\n",
      "Entity: Georgetown Advanced Analytics Program, Label: MISC, Score: 0.7878\n",
      "Entity: Based Swa, Label: MISC, Score: 0.8259\n",
      "Entity: FINRA, Label: ORG, Score: 0.9642\n",
      "Entity: Data, Label: ORG, Score: 0.6258\n"
     ]
    }
   ],
   "source": [
    "# Load the NER pipeline\n",
    "ner_pipeline2 = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", aggregation_strategy=\"simple\")\n",
    "\n",
    "\n",
    "# Detect entities using the NER pipeline\n",
    "entities2 = ner_pipeline2(resume_text)\n",
    "\n",
    "# Regex pattern for email extraction\n",
    "email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "\n",
    "# Find all email addresses in the text\n",
    "emails = re.findall(email_pattern, resume_text)\n",
    "\n",
    "# Print detected entities from NER\n",
    "for entity in entities2:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70122958",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11f2148",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46f571a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_test = \"\"\"\n",
    "Nicholas E. Reese\n",
    "Van Ness, Washington D.C.\n",
    "412-216-2398\n",
    "Nicholas.E.Reese@gmail.com\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50f461d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = ner_pipeline(resume_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "268f9cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Nicholas E. Reese Van Ness, Label: PER, Score: 0.8019\n",
      "Entity: Washington D, Label: LOC, Score: 0.9986\n",
      "Entity: C, Label: LOC, Score: 0.9995\n",
      "Entity: Nicholas, Label: PER, Score: 0.9980\n",
      "Entity: E. Reese, Label: PER, Score: 0.9686\n"
     ]
    }
   ],
   "source": [
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dbf5488",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds ={\n",
    "    'PER': .7,\n",
    "    'ORG': .8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fb17583",
   "metadata": {},
   "outputs": [],
   "source": [
    "redacted_text = resume_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "492bfc59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nicholas E. Reese\n",
      "Van Ness, Washington D.C.\n",
      "412-216-2398\n",
      "[Redacted Email]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for entity in entities:\n",
    "    entity_type = entity['entity_group']\n",
    "    score = entity['score']\n",
    "    \n",
    "    if entity_type == entity and score >= thresholds[entity]:\n",
    "        entity_text = entity['word']\n",
    "        redacted_text = re.sub(re.escape(entity_text), '[Redacted]', redacted_text)\n",
    "\n",
    "# Redact the email addresses\n",
    "redacted_text = re.sub(r'\\S+@\\S+', '[Redacted Email]', redacted_text)\n",
    "\n",
    "\n",
    "\n",
    "print(redacted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a9f30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(redacted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "946c1d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_test = \"\"\"\n",
    "Nicholas E. Reese\n",
    "Van Ness, Washington D.C.\n",
    "412-216-2398\n",
    "Nicholas.E.Reese@gmail.com\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b74c05ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = ner_pipeline(resume_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae978beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Nicholas E. Reese Van Ness, Label: PER, Score: 0.8019\n",
      "Entity: Washington D, Label: LOC, Score: 0.9986\n",
      "Entity: C, Label: LOC, Score: 0.9995\n",
      "Entity: Nicholas, Label: PER, Score: 0.9980\n",
      "Entity: E. Reese, Label: PER, Score: 0.9686\n"
     ]
    }
   ],
   "source": [
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ff796a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds ={\n",
    "    'PER': .8,\n",
    "    'ORG': .9,\n",
    "    'LOC': .8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbdce68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "redacted_text = resume_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83ac3a76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entities_sorted = sorted(entities, key=lambda x: len(x['word']), reverse=True)\n",
    "\n",
    "\n",
    "for entity in entities_sorted:\n",
    "    entity_type = entity['entity_group']\n",
    "    score = entity['score']\n",
    "    \n",
    "    if entity_type == entity_type and score >= thresholds[entity_type]:\n",
    "        entity_text = entity['word']\n",
    "        redacted_text = re.sub(re.escape(entity_text), '[Redacted]', redacted_text)\n",
    "\n",
    "\n",
    "        \n",
    "for entity in entities_sorted:\n",
    "    entity_type = entity['entity_group']\n",
    "    score = entity['score']\n",
    "    \n",
    "    if entity_type in thresholds and score >= thresholds[entity_type]:\n",
    "        entity_text = entity['word']\n",
    "        # Make sure to redact the smaller parts again if needed\n",
    "        redacted_text = re.sub(re.escape(entity_text), '[Redacted]', redacted_text)\n",
    "\n",
    "# Redact the email addresses and phone numbers \n",
    "redacted_text = re.sub(r'\\S+@\\S+', '[Redacted Email]', redacted_text)\n",
    "redacted_text = re.sub(r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}', '[Redacted Phone]', redacted_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fc7b19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Redacted] [Redacted]\n",
      "Van Ness, [Redacted].[Redacted].\n",
      "[Redacted Phone]\n",
      "[Redacted Email]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(redacted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1296530",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da53cf3d",
   "metadata": {},
   "source": [
    "## Adding In Resumes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b82d228a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added .docx: Genesis Roberto 2024 Resume.docx\n",
      "Added .docx: Jonathan J Saville resume.docx\n",
      "Added .pdf: Dezmond Richardson GU Q3.2024 Resume.docx.pdf\n",
      "Added .docx: Nicholas Reese Resume .docx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from docx import Document\n",
    "import pdfplumber\n",
    "\n",
    "def convert_files_to_json(folder_path, output_json_file):\n",
    "    corpus = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Skip temporary files created by Word\n",
    "        if filename.startswith('~$'):\n",
    "            print(f\"Skipped temporary file: {filename}\")\n",
    "            continue\n",
    "        \n",
    "        if filename.endswith('.docx'):\n",
    "            try:\n",
    "                doc = Document(file_path)\n",
    "                text = '\\n'.join([para.text for para in doc.paragraphs])\n",
    "                document_data = {\n",
    "                    'title': filename,\n",
    "                    'text': text, \n",
    "                    'type': 'word',\n",
    "                    'file_path': file_path\n",
    "                }\n",
    "                corpus.append(document_data)\n",
    "                print(f\"Added .docx: {filename}\") \n",
    "        \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing .docx file {filename}: {e}\")\n",
    "        \n",
    "        elif filename.endswith('.pdf'):\n",
    "            try:\n",
    "                with pdfplumber.open(file_path) as pdf:\n",
    "                    text = '\\n'.join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
    "                    document_data = {\n",
    "                        'title': filename, \n",
    "                        'text': text,\n",
    "                        'type': 'pdf',\n",
    "                        'file_path': file_path\n",
    "                    }\n",
    "                    corpus.append(document_data)\n",
    "                    print(f\"Added .pdf: {filename}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing .pdf file {filename}: {e}\")\n",
    "                \n",
    "    with open(output_json_file, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(corpus, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Call the function with your paths\n",
    "convert_files_to_json('/Users/nicholasreese/Desktop/Georgetown/Capstone/capstone_github/Capstone_Introduction/Saxa-4-Capstone', 'output_corpus.json')\n",
    "# change your file path to where you saved the resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1408929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = pd.read_json('output_corpus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7942dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = pd.DataFrame(resumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67fa0945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genesis Roberto 2024 Resume.docx</td>\n",
       "      <td>Ms. Genesis U. Roberto \\n     Rockville, MD   ...</td>\n",
       "      <td>word</td>\n",
       "      <td>/Users/nicholasreese/Desktop/Georgetown/Capsto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jonathan J Saville resume.docx</td>\n",
       "      <td>Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...</td>\n",
       "      <td>word</td>\n",
       "      <td>/Users/nicholasreese/Desktop/Georgetown/Capsto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dezmond Richardson GU Q3.2024 Resume.docx.pdf</td>\n",
       "      <td>D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...</td>\n",
       "      <td>pdf</td>\n",
       "      <td>/Users/nicholasreese/Desktop/Georgetown/Capsto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nicholas Reese Resume .docx</td>\n",
       "      <td>Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...</td>\n",
       "      <td>word</td>\n",
       "      <td>/Users/nicholasreese/Desktop/Georgetown/Capsto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0               Genesis Roberto 2024 Resume.docx   \n",
       "1                 Jonathan J Saville resume.docx   \n",
       "2  Dezmond Richardson GU Q3.2024 Resume.docx.pdf   \n",
       "3                    Nicholas Reese Resume .docx   \n",
       "\n",
       "                                                text  type  \\\n",
       "0  Ms. Genesis U. Roberto \\n     Rockville, MD   ...  word   \n",
       "1  Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...  word   \n",
       "2  D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...   pdf   \n",
       "3  Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...  word   \n",
       "\n",
       "                                           file_path  \n",
       "0  /Users/nicholasreese/Desktop/Georgetown/Capsto...  \n",
       "1  /Users/nicholasreese/Desktop/Georgetown/Capsto...  \n",
       "2  /Users/nicholasreese/Desktop/Georgetown/Capsto...  \n",
       "3  /Users/nicholasreese/Desktop/Georgetown/Capsto...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cb07008",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = resumes.drop('file_path', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0038752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genesis Roberto 2024 Resume.docx</td>\n",
       "      <td>Ms. Genesis U. Roberto \\n     Rockville, MD   ...</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jonathan J Saville resume.docx</td>\n",
       "      <td>Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dezmond Richardson GU Q3.2024 Resume.docx.pdf</td>\n",
       "      <td>D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...</td>\n",
       "      <td>pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nicholas Reese Resume .docx</td>\n",
       "      <td>Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0               Genesis Roberto 2024 Resume.docx   \n",
       "1                 Jonathan J Saville resume.docx   \n",
       "2  Dezmond Richardson GU Q3.2024 Resume.docx.pdf   \n",
       "3                    Nicholas Reese Resume .docx   \n",
       "\n",
       "                                                text  type  \n",
       "0  Ms. Genesis U. Roberto \\n     Rockville, MD   ...  word  \n",
       "1  Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...  word  \n",
       "2  D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...   pdf  \n",
       "3  Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...  word  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2382fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d168efe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "ner_pipeline = pipeline('ner', model = \"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "                       aggregation_strategy = 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e060ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes['text_list'] = resumes['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3ce5a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes['clean_text'] = resumes['text'].fillna(\"\").astype(str)\n",
    "\n",
    "resume_text = resumes['clean_text'].tolist()\n",
    "\n",
    "entities = ner_pipeline(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eac2df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = resumes.drop('text_clean', axis = 1)\n",
    "resumes = resumes.drop('text_list', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c90f5630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genesis Roberto 2024 Resume.docx</td>\n",
       "      <td>Ms. Genesis U. Roberto \\n     Rockville, MD   ...</td>\n",
       "      <td>word</td>\n",
       "      <td>Ms. Genesis U. Roberto \\n     Rockville, MD   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jonathan J Saville resume.docx</td>\n",
       "      <td>Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...</td>\n",
       "      <td>word</td>\n",
       "      <td>Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dezmond Richardson GU Q3.2024 Resume.docx.pdf</td>\n",
       "      <td>D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...</td>\n",
       "      <td>pdf</td>\n",
       "      <td>D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nicholas Reese Resume .docx</td>\n",
       "      <td>Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...</td>\n",
       "      <td>word</td>\n",
       "      <td>Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0               Genesis Roberto 2024 Resume.docx   \n",
       "1                 Jonathan J Saville resume.docx   \n",
       "2  Dezmond Richardson GU Q3.2024 Resume.docx.pdf   \n",
       "3                    Nicholas Reese Resume .docx   \n",
       "\n",
       "                                                text  type  \\\n",
       "0  Ms. Genesis U. Roberto \\n     Rockville, MD   ...  word   \n",
       "1  Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...  word   \n",
       "2  D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...   pdf   \n",
       "3  Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...  word   \n",
       "\n",
       "                                          clean_text  \n",
       "0  Ms. Genesis U. Roberto \\n     Rockville, MD   ...  \n",
       "1  Jonathan J Saville\\n503 Edwards Ave, Apt #7   ...  \n",
       "2  D R\\nEZMOND ICHARDSON\\nddr34@georgetown.edu ▪ ...  \n",
       "3  Nicholas E. Reese\\nVan Ness, Washington D.C.\\n...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ae524ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_pipeline = pipeline('ner', model = \"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "                       aggregation_strategy = 'simple')\n",
    "\n",
    "#entities = ner_pipeline(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d18a29f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Genesis U. Roberto Rockville, Label: PER, Score: 0.9323\n",
      "Entity: MD, Label: LOC, Score: 0.9810\n",
      "Entity: MD, Label: LOC, Score: 0.9903\n",
      "Entity: VA, Label: LOC, Score: 0.9143\n",
      "Entity: US GAAP, Label: MISC, Score: 0.7830\n",
      "Entity: SOX, Label: ORG, Score: 0.8475\n",
      "Entity: M & A, Label: ORG, Score: 0.8706\n",
      "Entity: Master, Label: MISC, Score: 0.4755\n",
      "Entity: Analysis, Label: MISC, Score: 0.4144\n",
      "Entity: Georgetown University, Label: ORG, Score: 0.9939\n",
      "Entity: Saggar, Label: PER, Score: 0.9326\n",
      "Entity: Rosenberg, Label: PER, Score: 0.9968\n",
      "Entity: Rockville, Label: LOC, Score: 0.9400\n",
      "Entity: MD, Label: LOC, Score: 0.9427\n",
      "Entity: Audit Services, Label: ORG, Score: 0.8769\n",
      "Entity: ASC, Label: MISC, Score: 0.6365\n",
      "Entity: Ernst and Young LLP, Label: ORG, Score: 0.9961\n",
      "Entity: Tysons, Label: LOC, Score: 0.9479\n",
      "Entity: Virginia, Label: LOC, Score: 0.9918\n",
      "Entity: Strategy and Transactions, Label: ORG, Score: 0.8156\n",
      "Entity: & A, Label: ORG, Score: 0.8782\n",
      "Entity: Alteryx, Label: ORG, Score: 0.8925\n",
      "Entity: PowerBi, Label: ORG, Score: 0.8365\n",
      "Entity: Technical Accounting and Advisory Services, Label: ORG, Score: 0.9893\n",
      "Entity: FAAS, Label: ORG, Score: 0.9710\n",
      "Entity: Audit & Assurance, Label: ORG, Score: 0.9223\n",
      "Entity: AS, Label: ORG, Score: 0.5883\n",
      "Entity: Canadian, Label: MISC, Score: 0.9955\n",
      "Entity: US, Label: MISC, Score: 0.6204\n",
      "Entity: GAA, Label: ORG, Score: 0.5875\n",
      "Entity: VA, Label: ORG, Score: 0.8660\n",
      "Entity: Jonathan J Saville, Label: PER, Score: 0.8632\n",
      "Entity: Edwards Ave, Label: LOC, Score: 0.8707\n",
      "Entity: Richmond, Label: LOC, Score: 0.9937\n",
      "Entity: Kentucky Lexington, Label: LOC, Score: 0.9745\n",
      "Entity: Marriott, Label: ORG, Score: 0.7979\n",
      "Entity: City Center, Label: LOC, Score: 0.9315\n",
      "Entity: Mar, Label: LOC, Score: 0.6524\n",
      "Entity: ##riott, Label: ORG, Score: 0.5960\n",
      "Entity: City Center Lexington, Label: LOC, Score: 0.9419\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9958\n",
      "Entity: Fedex Ground, Label: ORG, Score: 0.8165\n",
      "Entity: Lexington, Label: LOC, Score: 0.9817\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9969\n",
      "Entity: EZgigs Staffing Service, Label: ORG, Score: 0.9561\n",
      "Entity: Lexington, Label: LOC, Score: 0.9485\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9920\n",
      "Entity: Chris Stapleton, Label: PER, Score: 0.9293\n",
      "Entity: Rup, Label: LOC, Score: 0.7404\n",
      "Entity: Arena Harrodsburg, Label: LOC, Score: 0.8480\n",
      "Entity: Oktoberfest, Label: MISC, Score: 0.8395\n",
      "Entity: Hyatt Regency, Label: ORG, Score: 0.8098\n",
      "Entity: Lexington, Label: LOC, Score: 0.8495\n",
      "Entity: Lexington, Label: LOC, Score: 0.9959\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9964\n",
      "Entity: Hyttops Sports Bar, Label: LOC, Score: 0.5458\n",
      "Entity: Bluefire Bar, Label: LOC, Score: 0.7279\n",
      "Entity: Grill, Label: LOC, Score: 0.5772\n",
      "Entity: Keeneland Hospitality, Label: ORG, Score: 0.9142\n",
      "Entity: Lexington, Label: LOC, Score: 0.9314\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9924\n",
      "Entity: Dupree Catering, Label: ORG, Score: 0.9843\n",
      "Entity: Lexington, Label: LOC, Score: 0.9092\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9923\n",
      "Entity: Lexington, Label: LOC, Score: 0.9687\n",
      "Entity: Kentucky, Label: LOC, Score: 0.9667\n",
      "Entity: ##ience, Label: ORG, Score: 0.6774\n",
      "Entity: EZ, Label: ORG, Score: 0.7416\n",
      "Entity: ##ND ICHARDSON, Label: ORG, Score: 0.6285\n",
      "Entity: ##GETOW, Label: ORG, Score: 0.5843\n",
      "Entity: M, Label: ORG, Score: 0.5348\n",
      "Entity: ##Donough, Label: ORG, Score: 0.5409\n",
      "Entity: ##f, Label: ORG, Score: 0.7519\n",
      "Entity: ##iness, Label: ORG, Score: 0.8213\n",
      "Entity: Washington, Label: LOC, Score: 0.9688\n",
      "Entity: DC, Label: LOC, Score: 0.9802\n",
      "Entity: ##GE, Label: ORG, Score: 0.6753\n",
      "Entity: GeorgetownS, Label: ORG, Score: 0.8681\n",
      "Entity: ##fC, Label: ORG, Score: 0.6986\n",
      "Entity: Washington, Label: LOC, Score: 0.9808\n",
      "Entity: DC, Label: LOC, Score: 0.9879\n",
      "Entity: ##GE, Label: ORG, Score: 0.5883\n",
      "Entity: GeorgetownC, Label: ORG, Score: 0.8524\n",
      "Entity: ##Arts & Science, Label: ORG, Score: 0.7664\n",
      "Entity: Washington, Label: LOC, Score: 0.9739\n",
      "Entity: DC, Label: LOC, Score: 0.9905\n",
      "Entity: SQL, Label: MISC, Score: 0.6730\n",
      "Entity: Java, Label: MISC, Score: 0.9417\n",
      "Entity: Python, Label: MISC, Score: 0.7048\n",
      "Entity: Excel, Label: MISC, Score: 0.7036\n",
      "Entity: AWS, Label: ORG, Score: 0.5011\n",
      "Entity: Excel, Label: MISC, Score: 0.9101\n",
      "Entity: Pi, Label: MISC, Score: 0.5548\n",
      "Entity: Salesforce, Label: ORG, Score: 0.9055\n",
      "Entity: ##A, Label: ORG, Score: 0.6056\n",
      "Entity: ##L, Label: ORG, Score: 0.6379\n",
      "Entity: JIRA, Label: ORG, Score: 0.8310\n",
      "Entity: ETL, Label: ORG, Score: 0.6672\n",
      "Entity: Microsoft, Label: MISC, Score: 0.5206\n",
      "Entity: Microsoft, Label: MISC, Score: 0.4802\n",
      "Entity: Washington, Label: LOC, Score: 0.3889\n",
      "Entity: DC, Label: ORG, Score: 0.4081\n",
      "Entity: USA, Label: LOC, Score: 0.5551\n",
      "Entity: Nicholas E, Label: PER, Score: 0.9242\n",
      "Entity: Reese, Label: PER, Score: 0.9529\n",
      "Entity: Van Ness, Label: LOC, Score: 0.6164\n",
      "Entity: Washington D, Label: LOC, Score: 0.9983\n",
      "Entity: C, Label: LOC, Score: 0.9990\n",
      "Entity: Nicholas. E, Label: PER, Score: 0.7995\n",
      "Entity: Reese, Label: PER, Score: 0.9900\n",
      "Entity: Georgetown University, Label: ORG, Score: 0.9981\n",
      "Entity: Master, Label: MISC, Score: 0.4842\n",
      "Entity: Science, Label: MISC, Score: 0.6786\n",
      "Entity: Ana, Label: MISC, Score: 0.4281\n",
      "Entity: ##tics, Label: MISC, Score: 0.7451\n",
      "Entity: MSBA, Label: ORG, Score: 0.6407\n",
      "Entity: Dickinson College, Label: ORG, Score: 0.9969\n",
      "Entity: Science, Label: MISC, Score: 0.6827\n",
      "Entity: Major Varsity Tennis, Label: MISC, Score: 0.6279\n",
      "Entity: University of Bologna, Label: ORG, Score: 0.9712\n",
      "Entity: FINRA, Label: ORG, Score: 0.9380\n",
      "Entity: Washington, Label: LOC, Score: 0.9978\n",
      "Entity: D, Label: LOC, Score: 0.9986\n",
      "Entity: C, Label: LOC, Score: 0.9988\n",
      "Entity: PostgreSQL, Label: MISC, Score: 0.8501\n",
      "Entity: NoSQL, Label: MISC, Score: 0.9160\n",
      "Entity: R & Python, Label: MISC, Score: 0.8393\n",
      "Entity: Python, Label: MISC, Score: 0.9269\n",
      "Entity: R, Label: MISC, Score: 0.9422\n",
      "Entity: Power BI, Label: MISC, Score: 0.7778\n",
      "Entity: Tableau, Label: MISC, Score: 0.8167\n",
      "Entity: SQL, Label: MISC, Score: 0.7720\n",
      "Entity: Based S, Label: MISC, Score: 0.7409\n",
      "Entity: FINRA, Label: ORG, Score: 0.9751\n",
      "Entity: FINRA, Label: ORG, Score: 0.9750\n",
      "Entity: Georgetown, Label: ORG, Score: 0.7613\n",
      "Entity: Advanced Analytics Program, Label: MISC, Score: 0.6055\n",
      "Entity: Based S, Label: MISC, Score: 0.7396\n",
      "Entity: FINRA, Label: ORG, Score: 0.9024\n",
      "Entity: Power B, Label: MISC, Score: 0.6652\n",
      "Entity: MS, Label: ORG, Score: 0.5474\n"
     ]
    }
   ],
   "source": [
    "for doc_entities in entities:\n",
    "    for entity in doc_entities:\n",
    "        print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66894ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#email_data = pd.read_csv('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d9886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#email_data = pd.DataFrame(email_data)\n",
    "\n",
    "#email_data.to_csv('emails.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de2d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#email_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85332175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = Dataset.from_pandas(email_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#email_data = Dataset.from_pandas(email_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
